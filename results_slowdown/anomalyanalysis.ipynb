{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_ADNR_A01 = pd.read_csv('../data_ADNR/with0.1anomaly/allocatedJobs.csv')\n",
    "#df_ADNR_M01 = pd.read_csv('../data_ADNR/with0.1anomaly/destroyedJobs.csv')\n",
    "\n",
    "df_ADNR_A01 = pd.read_csv('../data_ADNR/with0.1anomaly/allocatedJobs.csv')\n",
    "df_ADNR_A01_2 = pd.read_csv('../experiments/experiment_results_NR/0.1/allocatedJobs.csv')\n",
    "df_ADNR_A01 = pd.concat([df_ADNR_A01,df_ADNR_A01_2], ignore_index=True)\n",
    "\n",
    "df_ADNR_M01 = pd.read_csv('../data_ADNR/with0.1anomaly/destroyedJobs.csv')\n",
    "df_ADNR_M01_2 = pd.read_csv('../experiments/experiment_results_NR/0.1/destroyedJobs.csv')\n",
    "df_ADNR_M01 = pd.concat([df_ADNR_M01,df_ADNR_M01_2], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def has_high_resource(row):\n",
    "    # Check if any resource requirement is above 10\n",
    "    return np.any(np.array(row['job ressource requirement']) > 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_to_list(row):\n",
    "    if isinstance(row, list):\n",
    "        return row\n",
    "    # Remove brackets and split on space\n",
    "    items = row.replace('[', '').replace(']', '').split(' ')\n",
    "    # Remove any empty strings caused by extra spaces\n",
    "    items = [item for item in items if item != '']\n",
    "    # Convert strings to integers\n",
    "    items = [int(item) for item in items]\n",
    "    return items"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def has_high_length(row):\n",
    "    return row['job Length'] >= 23"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ADNR_A01['job ressource requirement'] = df_ADNR_A01['job ressource requirement'].apply(convert_to_list)\n",
    "df_ADNR_M01['job ressource requirement'] = df_ADNR_M01['job ressource requirement'].apply(convert_to_list)\n",
    "\n",
    "df_ADNR_A01['high_resource'] = df_ADNR_A01.apply(has_high_resource, axis=1)\n",
    "df_ADNR_M01['high_resource'] = df_ADNR_M01.apply(has_high_resource, axis=1)\n",
    "\n",
    "df_ADNR_A01['high_length'] = df_ADNR_A01.apply(has_high_length, axis=1)\n",
    "df_ADNR_M01['high_length'] = df_ADNR_M01.apply(has_high_length, axis=1)\n",
    "\n",
    "df_ADNR_A01['high_length_or_resource'] = df_ADNR_A01['high_length'] | df_ADNR_A01['high_resource']\n",
    "df_ADNR_M01['high_length_or_resource'] = df_ADNR_M01['high_length'] | df_ADNR_M01['high_resource']\n",
    "\n",
    "allocated_high_length_or_resource = df_ADNR_A01['high_length_or_resource'].sum()\n",
    "destroyed_high_length_or_resource = df_ADNR_M01['high_length_or_resource'].sum()\n",
    "\n",
    "# Calculate the total number of jobs that satisfy either condition\n",
    "total_high_length_or_resource = allocated_high_length_or_resource + destroyed_high_length_or_resource\n",
    "\n",
    "# Calculate the proportion of these jobs that were destroyed\n",
    "proportion_destroyed_length_or_resource = float(destroyed_high_length_or_resource) / total_high_length_or_resource\n",
    "\n",
    "TN = len(df_ADNR_A01[(df_ADNR_A01['high_resource'] == False) & (df_ADNR_A01['high_length'] == False)])\n",
    "\n",
    "# False negatives (anomalous jobs incorrectly identified as non-anomalies)\n",
    "FN = len(df_ADNR_A01[(df_ADNR_A01['high_resource'] == True) | (df_ADNR_A01['high_length'] == True)])\n",
    "\n",
    "TP = len(df_ADNR_M01[(df_ADNR_M01['high_resource'] == True) | (df_ADNR_M01['high_length'] == True)])\n",
    "\n",
    "# False positives (non-anomalous jobs incorrectly identified as anomalies)\n",
    "FP = len(df_ADNR_M01[(df_ADNR_M01['high_resource'] == False) & (df_ADNR_M01['high_length'] == False)])\n",
    "\n",
    "# Recall calculation\n",
    "recall = float(TP) / (TP + FN)\n",
    "recall\n",
    "\n",
    "\n",
    "\n",
    "# Precision calculation\n",
    "precision = float(TP) / (TP + FP)\n",
    "precision\n",
    "\n",
    "f1_score = 2 * (precision * recall) / (precision+recall)\n",
    "f1_score\n",
    "\n",
    "print(proportion_destroyed_length_or_resource, precision, recall, f1_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ADNR_A01['job ressource requirement'] = df_ADNR_A01['job ressource requirement'].apply(convert_to_list)\n",
    "df_ADNR_M01['job ressource requirement'] = df_ADNR_M01['job ressource requirement'].apply(convert_to_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ADNR_A01['high_resource'] = df_ADNR_A01.apply(has_high_resource, axis=1)\n",
    "df_ADNR_M01['high_resource'] = df_ADNR_M01.apply(has_high_resource, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply the function to both dataframes\n",
    "df_ADNR_A01['high_length'] = df_ADNR_A01.apply(has_high_length, axis=1)\n",
    "df_ADNR_M01['high_length'] = df_ADNR_M01.apply(has_high_length, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a new column that is True when either high_length or high_resource is True\n",
    "df_ADNR_A01['high_length_or_resource'] = df_ADNR_A01['high_length'] | df_ADNR_A01['high_resource']\n",
    "df_ADNR_M01['high_length_or_resource'] = df_ADNR_M01['high_length'] | df_ADNR_M01['high_resource']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Proportion of jobs with either high length or high resource that were destroyed:', 0.7476025704399407)\n"
     ]
    }
   ],
   "source": [
    "allocated_high_length_or_resource = df_ADNR_A01['high_length_or_resource'].sum()\n",
    "destroyed_high_length_or_resource = df_ADNR_M01['high_length_or_resource'].sum()\n",
    "\n",
    "# Calculate the total number of jobs that satisfy either condition\n",
    "total_high_length_or_resource = allocated_high_length_or_resource + destroyed_high_length_or_resource\n",
    "\n",
    "# Calculate the proportion of these jobs that were destroyed\n",
    "proportion_destroyed_length_or_resource = float(destroyed_high_length_or_resource) / total_high_length_or_resource\n",
    "\n",
    "print(\"Proportion of jobs with either high length or high resource that were destroyed:\", proportion_destroyed_length_or_resource)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.31045380875202594"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TP = len(df_ADNR_M01[(df_ADNR_M01['high_resource'] == True) | (df_ADNR_M01['high_length'] == True)])\n",
    "\n",
    "# False positives (non-anomalous jobs incorrectly identified as anomalies)\n",
    "FP = len(df_ADNR_M01[(df_ADNR_M01['high_resource'] == False) & (df_ADNR_M01['high_length'] == False)])\n",
    "\n",
    "# Precision calculation\n",
    "precision = float(TP) / (TP + FP)\n",
    "precision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.43850512218851945"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1_score = 2 * (precision * proportion_destroyed_length_or_resource) / (precision+proportion_destroyed_length_or_resource)\n",
    "f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_ADNR_A03 = pd.read_csv('../data_ADNR/with0.3anomaly/allocatedJobs.csv')\n",
    "#df_ADNR_M03 = pd.read_csv('../data_ADNR/with0.3anomaly/destroyedJobs.csv')\n",
    "df_ADNR_A03 = pd.read_csv('../data_ADNR/with0.3anomaly/allocatedJobs.csv')\n",
    "df_ADNR_A03_2 = pd.read_csv('../experiments/experiment_results_NR/0.3/allocatedJobs.csv')\n",
    "df_ADNR_A03 = pd.concat([df_ADNR_A03,df_ADNR_A03_2], ignore_index=True)\n",
    "\n",
    "df_ADNR_M03 = pd.read_csv('../data_ADNR/with0.3anomaly/destroyedJobs.csv')\n",
    "df_ADNR_M03_2 = pd.read_csv('../experiments/experiment_results_NR/0.3/destroyedJobs.csv')\n",
    "df_ADNR_M03 = pd.concat([df_ADNR_M03,df_ADNR_M03_2], ignore_index=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0.8238316979876933, 0.7348612965435395, 0.8238316979876933, 0.7768072761486593)\n"
     ]
    }
   ],
   "source": [
    "df_ADNR_A03['job ressource requirement'] = df_ADNR_A03['job ressource requirement'].apply(convert_to_list)\n",
    "df_ADNR_M03['job ressource requirement'] = df_ADNR_M03['job ressource requirement'].apply(convert_to_list)\n",
    "\n",
    "df_ADNR_A03['high_resource'] = df_ADNR_A03.apply(has_high_resource, axis=1)\n",
    "df_ADNR_M03['high_resource'] = df_ADNR_M03.apply(has_high_resource, axis=1)\n",
    "\n",
    "df_ADNR_A03['high_length'] = df_ADNR_A03.apply(has_high_length, axis=1)\n",
    "df_ADNR_M03['high_length'] = df_ADNR_M03.apply(has_high_length, axis=1)\n",
    "\n",
    "df_ADNR_A03['high_length_or_resource'] = df_ADNR_A03['high_length'] | df_ADNR_A03['high_resource']\n",
    "df_ADNR_M03['high_length_or_resource'] = df_ADNR_M03['high_length'] | df_ADNR_M03['high_resource']\n",
    "\n",
    "allocated_high_length_or_resource = df_ADNR_A03['high_length_or_resource'].sum()\n",
    "destroyed_high_length_or_resource = df_ADNR_M03['high_length_or_resource'].sum()\n",
    "\n",
    "# Calculate the total number of jobs that satisfy either condition\n",
    "total_high_length_or_resource = allocated_high_length_or_resource + destroyed_high_length_or_resource\n",
    "\n",
    "# Calculate the proportion of these jobs that were destroyed\n",
    "proportion_destroyed_length_or_resource = float(destroyed_high_length_or_resource) / total_high_length_or_resource\n",
    "\n",
    "TN = len(df_ADNR_A03[(df_ADNR_A03['high_resource'] == False) & (df_ADNR_A03['high_length'] == False)])\n",
    "\n",
    "# False negatives (anomalous jobs incorrectly identified as non-anomalies)\n",
    "FN = len(df_ADNR_A03[(df_ADNR_A03['high_resource'] == True) | (df_ADNR_A03['high_length'] == True)])\n",
    "\n",
    "TP = len(df_ADNR_M03[(df_ADNR_M03['high_resource'] == True) | (df_ADNR_M03['high_length'] == True)])\n",
    "\n",
    "# False positives (non-anomalous jobs incorrectly identified as anomalies)\n",
    "FP = len(df_ADNR_M03[(df_ADNR_M03['high_resource'] == False) & (df_ADNR_M03['high_length'] == False)])\n",
    "\n",
    "# Recall calculation\n",
    "recall = float(TP) / (TP + FN)\n",
    "recall\n",
    "\n",
    "\n",
    "\n",
    "# Precision calculation\n",
    "precision = float(TP) / (TP + FP)\n",
    "precision\n",
    "\n",
    "f1_score = 2 * (precision * recall) / (precision+recall)\n",
    "f1_score\n",
    "\n",
    "print(proportion_destroyed_length_or_resource, precision, recall, f1_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_ADNR_A05 = pd.read_csv('../data_ADNR/with0.5anomaly/allocatedJobs.csv')\n",
    "#df_ADNR_M05 = pd.read_csv('../data_ADNR/with0.5anomaly/destroyedJobs.csv')\n",
    "\n",
    "df_ADNR_A05 = pd.read_csv('../data_ADNR/with0.5anomaly/allocatedJobs.csv')\n",
    "df_ADNR_A05_2 = pd.read_csv('../experiments/experiment_results_NR/0.5/allocatedJobs.csv')\n",
    "df_ADNR_A05 = pd.concat([df_ADNR_A05,df_ADNR_A05_2], ignore_index=True)\n",
    "\n",
    "df_ADNR_M05 = pd.read_csv('../data_ADNR/with0.5anomaly/destroyedJobs.csv')\n",
    "df_ADNR_M05_2 = pd.read_csv('../experiments/experiment_results_NR/0.5/destroyedJobs.csv')\n",
    "df_ADNR_M05 = pd.concat([df_ADNR_M05,df_ADNR_M05_2], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0.8969326062962292, 0.9189127609660597, 0.8969326062962292, 0.9077896527002017)\n"
     ]
    }
   ],
   "source": [
    "df_ADNR_A05['job ressource requirement'] = df_ADNR_A05['job ressource requirement'].apply(convert_to_list)\n",
    "df_ADNR_M05['job ressource requirement'] = df_ADNR_M05['job ressource requirement'].apply(convert_to_list)\n",
    "\n",
    "df_ADNR_A05['high_resource'] = df_ADNR_A05.apply(has_high_resource, axis=1)\n",
    "df_ADNR_M05['high_resource'] = df_ADNR_M05.apply(has_high_resource, axis=1)\n",
    "\n",
    "df_ADNR_A05['high_length'] = df_ADNR_A05.apply(has_high_length, axis=1)\n",
    "df_ADNR_M05['high_length'] = df_ADNR_M05.apply(has_high_length, axis=1)\n",
    "\n",
    "df_ADNR_A05['high_length_or_resource'] = df_ADNR_A05['high_length'] | df_ADNR_A05['high_resource']\n",
    "df_ADNR_M05['high_length_or_resource'] = df_ADNR_M05['high_length'] | df_ADNR_M05['high_resource']\n",
    "\n",
    "allocated_high_length_or_resource = df_ADNR_A05['high_length_or_resource'].sum()\n",
    "destroyed_high_length_or_resource = df_ADNR_M05['high_length_or_resource'].sum()\n",
    "\n",
    "# Calculate the total number of jobs that satisfy either condition\n",
    "total_high_length_or_resource = allocated_high_length_or_resource + destroyed_high_length_or_resource\n",
    "\n",
    "# Calculate the proportion of these jobs that were destroyed\n",
    "proportion_destroyed_length_or_resource = float(destroyed_high_length_or_resource) / total_high_length_or_resource\n",
    "\n",
    "TN = len(df_ADNR_A05[(df_ADNR_A05['high_resource'] == False) & (df_ADNR_A05['high_length'] == False)])\n",
    "\n",
    "# False negatives (anomalous jobs incorrectly identified as non-anomalies)\n",
    "FN = len(df_ADNR_A05[(df_ADNR_A05['high_resource'] == True) | (df_ADNR_A05['high_length'] == True)])\n",
    "\n",
    "TP = len(df_ADNR_M05[(df_ADNR_M05['high_resource'] == True) | (df_ADNR_M05['high_length'] == True)])\n",
    "\n",
    "# False positives (non-anomalous jobs incorrectly identified as anomalies)\n",
    "FP = len(df_ADNR_M05[(df_ADNR_M05['high_resource'] == False) & (df_ADNR_M05['high_length'] == False)])\n",
    "\n",
    "# Recall calculation\n",
    "recall = float(TP) / (TP + FN)\n",
    "recall\n",
    "\n",
    "# Precision calculation\n",
    "precision = float(TP) / (TP + FP)\n",
    "precision\n",
    "\n",
    "f1_score = 2 * (precision * recall) / (precision+recall)\n",
    "f1_score\n",
    "\n",
    "print(proportion_destroyed_length_or_resource, precision, recall, f1_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_AD_A01 = pd.read_csv('../data_AD/anomalyrate0.1/allocatedJobs.csv')\n",
    "df_AD_A01_2 = pd.read_csv('../experiments/experiment_results_AD/0.1/allocatedJobs.csv')\n",
    "df_AD_A01 = pd.concat([df_AD_A01,df_AD_A01_2], ignore_index=True)\n",
    "\n",
    "df_AD_M01 = pd.read_csv('../data_AD/anomalyrate0.1/destroyedJobs.csv')\n",
    "df_AD_M01_2 = pd.read_csv('../experiments/experiment_results_AD/0.1/destroyedJobs.csv')\n",
    "df_AD_M01 = pd.concat([df_AD_M01,df_AD_M01_2], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0.7930298719772404, 0.3604992024830797, 0.7930298719772404, 0.4956730484262936)\n"
     ]
    }
   ],
   "source": [
    "df_AD_A01['job ressource requirement'] = df_AD_A01['job ressource requirement'].apply(convert_to_list)\n",
    "df_AD_M01['job ressource requirement'] = df_AD_M01['job ressource requirement'].apply(convert_to_list)\n",
    "\n",
    "df_AD_A01['high_resource'] = df_AD_A01.apply(has_high_resource, axis=1)\n",
    "df_AD_M01['high_resource'] = df_AD_M01.apply(has_high_resource, axis=1)\n",
    "\n",
    "df_AD_A01['high_length'] = df_AD_A01.apply(has_high_length, axis=1)\n",
    "df_AD_M01['high_length'] = df_AD_M01.apply(has_high_length, axis=1)\n",
    "\n",
    "df_AD_A01['high_length_or_resource'] = df_AD_A01['high_length'] | df_AD_A01['high_resource']\n",
    "df_AD_M01['high_length_or_resource'] = df_AD_M01['high_length'] | df_AD_M01['high_resource']\n",
    "\n",
    "allocated_high_length_or_resource = df_AD_A01['high_length_or_resource'].sum()\n",
    "destroyed_high_length_or_resource = df_AD_M01['high_length_or_resource'].sum()\n",
    "\n",
    "# Calculate the total number of jobs that satisfy either condition\n",
    "total_high_length_or_resource = allocated_high_length_or_resource + destroyed_high_length_or_resource\n",
    "\n",
    "# Calculate the proportion of these jobs that were destroyed\n",
    "proportion_destroyed_length_or_resource = float(destroyed_high_length_or_resource) / total_high_length_or_resource\n",
    "\n",
    "TN = len(df_AD_A01[(df_AD_A01['high_resource'] == False) & (df_AD_A01['high_length'] == False)])\n",
    "\n",
    "# False negatives (anomalous jobs incorrectly identified as non-anomalies)\n",
    "FN = len(df_AD_A01[(df_AD_A01['high_resource'] == True) | (df_AD_A01['high_length'] == True)])\n",
    "\n",
    "TP = len(df_AD_M01[(df_AD_M01['high_resource'] == True) | (df_AD_M01['high_length'] == True)])\n",
    "\n",
    "# False positives (non-anomalous jobs incorrectly identified as anomalies)\n",
    "FP = len(df_AD_M01[(df_AD_M01['high_resource'] == False) & (df_AD_M01['high_length'] == False)])\n",
    "\n",
    "# Recall calculation\n",
    "recall = float(TP) / (TP + FN)\n",
    "recall\n",
    "\n",
    "# Precision calculation\n",
    "precision = float(TP) / (TP + FP)\n",
    "precision\n",
    "\n",
    "f1_score = 2 * (precision * recall) / (precision+recall)\n",
    "f1_score\n",
    "\n",
    "print(proportion_destroyed_length_or_resource, precision, recall, f1_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_AD_A03 = pd.read_csv('../data_AD/anomalyrate0.3/allocatedJobs.csv')\n",
    "df_AD_A03_2 = pd.read_csv('../experiments/experiment_results_AD/0.3/allocatedJobs.csv')\n",
    "df_AD_A03 = pd.concat([df_AD_A03,df_AD_A03_2], ignore_index=True)\n",
    "\n",
    "df_AD_M03 = pd.read_csv('../data_AD/anomalyrate0.3/destroyedJobs.csv')\n",
    "df_AD_M03_2 = pd.read_csv('../experiments/experiment_results_AD/0.3/destroyedJobs.csv')\n",
    "df_AD_M03 = pd.concat([df_AD_M03,df_AD_M03_2], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0.7957710404492676, 0.7958540866182818, 0.7957710404492676, 0.7958125613672262)\n"
     ]
    }
   ],
   "source": [
    "df_AD_A03['job ressource requirement'] = df_AD_A03['job ressource requirement'].apply(convert_to_list)\n",
    "df_AD_M03['job ressource requirement'] = df_AD_M03['job ressource requirement'].apply(convert_to_list)\n",
    "\n",
    "df_AD_A03['high_resource'] = df_AD_A03.apply(has_high_resource, axis=1)\n",
    "df_AD_M03['high_resource'] = df_AD_M03.apply(has_high_resource, axis=1)\n",
    "\n",
    "df_AD_A03['high_length'] = df_AD_A03.apply(has_high_length, axis=1)\n",
    "df_AD_M03['high_length'] = df_AD_M03.apply(has_high_length, axis=1)\n",
    "\n",
    "df_AD_A03['high_length_or_resource'] = df_AD_A03['high_length'] | df_AD_A03['high_resource']\n",
    "df_AD_M03['high_length_or_resource'] = df_AD_M03['high_length'] | df_AD_M03['high_resource']\n",
    "\n",
    "allocated_high_length_or_resource = df_AD_A03['high_length_or_resource'].sum()\n",
    "destroyed_high_length_or_resource = df_AD_M03['high_length_or_resource'].sum()\n",
    "\n",
    "# Calculate the total number of jobs that satisfy either condition\n",
    "total_high_length_or_resource = allocated_high_length_or_resource + destroyed_high_length_or_resource\n",
    "\n",
    "# Calculate the proportion of these jobs that were destroyed\n",
    "proportion_destroyed_length_or_resource = float(destroyed_high_length_or_resource) / total_high_length_or_resource\n",
    "\n",
    "TN = len(df_AD_A03[(df_AD_A03['high_resource'] == False) & (df_AD_A03['high_length'] == False)])\n",
    "\n",
    "# False negatives (anomalous jobs incorrectly identified as non-anomalies)\n",
    "FN = len(df_AD_A03[(df_AD_A03['high_resource'] == True) | (df_AD_A03['high_length'] == True)])\n",
    "\n",
    "TP = len(df_AD_M03[(df_AD_M03['high_resource'] == True) | (df_AD_M03['high_length'] == True)])\n",
    "\n",
    "# False positives (non-anomalous jobs incorrectly identified as anomalies)\n",
    "FP = len(df_AD_M03[(df_AD_M03['high_resource'] == False) & (df_AD_M03['high_length'] == False)])\n",
    "\n",
    "# Recall calculation\n",
    "recall = float(TP) / (TP + FN)\n",
    "recall\n",
    "\n",
    "# Precision calculation\n",
    "precision = float(TP) / (TP + FP)\n",
    "precision\n",
    "\n",
    "f1_score = 2 * (precision * recall) / (precision+recall)\n",
    "f1_score\n",
    "\n",
    "print(proportion_destroyed_length_or_resource, precision, recall, f1_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_AD_A05 = pd.read_csv('../data_AD/anomalyrate0.5/allocatedJobs.csv')\n",
    "df_AD_A05_2 = pd.read_csv('../experiments/experiment_results_AD/0.5/allocatedJobs.csv')\n",
    "df_AD_A05 = pd.concat([df_AD_A05,df_AD_A05_2], ignore_index=True)\n",
    "\n",
    "df_AD_M05 = pd.read_csv('../data_AD/anomalyrate0.5/destroyedJobs.csv')\n",
    "df_AD_M05_2 = pd.read_csv('../experiments/experiment_results_AD/0.5/destroyedJobs.csv')\n",
    "df_AD_M05 = pd.concat([df_AD_M05,df_AD_M05_2], ignore_index=True)\n",
    "#df_AD_A05.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0.790907033777544, 0.9429238060517682, 0.790907033777544, 0.8602512464203872)\n"
     ]
    }
   ],
   "source": [
    "df_AD_A05['job ressource requirement'] = df_AD_A05['job ressource requirement'].apply(convert_to_list)\n",
    "df_AD_M05['job ressource requirement'] = df_AD_M05['job ressource requirement'].apply(convert_to_list)\n",
    "\n",
    "df_AD_A05['high_resource'] = df_AD_A05.apply(has_high_resource, axis=1)\n",
    "df_AD_M05['high_resource'] = df_AD_M05.apply(has_high_resource, axis=1)\n",
    "\n",
    "df_AD_A05['high_length'] = df_AD_A05.apply(has_high_length, axis=1)\n",
    "df_AD_M05['high_length'] = df_AD_M05.apply(has_high_length, axis=1)\n",
    "\n",
    "df_AD_A05['high_length_or_resource'] = df_AD_A05['high_length'] | df_AD_A05['high_resource']\n",
    "df_AD_M05['high_length_or_resource'] = df_AD_M05['high_length'] | df_AD_M05['high_resource']\n",
    "\n",
    "allocated_high_length_or_resource = df_AD_A05['high_length_or_resource'].sum()\n",
    "destroyed_high_length_or_resource = df_AD_M05['high_length_or_resource'].sum()\n",
    "\n",
    "# Calculate the total number of jobs that satisfy either condition\n",
    "total_high_length_or_resource = allocated_high_length_or_resource + destroyed_high_length_or_resource\n",
    "\n",
    "# Calculate the proportion of these jobs that were destroyed\n",
    "proportion_destroyed_length_or_resource = float(destroyed_high_length_or_resource) / total_high_length_or_resource\n",
    "\n",
    "TN = len(df_AD_A05[(df_AD_A05['high_resource'] == False) & (df_AD_A05['high_length'] == False)])\n",
    "\n",
    "# False negatives (anomalous jobs incorrectly identified as non-anomalies)\n",
    "FN = len(df_AD_A05[(df_AD_A05['high_resource'] == True) | (df_AD_A05['high_length'] == True)])\n",
    "\n",
    "TP = len(df_AD_M05[(df_AD_M05['high_resource'] == True) | (df_AD_M05['high_length'] == True)])\n",
    "\n",
    "# False positives (non-anomalous jobs incorrectly identified as anomalies)\n",
    "FP = len(df_AD_M05[(df_AD_M05['high_resource'] == False) & (df_AD_M05['high_length'] == False)])\n",
    "\n",
    "# Recall calculation\n",
    "recall = float(TP) / (TP + FN)\n",
    "recall\n",
    "\n",
    "# Precision calculation\n",
    "precision = float(TP) / (TP + FP)\n",
    "precision\n",
    "\n",
    "f1_score = 2 * (precision * recall) / (precision+recall)\n",
    "f1_score\n",
    "\n",
    "print(proportion_destroyed_length_or_resource, precision, recall, f1_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ECO_A01M1 = pd.read_csv('../data_ECO/anomalyrate0.1/allocatedJobsM1.csv')\n",
    "df_ECO_A01M1_2 = pd.read_csv('../experiment_results_ECO/0.1/allocatedJobsM1.csv')\n",
    "df_ECO_A01M2 = pd.read_csv('../data_ECO/anomalyrate0.1/allocatedJobsM2.csv')\n",
    "df_ECO_A01M2_2 = pd.read_csv('../experiment_results_ECO/0.1/allocatedJobsM2.csv')\n",
    "df_ECO_A01 = pd.concat([df_ECO_A01M1,df_ECO_A01M1_2, df_ECO_A01M2, df_ECO_A01M2_2], ignore_index=True)\n",
    "\n",
    "df_ECO_M01M3 = pd.read_csv('../data_ECO/anomalyrate0.1/allocatedJobsM3.csv')\n",
    "df_ECO_M01M3_2 = pd.read_csv('../experiment_results_ECO/0.1/allocatedJobsM3.csv')\n",
    "df_ECO_M01M3 = pd.concat([df_ECO_M01M3,df_ECO_M01M3_2], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0.9985550361240969, 0.3053887545816112, 0.9985550361240969, 0.4677310188318669)\n"
     ]
    }
   ],
   "source": [
    "df_ECO_A01['job ressource requirement'] = df_ECO_A01['job ressource requirement'].apply(convert_to_list)\n",
    "df_ECO_M01M3['job ressource requirement'] = df_ECO_M01M3['job ressource requirement'].apply(convert_to_list)\n",
    "\n",
    "df_ECO_A01['high_resource'] = df_ECO_A01.apply(has_high_resource, axis=1)\n",
    "df_ECO_M01M3['high_resource'] = df_ECO_M01M3.apply(has_high_resource, axis=1)\n",
    "\n",
    "df_ECO_A01['high_length'] = df_ECO_A01.apply(has_high_length, axis=1)\n",
    "df_ECO_M01M3['high_length'] = df_ECO_M01M3.apply(has_high_length, axis=1)\n",
    "\n",
    "df_ECO_A01['high_length_or_resource'] = df_ECO_A01['high_length'] | df_ECO_A01['high_resource']\n",
    "df_ECO_M01M3['high_length_or_resource'] = df_ECO_M01M3['high_length'] | df_ECO_M01M3['high_resource']\n",
    "\n",
    "allocated_high_length_or_resource = df_ECO_A01['high_length_or_resource'].sum()\n",
    "destroyed_high_length_or_resource = df_ECO_M01M3['high_length_or_resource'].sum()\n",
    "\n",
    "# Calculate the total number of jobs that satisfy either condition\n",
    "total_high_length_or_resource = allocated_high_length_or_resource + destroyed_high_length_or_resource\n",
    "\n",
    "# Calculate the proportion of these jobs that were destroyed\n",
    "proportion_destroyed_length_or_resource = float(destroyed_high_length_or_resource) / total_high_length_or_resource\n",
    "\n",
    "TN = len(df_ECO_A01[(df_ECO_A01['high_resource'] == False) & (df_ECO_A01['high_length'] == False)])\n",
    "\n",
    "# False negatives (anomalous jobs incorrectly identified as non-anomalies)\n",
    "FN = len(df_ECO_A01[(df_ECO_A01['high_resource'] == True) | (df_ECO_A01['high_length'] == True)])\n",
    "\n",
    "TP = len(df_ECO_M01M3[(df_ECO_M01M3['high_resource'] == True) | (df_ECO_M01M3['high_length'] == True)])\n",
    "\n",
    "# False positives (non-anomalous jobs incorrectly identified as anomalies)\n",
    "FP = len(df_ECO_M01M3[(df_ECO_M01M3['high_resource'] == False) & (df_ECO_M01M3['high_length'] == False)])\n",
    "\n",
    "# Recall calculation\n",
    "recall = float(TP) / (TP + FN)\n",
    "recall\n",
    "\n",
    "# Precision calculation\n",
    "precision = float(TP) / (TP + FP)\n",
    "precision\n",
    "\n",
    "f1_score = 2 * (precision * recall) / (precision+recall)\n",
    "f1_score\n",
    "\n",
    "print(proportion_destroyed_length_or_resource, precision, recall, f1_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ECO_A03M1 = pd.read_csv('../data_ECO/anomalyrate0.3/allocatedJobsM1.csv')\n",
    "df_ECO_A03M1_2 = pd.read_csv('../experiment_results_ECO/0.3/allocatedJobsM1.csv')\n",
    "df_ECO_A03M2 = pd.read_csv('../data_ECO/anomalyrate0.3/allocatedJobsM2.csv')\n",
    "df_ECO_A03M2_2 = pd.read_csv('../experiment_results_ECO/0.3/allocatedJobsM2.csv')\n",
    "df_ECO_A03 = pd.concat([df_ECO_A03M1,df_ECO_A03M1_2, df_ECO_A03M2, df_ECO_A03M2_2], ignore_index=True)\n",
    "\n",
    "df_ECO_M03M3 = pd.read_csv('../data_ECO/anomalyrate0.3/allocatedJobsM3.csv')\n",
    "df_ECO_M03M3_2 = pd.read_csv('../experiment_results_ECO/0.3/allocatedJobsM3.csv')\n",
    "df_ECO_M03M3 = pd.concat([df_ECO_M03M3,df_ECO_M03M3_2], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<type 'list'>\n"
     ]
    }
   ],
   "source": [
    "print(type(df_ECO_A03['job ressource requirement'].iloc[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0.9847071988064156, 0.732824427480916, 0.9847071988064156, 0.8402960133683457)\n"
     ]
    }
   ],
   "source": [
    "df_ECO_A03['job ressource requirement'] = df_ECO_A03['job ressource requirement'].apply(convert_to_list)\n",
    "df_ECO_M03M3['job ressource requirement'] = df_ECO_M03M3['job ressource requirement'].apply(convert_to_list)\n",
    "\n",
    "df_ECO_A03['high_resource'] = df_ECO_A03.apply(has_high_resource, axis=1)\n",
    "df_ECO_M03M3['high_resource'] = df_ECO_M03M3.apply(has_high_resource, axis=1)\n",
    "\n",
    "df_ECO_A03['high_length'] = df_ECO_A03.apply(has_high_length, axis=1)\n",
    "df_ECO_M03M3['high_length'] = df_ECO_M03M3.apply(has_high_length, axis=1)\n",
    "\n",
    "df_ECO_A03['high_length_or_resource'] = df_ECO_A03['high_length'] | df_ECO_A03['high_resource']\n",
    "df_ECO_M03M3['high_length_or_resource'] = df_ECO_M03M3['high_length'] | df_ECO_M03M3['high_resource']\n",
    "\n",
    "allocated_high_length_or_resource = df_ECO_A03['high_length_or_resource'].sum()\n",
    "destroyed_high_length_or_resource = df_ECO_M03M3['high_length_or_resource'].sum()\n",
    "\n",
    "# Calculate the total number of jobs that satisfy either condition\n",
    "total_high_length_or_resource = allocated_high_length_or_resource + destroyed_high_length_or_resource\n",
    "\n",
    "# Calculate the proportion of these jobs that were destroyed\n",
    "proportion_destroyed_length_or_resource = float(destroyed_high_length_or_resource) / total_high_length_or_resource\n",
    "\n",
    "TN = len(df_ECO_A03[(df_ECO_A03['high_resource'] == False) & (df_ECO_A03['high_length'] == False)])\n",
    "\n",
    "# False negatives (anomalous jobs incorrectly identified as non-anomalies)\n",
    "FN = len(df_ECO_A03[(df_ECO_A03['high_resource'] == True) | (df_ECO_A03['high_length'] == True)])\n",
    "\n",
    "TP = len(df_ECO_M03M3[(df_ECO_M03M3['high_resource'] == True) | (df_ECO_M03M3['high_length'] == True)])\n",
    "\n",
    "# False positives (non-anomalous jobs incorrectly identified as anomalies)\n",
    "FP = len(df_ECO_M03M3[(df_ECO_M03M3['high_resource'] == False) & (df_ECO_M03M3['high_length'] == False)])\n",
    "\n",
    "# Recall calculation\n",
    "recall = float(TP) / (TP + FN)\n",
    "recall\n",
    "\n",
    "# Precision calculation\n",
    "precision = float(TP) / (TP + FP)\n",
    "precision\n",
    "\n",
    "f1_score = 2 * (precision * recall) / (precision+recall)\n",
    "f1_score\n",
    "\n",
    "print(proportion_destroyed_length_or_resource, precision, recall, f1_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ECO_A05M1 = pd.read_csv('../data_ECO/anomalyrate0.5/allocatedJobsM1.csv')\n",
    "df_ECO_A05M1_2 = pd.read_csv('../experiment_results_ECO/0.5/allocatedJobsM1.csv')\n",
    "df_ECO_A05M2 = pd.read_csv('../data_ECO/anomalyrate0.5/allocatedJobsM2.csv')\n",
    "df_ECO_A05M2_2 = pd.read_csv('../experiment_results_ECO/0.5/allocatedJobsM2.csv')\n",
    "df_ECO_A05 = pd.concat([df_ECO_A05M1,df_ECO_A05M1_2, df_ECO_A05M2, df_ECO_A05M2_2], ignore_index=True)\n",
    "\n",
    "df_ECO_M05M3 = pd.read_csv('../data_ECO/anomalyrate0.5/allocatedJobsM3.csv')\n",
    "df_ECO_M05M3_2 = pd.read_csv('../experiment_results_ECO/0.5/allocatedJobsM3.csv')\n",
    "df_ECO_M05M3 = pd.concat([df_ECO_M05M3,df_ECO_M05M3_2], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0.9521979985704074, 0.8415192672141504, 0.9521979985704074, 0.8934439973172367)\n"
     ]
    }
   ],
   "source": [
    "df_ECO_A05['job ressource requirement'] = df_ECO_A05['job ressource requirement'].apply(convert_to_list)\n",
    "df_ECO_M05M3['job ressource requirement'] = df_ECO_M05M3['job ressource requirement'].apply(convert_to_list)\n",
    "\n",
    "df_ECO_A05['high_resource'] = df_ECO_A05.apply(has_high_resource, axis=1)\n",
    "df_ECO_M05M3['high_resource'] = df_ECO_M05M3.apply(has_high_resource, axis=1)\n",
    "\n",
    "df_ECO_A05['high_length'] = df_ECO_A05.apply(has_high_length, axis=1)\n",
    "df_ECO_M05M3['high_length'] = df_ECO_M05M3.apply(has_high_length, axis=1)\n",
    "\n",
    "df_ECO_A05['high_length_or_resource'] = df_ECO_A05['high_length'] | df_ECO_A05['high_resource']\n",
    "df_ECO_M05M3['high_length_or_resource'] = df_ECO_M05M3['high_length'] | df_ECO_M05M3['high_resource']\n",
    "\n",
    "allocated_high_length_or_resource = df_ECO_A05['high_length_or_resource'].sum()\n",
    "destroyed_high_length_or_resource = df_ECO_M05M3['high_length_or_resource'].sum()\n",
    "\n",
    "# Calculate the total number of jobs that satisfy either condition\n",
    "total_high_length_or_resource = allocated_high_length_or_resource + destroyed_high_length_or_resource\n",
    "\n",
    "# Calculate the proportion of these jobs that were destroyed\n",
    "proportion_destroyed_length_or_resource = float(destroyed_high_length_or_resource) / total_high_length_or_resource\n",
    "\n",
    "TN = len(df_ECO_A05[(df_ECO_A05['high_resource'] == False) & (df_ECO_A05['high_length'] == False)])\n",
    "\n",
    "# False negatives (anomalous jobs incorrectly identified as non-anomalies)\n",
    "FN = len(df_ECO_A05[(df_ECO_A05['high_resource'] == True) | (df_ECO_A05['high_length'] == True)])\n",
    "\n",
    "TP = len(df_ECO_M05M3[(df_ECO_M05M3['high_resource'] == True) | (df_ECO_M05M3['high_length'] == True)])\n",
    "\n",
    "# False positives (non-anomalous jobs incorrectly identified as anomalies)\n",
    "FP = len(df_ECO_M05M3[(df_ECO_M05M3['high_resource'] == False) & (df_ECO_M05M3['high_length'] == False)])\n",
    "\n",
    "# Recall calculation\n",
    "recall = float(TP) / (TP + FN)\n",
    "recall\n",
    "\n",
    "# Precision calculation\n",
    "precision = float(TP) / (TP + FP)\n",
    "precision\n",
    "\n",
    "f1_score = 2 * (precision * recall) / (precision+recall)\n",
    "f1_score\n",
    "\n",
    "print(proportion_destroyed_length_or_resource, precision, recall, f1_score)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "p2venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.18"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
