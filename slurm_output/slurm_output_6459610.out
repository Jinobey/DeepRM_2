============================================================================================== 
Warning! Mixing Conda and module environments may lead to corruption of the
user environment. 
We do not recommend users mixing those two environments unless absolutely
necessary. Note that 
SURF does not provide any support for Conda environment.
For more information, please refer to our software policy page:
https://servicedesk.surf.nl/wiki/display/WIKI/Software+policy+Snellius#SoftwarepolicySnellius-UseofAnacondaandMinicondaenvironmentsonSnellius 

Remember that many packages have already been installed on the system and can
be loaded using 
the 'module load <package__name>' command. If you are uncertain if a package is
already available 
on the system, please use 'module avail' or 'module spider' to search for it.
============================================================================================== 
Active conda environment: py27
ERROR (theano.sandbox.cuda): nvcc compiler not found on $PATH. Check your nvcc installation and try again.
/home/terhard/.conda/envs/py27/lib/python2.7/site-packages/theano/tensor/signal/downsample.py:6: UserWarning: downsample module has been moved to the theano.tensor.signal.pool module.
  "downsample module has been moved to the theano.tensor.signal.pool module.")

Experiment type: pg_re
CNN used: True

Preparing for workers...
Filename: /gpfs/home6/terhard/DeepRM_2/data_collection.py

Line #    Mem usage    Increment   Line Contents
================================================
     9    144.8 MiB    144.8 MiB           @profile
    10                                     def convert_parameter_to_yaml(self,pa):
    11    144.8 MiB      0.0 MiB                   parameters = {                
    12    144.8 MiB      0.0 MiB                           'output_filename': pa.output_filename,
    13    144.8 MiB      0.0 MiB                           'num_epochs':pa.num_epochs,
    14    144.8 MiB      0.0 MiB                           'simu_len': pa.simu_len,
    15    144.8 MiB      0.0 MiB                           'num_ex':pa.num_ex,
    16    144.8 MiB      0.0 MiB                           'anomalous_job_rate':pa.anomalous_job_rate,
    17    144.8 MiB      0.0 MiB                           'output_freq':pa.output_freq,
    18    144.8 MiB      0.0 MiB                           'num_seq_per_batch':pa.num_seq_per_batch,
    19    144.8 MiB      0.0 MiB                           'episode_max_length':pa.episode_max_length,
    20    144.8 MiB      0.0 MiB                           'num_res':pa.num_res,
    21    144.8 MiB      0.0 MiB                           'num_nw':pa.num_nw,
    22    144.8 MiB      0.0 MiB                           'time_horizon':pa.time_horizon,
    23    144.8 MiB      0.0 MiB                           'max_job_len':pa.max_job_len,
    24    144.8 MiB      0.0 MiB                           'res_slot1':pa.res_slot1,
    25    144.8 MiB      0.0 MiB                           'res_slot2':pa.res_slot2,
    26    144.8 MiB      0.0 MiB                           'res_slot3':pa.res_slot3,
    27    144.8 MiB      0.0 MiB                           'max_job_size':pa.max_job_size,
    28    144.8 MiB      0.0 MiB                           'anomalous_job_len_upper_bound':pa.anomalous_job_len_upper_bound,
    29    144.8 MiB      0.0 MiB                           'anomalous_job_len-middle_bound': pa.anomalous_job_len_middle_bound,
    30    144.8 MiB      0.0 MiB                           'anomalous_job_len_lower_bound':pa.anomalous_job_len_lower_bound,
    31    144.8 MiB      0.0 MiB                           'anomalous_job_resources_upper':pa.anomalous_job_resources_upper,
    32    144.8 MiB      0.0 MiB                           'anomalous_job_resources_lower':pa.anomalous_job_resources_lower,
    33    144.8 MiB      0.0 MiB                           'backlog_size':pa.backlog_size,
    34    144.8 MiB      0.0 MiB                           'max_track_since_new':pa.max_track_since_new,
    35    144.8 MiB      0.0 MiB                           'job_num_cap':pa.job_num_cap,
    36    144.8 MiB      0.0 MiB                           'new_job_rate':pa.new_job_rate,
    37    144.8 MiB      0.0 MiB                           'discount':pa.discount,
    38    144.8 MiB      0.0 MiB                           'dist':pa.dist,
    39    144.8 MiB      0.0 MiB                           'backlog_width':pa.backlog_width,
    40    144.8 MiB      0.0 MiB                           'network_input_height':pa.network_input_height,
    41    144.8 MiB      0.0 MiB                           'network_input_width':pa.network_input_width,
    42    144.8 MiB      0.0 MiB                           'network_compact_dim':pa.network_compact_dim,
    43    144.8 MiB      0.0 MiB                           'network_output_dim':pa.network_output_dim,
    44    144.8 MiB      0.0 MiB                           'delay_penalty':pa.delay_penalty,
    45    144.8 MiB      0.0 MiB                           'hold_penalty':pa.hold_penalty,
    46    144.8 MiB      0.0 MiB                           'dismiss_penalty':pa.dismiss_penalty,
    47    144.8 MiB      0.0 MiB                           'num_frames':pa.num_frames,
    48    144.8 MiB      0.0 MiB                           'lr_rate':pa.lr_rate,
    49    144.8 MiB      0.0 MiB                           'rms_rho':pa.rms_rho,
    50    144.8 MiB      0.0 MiB                           'rms_eps':pa.rms_eps,
    51    144.8 MiB      0.0 MiB                           'unseen':pa.unseen,
    52    144.8 MiB      0.0 MiB                           'batch_size':pa.batch_size,
    53    144.8 MiB      0.0 MiB                           'evaluate_policy_name':pa.evaluate_policy_name 
    54                                                     }
    55                                             
    56    144.8 MiB      0.0 MiB                   with open('params.yaml', 'w') as file:
    57    144.8 MiB      0.0 MiB                           yaml.dump(parameters, file)


('rand val', 0.9507143064099162)
test2
('big job', 14)
('the random val for res', 0.5986584841970366)
('the resource vector req: ', array([1., 6.]))
('rand valx', 0.05808361216819946)
('anomalous job', 26)
('the random val for res', 0.6011150117432088)
('the resource vector req: ', array([7., 2.]))
('rand val', 0.7219987722668247)
('small job', 2)
('the random val for res', 0.0007787658410143283)
('the resource vector req: ', array([ 2., 11.]))
('rand val', 0.6116531604882809)
('small job', 1)
('the random val for res', 0.023062425041415757)
('the resource vector req: ', array([ 1., 13.]))
('rand valx', 0.04666566321361543)
('anomalous job', 21)
('the random val for res', 0.5142344384136116)
('the resource vector req: ', array([2., 5.]))
('rand val', 0.6075448519014384)
('small job', 1)
('the random val for res', 0.06505159298527952)
('the resource vector req: ', array([14.,  1.]))
('rand val', 0.8083973481164611)
test2
('big job', 12)
('the random val for res', 0.09767211400638387)
('the resource vector req: ', array([ 2., 14.]))
('rand valx', 0.12203823484477883)
('anomalous job', 26)
('the random val for res', 0.17336465350777208)
('the resource vector req: ', array([11.,  2.]))
('rand val', 0.7553614103176525)
test2
('big job', 17)
('the random val for res', 0.20794166286818883)
('the resource vector req: ', array([ 2., 12.]))
('rand val', 0.8422847745949985)
test2
('big job', 15)
('the random val for res', 0.3951502360018144)
('the resource vector req: ', array([ 2., 12.]))
('rand valx', 0.3265407688058354)
('anomalous job', 25)
('the random val for res', 0.045227288910538066)
('the resource vector req: ', array([ 2., 11.]))
('rand valx', 0.2713490317738959)
('anomalous job', 23)
('the random val for res', 0.3567533266935893)
('the resource vector req: ', array([ 2., 14.]))
('rand valx', 0.14092422497476265)
('anomalous job', 19)
('the random val for res', 0.9868869366005173)
('the resource vector req: ', array([5., 2.]))
('rand valx', 0.014079822715084456)
('anomalous job', 21)
('the random val for res', 0.71134195274865)
('the resource vector req: ', array([7., 1.]))
('rand val', 0.926300878513349)
test2
('big job', 13)
('the random val for res', 0.9149596755437808)
('the resource vector req: ', array([5., 2.]))
('rand valx', 0.09541011649041131)
('anomalous job', 25)
('the random val for res', 0.6688412526636073)
('the resource vector req: ', array([9., 1.]))
('rand valx', 0.27472179299006416)
('anomalous job', 21)
('the random val for res', 0.38292687475378984)
('the resource vector req: ', array([13.,  2.]))
('rand val', 0.7217295211648732)
('small job', 3)
('the random val for res', 0.25606832276132396)
('the resource vector req: ', array([13.,  1.]))
('rand valx', 0.11089082081183133)
('anomalous job', 21)
('the random val for res', 0.8957635956735194)
('the resource vector req: ', array([5., 2.]))
('rand val', 0.6955160864261275)
('small job', 1)
('the random val for res', 0.6044173792778172)
('the resource vector req: ', array([7., 1.]))
('rand valx', 0.07697990982879299)
('anomalous job', 21)
('the random val for res', 0.8804678390152577)
('the resource vector req: ', array([2., 9.]))
('rand valx', 0.10549425983027061)
('anomalous job', 22)
('the random val for res', 0.8832802589188683)
('the resource vector req: ', array([2., 6.]))
('rand valx', 0.3562978380769749)
('anomalous job', 19)
('the random val for res', 0.22793516254194168)
('the resource vector req: ', array([12.,  1.]))
('rand val', 0.8607305832563434)
test2
('big job', 18)
('the random val for res', 0.5107473025775657)
('the resource vector req: ', array([ 1., 10.]))
('rand valx', 0.1198653673336828)
('anomalous job', 26)
('the random val for res', 0.16829104217293056)
('the resource vector req: ', array([14.,  2.]))
Filename: /gpfs/home6/terhard/DeepRM_2/job_distribution.py

Line #    Mem usage    Increment   Line Contents
================================================
    96    144.8 MiB    144.8 MiB   @profile
    97                             def generate_sequence_work(pa, seed=42):
    98                             
    99    144.8 MiB      0.0 MiB       np.random.seed(seed)
   100                             
   101    144.8 MiB      0.0 MiB       simu_len = pa.simu_len * pa.num_ex
   102                             
   103    144.8 MiB      0.0 MiB       nw_dist = pa.dist.bi_model_dist
   104                             
   105    144.8 MiB      0.0 MiB       nw_anomalous_dist = pa.dist
   106                             
   107    144.8 MiB      0.0 MiB       nw_len_seq = np.zeros(simu_len, dtype=int)
   108    144.8 MiB      0.0 MiB       nw_size_seq = np.zeros((simu_len, pa.num_res), dtype=int)
   109                             
   110    144.9 MiB      0.0 MiB       for i in range(simu_len):
   111                             
   112    144.9 MiB      0.0 MiB           if np.random.rand() < pa.new_job_rate:  # a new job comes
   113                                         
   114    144.9 MiB      0.1 MiB               nw_len_seq[i], nw_size_seq[i, :] = nw_dist()
   115                                         #print('new job came ! ')
   116                             
   117    144.9 MiB      0.0 MiB       nw_len_seq = np.reshape(nw_len_seq,
   118    144.9 MiB      0.0 MiB                               [pa.num_ex, pa.simu_len])
   119    144.9 MiB      0.0 MiB       nw_size_seq = np.reshape(nw_size_seq,
   120    144.9 MiB      0.0 MiB                                [pa.num_ex, pa.simu_len, pa.num_res])
   121                             
   122    144.9 MiB      0.0 MiB       return nw_len_seq, nw_size_seq


('-prepare for env-', 0)
initialize the environment...
('-prepare for env-', 1)
initialize the environment...
('-prepare for env-', 2)
initialize the environment...
('-prepare for env-', 3)
initialize the environment...
('-prepare for env-', 4)
initialize the environment...
('-prepare for worker-', 0)
('Input layer shape: ', (None, 1, 30, 225))
('Conv1 layer shape: ', (None, 32, 28, 223))
('Pool1 layer shape: ', (None, 32, 14, 111))
('Conv2 layer shape: ', (None, 64, 12, 109))
('Pool2 layer shape: ', (None, 64, 6, 54))
('Hidden layer shape: ', (None, 128))
('Dropout layer shape: ', (None, 128))
('Output layer shape: ', (None, 16))
Filename: /gpfs/home6/terhard/DeepRM_2/pg_network.py

Line #    Mem usage    Increment   Line Contents
================================================
   247    145.5 MiB    145.5 MiB   @profile
   248                             def build_cnn_pg_network(input_height, input_width, output_length):
   249                                 
   250                                 # Input layer
   251    145.5 MiB      0.0 MiB       l_in = lasagne.layers.InputLayer(
   252    145.5 MiB      0.0 MiB           shape=(None, 1, input_height, input_width),
   253                                 )
   254                                 
   255    145.5 MiB      0.0 MiB       print("Input layer shape: ", l_in.output_shape)
   256                                 
   257                                 # First convolutional layer
   258    145.5 MiB      0.0 MiB       l_conv1 = lasagne.layers.Conv2DLayer(
   259    145.5 MiB      0.0 MiB           l_in,
   260    145.5 MiB      0.0 MiB           num_filters=32,
   261    145.5 MiB      0.0 MiB           filter_size=(3, 3),
   262    145.5 MiB      0.0 MiB           nonlinearity=lasagne.nonlinearities.rectify,
   263    145.5 MiB      0.0 MiB           W=lasagne.init.GlorotUniform()
   264                                 )
   265                                 
   266    145.5 MiB      0.0 MiB       print("Conv1 layer shape: ", l_conv1.output_shape)
   267                                 
   268                                 # Pooling layer
   269    145.5 MiB      0.0 MiB       l_pool1 = lasagne.layers.MaxPool2DLayer(l_conv1, pool_size=(2, 2))
   270                                 
   271    145.7 MiB      0.2 MiB       print("Pool1 layer shape: ",l_pool1.output_shape)
   272                                                                                             
   273                                 # Second convolutional layer
   274    145.7 MiB      0.0 MiB       l_conv2 = lasagne.layers.Conv2DLayer(
   275    145.7 MiB      0.0 MiB           l_pool1,
   276    145.7 MiB      0.0 MiB           num_filters=64,
   277    145.7 MiB      0.0 MiB           filter_size=(3, 3),
   278    145.7 MiB      0.0 MiB           nonlinearity=lasagne.nonlinearities.rectify
   279                                 )
   280                                 
   281    145.7 MiB      0.0 MiB       print("Conv2 layer shape: ", l_conv2.output_shape)
   282                                 
   283                                 # Pooling layer
   284    145.7 MiB      0.0 MiB       l_pool2 = lasagne.layers.MaxPool2DLayer(l_conv2, pool_size=(2, 2))
   285                                 
   286    145.7 MiB      0.0 MiB       print("Pool2 layer shape: ", l_pool2.output_shape) 
   287                                 
   288                                 # Fully connected layer
   289    145.7 MiB      0.0 MiB       l_hid = lasagne.layers.DenseLayer(
   290    145.7 MiB      0.0 MiB           l_pool2,
   291    145.7 MiB      0.0 MiB           num_units=128,
   292    145.7 MiB      0.0 MiB           nonlinearity=lasagne.nonlinearities.rectify,
   293    154.5 MiB      8.8 MiB           W=lasagne.init.GlorotUniform()
   294                                 )
   295                                 
   296    154.5 MiB      0.0 MiB       print("Hidden layer shape: ", l_hid.output_shape)
   297                                 
   298                                 # Dropout layer
   299    154.5 MiB      0.0 MiB       l_dropout = lasagne.layers.DropoutLayer(l_hid, p=0.5)
   300                                 
   301    154.5 MiB      0.0 MiB       print("Dropout layer shape: ", l_dropout.output_shape)
   302                                 
   303                                 # Output layer 
   304    154.5 MiB      0.0 MiB       l_out = lasagne.layers.DenseLayer(
   305    154.5 MiB      0.0 MiB           l_dropout,
   306    154.5 MiB      0.0 MiB           num_units=output_length,
   307    154.5 MiB      0.0 MiB           nonlinearity=lasagne.nonlinearities.softmax
   308                                 )
   309                                 
   310    154.5 MiB      0.0 MiB       print("Output layer shape: ", l_out.output_shape)
   311                                 
   312    154.5 MiB      0.0 MiB       return l_out


(' params=', [W, b, W, b, W, b, W, b], ' count=', 2675216)
/home/terhard/.conda/envs/py27/lib/python2.7/site-packages/lasagne/layers/conv.py:489: UserWarning: The `image_shape` keyword argument to `tensor.nnet.conv2d` is deprecated, it has been renamed to `input_shape`.
  border_mode=border_mode)
Filename: /gpfs/home6/terhard/DeepRM_2/pg_network.py

Line #    Mem usage    Increment   Line Contents
================================================
     7    165.0 MiB    165.0 MiB   @profile
     8                             def rmsprop_updates(grads, params, stepsize, rho=0.9, epsilon=1e-9):
     9                             
    10    165.0 MiB      0.0 MiB       updates = []
    11                             
    12    175.1 MiB      0.0 MiB       for param, grad in zip(params, grads):
    13    175.1 MiB      9.6 MiB           accum = theano.shared(np.zeros(param.get_value(borrow=True).shape, dtype=param.dtype))
    14                                     # print('thanos car thanos car', accum)
    15    175.1 MiB      0.2 MiB           accum_new = rho * accum + (1 - rho) * grad ** 2
    16                                     # print('thanos bus', accum_new)
    17    175.1 MiB      0.0 MiB           updates.append((accum, accum_new))
    18    175.1 MiB      0.0 MiB           updates.append((param, param + (stepsize * grad / T.sqrt(accum_new + epsilon))))
    19                                     # print('upadata,', updates)
    20                                     # lasagne has '-' after param
    21    175.1 MiB      0.0 MiB       return updates


Filename: /gpfs/home6/terhard/DeepRM_2/pg_network.py

Line #    Mem usage    Increment   Line Contents
================================================
    60    144.9 MiB    144.9 MiB       @profile
    61                                 def __init__(self, pa, use_cnn=True):
    62                             
    63    144.9 MiB      0.0 MiB           self.input_height = pa.network_input_height
    64    144.9 MiB      0.0 MiB           self.input_width = pa.network_input_width
    65    144.9 MiB      0.0 MiB           self.output_height = pa.network_output_dim
    66                             
    67    144.9 MiB      0.0 MiB           self.num_frames = pa.num_frames
    68                                     
    69    144.9 MiB      0.0 MiB           self.update_counter = 0
    70                             
    71    145.5 MiB      0.6 MiB           self.states = T.tensor4('states')
    72    145.5 MiB      0.0 MiB           self.actions = T.ivector('actions')
    73    145.5 MiB      0.0 MiB           self.values = T.vector('values')
    74                             
    75                                     # print 'network_input_height=', pa.network_input_height
    76                                     # print 'network_input_width=', pa.network_input_width
    77                                     # print 'network_output_dim=', pa.network_output_dim
    78                             
    79                                     # print("use_cnn is now set to:", use_cnn)
    80    145.5 MiB      0.0 MiB           if use_cnn:  # choose network based on use_cnn parameter
    81    154.5 MiB      9.0 MiB               self.l_out = build_cnn_pg_network(pa.network_input_height, pa.network_input_width, pa.network_output_dim)
    82                                     else:
    83                                         self.l_out = build_pg_network(pa.network_input_height, pa.network_input_width, pa.network_output_dim)
    84                                     
    85                                     # image representation
    86                                     # self.l_out = \
    87                                     #     build_pg_network(pa.network_input_height, pa.network_input_width, pa.network_output_dim)
    88                                     
    89                                     #self.l_out = \
    90                                      #   build_pg_network(pa.network_input_height, pa.network_input_width, pa.network_output_dim)
    91                             
    92                                     # compact representation
    93                                     #self.l_out = \
    94                                      #    build_compact_pg_network(pa.network_input_height, pa.network_input_width, pa.network_output_dim)
    95                             
    96    154.5 MiB      0.0 MiB           self.lr_rate = pa.lr_rate
    97    154.5 MiB      0.0 MiB           self.rms_rho = pa.rms_rho
    98    154.5 MiB      0.0 MiB           self.rms_eps = pa.rms_eps
    99                             
   100    154.5 MiB      0.0 MiB           params = lasagne.layers.helper.get_all_params(self.l_out)
   101    154.5 MiB      0.0 MiB           print(' params=', params, ' count=', lasagne.layers.count_params(self.l_out))
   102    159.6 MiB      5.1 MiB           self._get_param = theano.function([], params)
   103                             
   104                                     # ===================================
   105                                     # training function part
   106                                     # ===================================
   107                             
   108    162.0 MiB      2.4 MiB           prob_act = lasagne.layers.get_output(self.l_out, self.states)
   109    164.2 MiB      2.2 MiB           self._get_act_prob = theano.function([self.states], prob_act, allow_input_downcast=True)
   110                             
   111                                     # --------  Policy Gradient  --------
   112                             
   113    164.2 MiB      0.0 MiB           N = self.states.shape[0]
   114    164.3 MiB      0.0 MiB           loss = T.log(prob_act[T.arange(N), self.actions]).dot(self.values) / N  # call it "loss"
   115    165.0 MiB      0.7 MiB           grads = T.grad(loss, params)
   116    165.0 MiB      0.0 MiB           updates = rmsprop_updates(
   117    175.1 MiB     10.1 MiB               grads, params, self.lr_rate, self.rms_rho, self.rms_eps)
   118                             
   119                                     # updates = adam_update(
   120                                     #     grads, params, self.lr_rate)
   121                             
   122    175.1 MiB      0.0 MiB           self._train_fn = theano.function([self.states, self.actions, self.values], loss,
   123    182.7 MiB      7.6 MiB                                            updates=updates, allow_input_downcast=True)
   124    184.7 MiB      1.9 MiB           self._get_loss = theano.function([self.states, self.actions, self.values], loss, allow_input_downcast=True)
   125    188.5 MiB      3.9 MiB           self._get_grad = theano.function([self.states, self.actions, self.values], grads, allow_input_downcast=True)
   126                             
   127                                     # --------  Supervised Learning  --------
   128                             
   129    188.5 MiB      0.0 MiB           su_target = T.ivector('su_target')
   130    188.5 MiB      0.0 MiB           su_loss = lasagne.objectives.categorical_crossentropy(prob_act, su_target)
   131    188.5 MiB      0.0 MiB           su_loss = su_loss.mean()
   132    188.6 MiB      0.0 MiB           l2_penalty = lasagne.regularization.regularize_network_params(self.l_out, lasagne.regularization.l2)
   133                                     # l1_penalty = lasagne.regularization.regularize_network_params(self.l_out, lasagne.regularization.l1)
   134    188.6 MiB      0.0 MiB           su_loss += 1e-3*l2_penalty
   135                                     # print 'lr_rate=', self.lr_rate
   136    188.6 MiB      0.0 MiB           su_updates = lasagne.updates.rmsprop(su_loss, params,
   137    200.5 MiB     12.0 MiB                                                self.lr_rate, self.rms_rho, self.rms_eps)
   138                                     #su_updates = lasagne.updates.nesterov_momentum(su_loss, params, self.lr_rate)
   139    207.8 MiB      7.2 MiB           self._su_train_fn = theano.function([self.states, su_target], [su_loss, prob_act], updates=su_updates)
   140    210.0 MiB      2.2 MiB           self._su_loss = theano.function([self.states, su_target], [su_loss, prob_act])
   141    210.5 MiB      0.5 MiB           self._debug = theano.function([self.states], [self.states.flatten(2)])


('-prepare for worker-', 1)
('Input layer shape: ', (None, 1, 30, 225))
('Conv1 layer shape: ', (None, 32, 28, 223))
('Pool1 layer shape: ', (None, 32, 14, 111))
('Conv2 layer shape: ', (None, 64, 12, 109))
('Pool2 layer shape: ', (None, 64, 6, 54))
('Hidden layer shape: ', (None, 128))
('Dropout layer shape: ', (None, 128))
('Output layer shape: ', (None, 16))
Filename: /gpfs/home6/terhard/DeepRM_2/pg_network.py

Line #    Mem usage    Increment   Line Contents
================================================
   247    210.5 MiB    210.5 MiB   @profile
   248                             def build_cnn_pg_network(input_height, input_width, output_length):
   249                                 
   250                                 # Input layer
   251    210.5 MiB      0.0 MiB       l_in = lasagne.layers.InputLayer(
   252    210.5 MiB      0.0 MiB           shape=(None, 1, input_height, input_width),
   253                                 )
   254                                 
   255    210.5 MiB      0.0 MiB       print("Input layer shape: ", l_in.output_shape)
   256                                 
   257                                 # First convolutional layer
   258    210.5 MiB      0.0 MiB       l_conv1 = lasagne.layers.Conv2DLayer(
   259    210.5 MiB      0.0 MiB           l_in,
   260    210.5 MiB      0.0 MiB           num_filters=32,
   261    210.5 MiB      0.0 MiB           filter_size=(3, 3),
   262    210.5 MiB      0.0 MiB           nonlinearity=lasagne.nonlinearities.rectify,
   263    210.5 MiB      0.0 MiB           W=lasagne.init.GlorotUniform()
   264                                 )
   265                                 
   266    210.5 MiB      0.0 MiB       print("Conv1 layer shape: ", l_conv1.output_shape)
   267                                 
   268                                 # Pooling layer
   269    210.5 MiB      0.0 MiB       l_pool1 = lasagne.layers.MaxPool2DLayer(l_conv1, pool_size=(2, 2))
   270                                 
   271    210.5 MiB      0.0 MiB       print("Pool1 layer shape: ",l_pool1.output_shape)
   272                                                                                             
   273                                 # Second convolutional layer
   274    210.5 MiB      0.0 MiB       l_conv2 = lasagne.layers.Conv2DLayer(
   275    210.5 MiB      0.0 MiB           l_pool1,
   276    210.5 MiB      0.0 MiB           num_filters=64,
   277    210.5 MiB      0.0 MiB           filter_size=(3, 3),
   278    210.5 MiB      0.0 MiB           nonlinearity=lasagne.nonlinearities.rectify
   279                                 )
   280                                 
   281    210.5 MiB      0.0 MiB       print("Conv2 layer shape: ", l_conv2.output_shape)
   282                                 
   283                                 # Pooling layer
   284    210.5 MiB      0.0 MiB       l_pool2 = lasagne.layers.MaxPool2DLayer(l_conv2, pool_size=(2, 2))
   285                                 
   286    210.5 MiB      0.0 MiB       print("Pool2 layer shape: ", l_pool2.output_shape) 
   287                                 
   288                                 # Fully connected layer
   289    210.5 MiB      0.0 MiB       l_hid = lasagne.layers.DenseLayer(
   290    210.5 MiB      0.0 MiB           l_pool2,
   291    210.5 MiB      0.0 MiB           num_units=128,
   292    210.5 MiB      0.0 MiB           nonlinearity=lasagne.nonlinearities.rectify,
   293    240.9 MiB     30.4 MiB           W=lasagne.init.GlorotUniform()
   294                                 )
   295                                 
   296    240.9 MiB      0.0 MiB       print("Hidden layer shape: ", l_hid.output_shape)
   297                                 
   298                                 # Dropout layer
   299    240.9 MiB      0.0 MiB       l_dropout = lasagne.layers.DropoutLayer(l_hid, p=0.5)
   300                                 
   301    240.9 MiB      0.0 MiB       print("Dropout layer shape: ", l_dropout.output_shape)
   302                                 
   303                                 # Output layer 
   304    240.9 MiB      0.0 MiB       l_out = lasagne.layers.DenseLayer(
   305    240.9 MiB      0.0 MiB           l_dropout,
   306    240.9 MiB      0.0 MiB           num_units=output_length,
   307    240.9 MiB      0.0 MiB           nonlinearity=lasagne.nonlinearities.softmax
   308                                 )
   309                                 
   310    240.9 MiB      0.0 MiB       print("Output layer shape: ", l_out.output_shape)
   311                                 
   312    240.9 MiB      0.0 MiB       return l_out


(' params=', [W, b, W, b, W, b, W, b], ' count=', 2675216)
Filename: /gpfs/home6/terhard/DeepRM_2/pg_network.py

Line #    Mem usage    Increment   Line Contents
================================================
     7    242.9 MiB    242.9 MiB   @profile
     8                             def rmsprop_updates(grads, params, stepsize, rho=0.9, epsilon=1e-9):
     9                             
    10    242.9 MiB      0.0 MiB       updates = []
    11                             
    12    253.2 MiB      0.0 MiB       for param, grad in zip(params, grads):
    13    253.2 MiB      9.9 MiB           accum = theano.shared(np.zeros(param.get_value(borrow=True).shape, dtype=param.dtype))
    14                                     # print('thanos car thanos car', accum)
    15    253.2 MiB      0.0 MiB           accum_new = rho * accum + (1 - rho) * grad ** 2
    16                                     # print('thanos bus', accum_new)
    17    253.2 MiB      0.0 MiB           updates.append((accum, accum_new))
    18    253.2 MiB      0.2 MiB           updates.append((param, param + (stepsize * grad / T.sqrt(accum_new + epsilon))))
    19                                     # print('upadata,', updates)
    20                                     # lasagne has '-' after param
    21    253.2 MiB      0.0 MiB       return updates


Filename: /gpfs/home6/terhard/DeepRM_2/pg_network.py

Line #    Mem usage    Increment   Line Contents
================================================
    60    210.5 MiB    210.5 MiB       @profile
    61                                 def __init__(self, pa, use_cnn=True):
    62                             
    63    210.5 MiB      0.0 MiB           self.input_height = pa.network_input_height
    64    210.5 MiB      0.0 MiB           self.input_width = pa.network_input_width
    65    210.5 MiB      0.0 MiB           self.output_height = pa.network_output_dim
    66                             
    67    210.5 MiB      0.0 MiB           self.num_frames = pa.num_frames
    68                                     
    69    210.5 MiB      0.0 MiB           self.update_counter = 0
    70                             
    71    210.5 MiB      0.0 MiB           self.states = T.tensor4('states')
    72    210.5 MiB      0.0 MiB           self.actions = T.ivector('actions')
    73    210.5 MiB      0.0 MiB           self.values = T.vector('values')
    74                             
    75                                     # print 'network_input_height=', pa.network_input_height
    76                                     # print 'network_input_width=', pa.network_input_width
    77                                     # print 'network_output_dim=', pa.network_output_dim
    78                             
    79                                     # print("use_cnn is now set to:", use_cnn)
    80    210.5 MiB      0.0 MiB           if use_cnn:  # choose network based on use_cnn parameter
    81    240.9 MiB     30.4 MiB               self.l_out = build_cnn_pg_network(pa.network_input_height, pa.network_input_width, pa.network_output_dim)
    82                                     else:
    83                                         self.l_out = build_pg_network(pa.network_input_height, pa.network_input_width, pa.network_output_dim)
    84                                     
    85                                     # image representation
    86                                     # self.l_out = \
    87                                     #     build_pg_network(pa.network_input_height, pa.network_input_width, pa.network_output_dim)
    88                                     
    89                                     #self.l_out = \
    90                                      #   build_pg_network(pa.network_input_height, pa.network_input_width, pa.network_output_dim)
    91                             
    92                                     # compact representation
    93                                     #self.l_out = \
    94                                      #    build_compact_pg_network(pa.network_input_height, pa.network_input_width, pa.network_output_dim)
    95                             
    96    240.9 MiB      0.0 MiB           self.lr_rate = pa.lr_rate
    97    240.9 MiB      0.0 MiB           self.rms_rho = pa.rms_rho
    98    240.9 MiB      0.0 MiB           self.rms_eps = pa.rms_eps
    99                             
   100    240.9 MiB      0.0 MiB           params = lasagne.layers.helper.get_all_params(self.l_out)
   101    240.9 MiB      0.0 MiB           print(' params=', params, ' count=', lasagne.layers.count_params(self.l_out))
   102    241.0 MiB      0.1 MiB           self._get_param = theano.function([], params)
   103                             
   104                                     # ===================================
   105                                     # training function part
   106                                     # ===================================
   107                             
   108    241.4 MiB      0.3 MiB           prob_act = lasagne.layers.get_output(self.l_out, self.states)
   109    242.1 MiB      0.7 MiB           self._get_act_prob = theano.function([self.states], prob_act, allow_input_downcast=True)
   110                             
   111                                     # --------  Policy Gradient  --------
   112                             
   113    242.1 MiB      0.0 MiB           N = self.states.shape[0]
   114    242.1 MiB      0.0 MiB           loss = T.log(prob_act[T.arange(N), self.actions]).dot(self.values) / N  # call it "loss"
   115    242.7 MiB      0.6 MiB           grads = T.grad(loss, params)
   116    242.7 MiB      0.0 MiB           updates = rmsprop_updates(
   117    253.2 MiB     10.5 MiB               grads, params, self.lr_rate, self.rms_rho, self.rms_eps)
   118                             
   119                                     # updates = adam_update(
   120                                     #     grads, params, self.lr_rate)
   121                             
   122    253.2 MiB      0.0 MiB           self._train_fn = theano.function([self.states, self.actions, self.values], loss,
   123    259.9 MiB      6.7 MiB                                            updates=updates, allow_input_downcast=True)
   124    262.1 MiB      2.2 MiB           self._get_loss = theano.function([self.states, self.actions, self.values], loss, allow_input_downcast=True)
   125    265.5 MiB      3.4 MiB           self._get_grad = theano.function([self.states, self.actions, self.values], grads, allow_input_downcast=True)
   126                             
   127                                     # --------  Supervised Learning  --------
   128                             
   129    265.5 MiB      0.0 MiB           su_target = T.ivector('su_target')
   130    265.5 MiB      0.0 MiB           su_loss = lasagne.objectives.categorical_crossentropy(prob_act, su_target)
   131    265.5 MiB      0.0 MiB           su_loss = su_loss.mean()
   132    265.5 MiB      0.0 MiB           l2_penalty = lasagne.regularization.regularize_network_params(self.l_out, lasagne.regularization.l2)
   133                                     # l1_penalty = lasagne.regularization.regularize_network_params(self.l_out, lasagne.regularization.l1)
   134    265.5 MiB      0.0 MiB           su_loss += 1e-3*l2_penalty
   135                                     # print 'lr_rate=', self.lr_rate
   136    265.5 MiB      0.0 MiB           su_updates = lasagne.updates.rmsprop(su_loss, params,
   137    276.4 MiB     10.9 MiB                                                self.lr_rate, self.rms_rho, self.rms_eps)
   138                                     #su_updates = lasagne.updates.nesterov_momentum(su_loss, params, self.lr_rate)
   139    284.2 MiB      7.7 MiB           self._su_train_fn = theano.function([self.states, su_target], [su_loss, prob_act], updates=su_updates)
   140    285.6 MiB      1.4 MiB           self._su_loss = theano.function([self.states, su_target], [su_loss, prob_act])
   141    286.1 MiB      0.5 MiB           self._debug = theano.function([self.states], [self.states.flatten(2)])


('-prepare for worker-', 2)
('Input layer shape: ', (None, 1, 30, 225))
('Conv1 layer shape: ', (None, 32, 28, 223))
('Pool1 layer shape: ', (None, 32, 14, 111))
('Conv2 layer shape: ', (None, 64, 12, 109))
('Pool2 layer shape: ', (None, 64, 6, 54))
('Hidden layer shape: ', (None, 128))
('Dropout layer shape: ', (None, 128))
('Output layer shape: ', (None, 16))
Filename: /gpfs/home6/terhard/DeepRM_2/pg_network.py

Line #    Mem usage    Increment   Line Contents
================================================
   247    286.1 MiB    286.1 MiB   @profile
   248                             def build_cnn_pg_network(input_height, input_width, output_length):
   249                                 
   250                                 # Input layer
   251    286.1 MiB      0.0 MiB       l_in = lasagne.layers.InputLayer(
   252    286.1 MiB      0.0 MiB           shape=(None, 1, input_height, input_width),
   253                                 )
   254                                 
   255    286.1 MiB      0.0 MiB       print("Input layer shape: ", l_in.output_shape)
   256                                 
   257                                 # First convolutional layer
   258    286.1 MiB      0.0 MiB       l_conv1 = lasagne.layers.Conv2DLayer(
   259    286.1 MiB      0.0 MiB           l_in,
   260    286.1 MiB      0.0 MiB           num_filters=32,
   261    286.1 MiB      0.0 MiB           filter_size=(3, 3),
   262    286.1 MiB      0.0 MiB           nonlinearity=lasagne.nonlinearities.rectify,
   263    286.1 MiB      0.0 MiB           W=lasagne.init.GlorotUniform()
   264                                 )
   265                                 
   266    286.1 MiB      0.0 MiB       print("Conv1 layer shape: ", l_conv1.output_shape)
   267                                 
   268                                 # Pooling layer
   269    286.1 MiB      0.0 MiB       l_pool1 = lasagne.layers.MaxPool2DLayer(l_conv1, pool_size=(2, 2))
   270                                 
   271    286.1 MiB      0.0 MiB       print("Pool1 layer shape: ",l_pool1.output_shape)
   272                                                                                             
   273                                 # Second convolutional layer
   274    286.1 MiB      0.0 MiB       l_conv2 = lasagne.layers.Conv2DLayer(
   275    286.1 MiB      0.0 MiB           l_pool1,
   276    286.1 MiB      0.0 MiB           num_filters=64,
   277    286.1 MiB      0.0 MiB           filter_size=(3, 3),
   278    286.1 MiB      0.0 MiB           nonlinearity=lasagne.nonlinearities.rectify
   279                                 )
   280                                 
   281    286.1 MiB      0.0 MiB       print("Conv2 layer shape: ", l_conv2.output_shape)
   282                                 
   283                                 # Pooling layer
   284    286.1 MiB      0.0 MiB       l_pool2 = lasagne.layers.MaxPool2DLayer(l_conv2, pool_size=(2, 2))
   285                                 
   286    286.1 MiB      0.0 MiB       print("Pool2 layer shape: ", l_pool2.output_shape) 
   287                                 
   288                                 # Fully connected layer
   289    286.1 MiB      0.0 MiB       l_hid = lasagne.layers.DenseLayer(
   290    286.1 MiB      0.0 MiB           l_pool2,
   291    286.1 MiB      0.0 MiB           num_units=128,
   292    286.1 MiB      0.0 MiB           nonlinearity=lasagne.nonlinearities.rectify,
   293    316.4 MiB     30.3 MiB           W=lasagne.init.GlorotUniform()
   294                                 )
   295                                 
   296    316.4 MiB      0.0 MiB       print("Hidden layer shape: ", l_hid.output_shape)
   297                                 
   298                                 # Dropout layer
   299    316.4 MiB      0.0 MiB       l_dropout = lasagne.layers.DropoutLayer(l_hid, p=0.5)
   300                                 
   301    316.4 MiB      0.0 MiB       print("Dropout layer shape: ", l_dropout.output_shape)
   302                                 
   303                                 # Output layer 
   304    316.4 MiB      0.0 MiB       l_out = lasagne.layers.DenseLayer(
   305    316.4 MiB      0.0 MiB           l_dropout,
   306    316.4 MiB      0.0 MiB           num_units=output_length,
   307    316.4 MiB      0.0 MiB           nonlinearity=lasagne.nonlinearities.softmax
   308                                 )
   309                                 
   310    316.4 MiB      0.0 MiB       print("Output layer shape: ", l_out.output_shape)
   311                                 
   312    316.4 MiB      0.0 MiB       return l_out


(' params=', [W, b, W, b, W, b, W, b], ' count=', 2675216)
Filename: /gpfs/home6/terhard/DeepRM_2/pg_network.py

Line #    Mem usage    Increment   Line Contents
================================================
     7    319.3 MiB    319.3 MiB   @profile
     8                             def rmsprop_updates(grads, params, stepsize, rho=0.9, epsilon=1e-9):
     9                             
    10    319.3 MiB      0.0 MiB       updates = []
    11                             
    12    329.9 MiB      0.0 MiB       for param, grad in zip(params, grads):
    13    329.9 MiB     10.3 MiB           accum = theano.shared(np.zeros(param.get_value(borrow=True).shape, dtype=param.dtype))
    14                                     # print('thanos car thanos car', accum)
    15    329.9 MiB      0.2 MiB           accum_new = rho * accum + (1 - rho) * grad ** 2
    16                                     # print('thanos bus', accum_new)
    17    329.9 MiB      0.0 MiB           updates.append((accum, accum_new))
    18    329.9 MiB      0.1 MiB           updates.append((param, param + (stepsize * grad / T.sqrt(accum_new + epsilon))))
    19                                     # print('upadata,', updates)
    20                                     # lasagne has '-' after param
    21    329.9 MiB      0.0 MiB       return updates


Filename: /gpfs/home6/terhard/DeepRM_2/pg_network.py

Line #    Mem usage    Increment   Line Contents
================================================
    60    286.1 MiB    286.1 MiB       @profile
    61                                 def __init__(self, pa, use_cnn=True):
    62                             
    63    286.1 MiB      0.0 MiB           self.input_height = pa.network_input_height
    64    286.1 MiB      0.0 MiB           self.input_width = pa.network_input_width
    65    286.1 MiB      0.0 MiB           self.output_height = pa.network_output_dim
    66                             
    67    286.1 MiB      0.0 MiB           self.num_frames = pa.num_frames
    68                                     
    69    286.1 MiB      0.0 MiB           self.update_counter = 0
    70                             
    71    286.1 MiB      0.0 MiB           self.states = T.tensor4('states')
    72    286.1 MiB      0.0 MiB           self.actions = T.ivector('actions')
    73    286.1 MiB      0.0 MiB           self.values = T.vector('values')
    74                             
    75                                     # print 'network_input_height=', pa.network_input_height
    76                                     # print 'network_input_width=', pa.network_input_width
    77                                     # print 'network_output_dim=', pa.network_output_dim
    78                             
    79                                     # print("use_cnn is now set to:", use_cnn)
    80    286.1 MiB      0.0 MiB           if use_cnn:  # choose network based on use_cnn parameter
    81    316.4 MiB     30.3 MiB               self.l_out = build_cnn_pg_network(pa.network_input_height, pa.network_input_width, pa.network_output_dim)
    82                                     else:
    83                                         self.l_out = build_pg_network(pa.network_input_height, pa.network_input_width, pa.network_output_dim)
    84                                     
    85                                     # image representation
    86                                     # self.l_out = \
    87                                     #     build_pg_network(pa.network_input_height, pa.network_input_width, pa.network_output_dim)
    88                                     
    89                                     #self.l_out = \
    90                                      #   build_pg_network(pa.network_input_height, pa.network_input_width, pa.network_output_dim)
    91                             
    92                                     # compact representation
    93                                     #self.l_out = \
    94                                      #    build_compact_pg_network(pa.network_input_height, pa.network_input_width, pa.network_output_dim)
    95                             
    96    316.4 MiB      0.0 MiB           self.lr_rate = pa.lr_rate
    97    316.4 MiB      0.0 MiB           self.rms_rho = pa.rms_rho
    98    316.4 MiB      0.0 MiB           self.rms_eps = pa.rms_eps
    99                             
   100    316.4 MiB      0.0 MiB           params = lasagne.layers.helper.get_all_params(self.l_out)
   101    316.4 MiB      0.0 MiB           print(' params=', params, ' count=', lasagne.layers.count_params(self.l_out))
   102    316.6 MiB      0.2 MiB           self._get_param = theano.function([], params)
   103                             
   104                                     # ===================================
   105                                     # training function part
   106                                     # ===================================
   107                             
   108    316.9 MiB      0.2 MiB           prob_act = lasagne.layers.get_output(self.l_out, self.states)
   109    318.7 MiB      1.9 MiB           self._get_act_prob = theano.function([self.states], prob_act, allow_input_downcast=True)
   110                             
   111                                     # --------  Policy Gradient  --------
   112                             
   113    318.7 MiB      0.0 MiB           N = self.states.shape[0]
   114    318.7 MiB      0.0 MiB           loss = T.log(prob_act[T.arange(N), self.actions]).dot(self.values) / N  # call it "loss"
   115    319.3 MiB      0.5 MiB           grads = T.grad(loss, params)
   116    319.3 MiB      0.0 MiB           updates = rmsprop_updates(
   117    329.9 MiB     10.6 MiB               grads, params, self.lr_rate, self.rms_rho, self.rms_eps)
   118                             
   119                                     # updates = adam_update(
   120                                     #     grads, params, self.lr_rate)
   121                             
   122    329.9 MiB      0.0 MiB           self._train_fn = theano.function([self.states, self.actions, self.values], loss,
   123    336.6 MiB      6.7 MiB                                            updates=updates, allow_input_downcast=True)
   124    338.6 MiB      2.1 MiB           self._get_loss = theano.function([self.states, self.actions, self.values], loss, allow_input_downcast=True)
   125    341.4 MiB      2.8 MiB           self._get_grad = theano.function([self.states, self.actions, self.values], grads, allow_input_downcast=True)
   126                             
   127                                     # --------  Supervised Learning  --------
   128                             
   129    341.4 MiB      0.0 MiB           su_target = T.ivector('su_target')
   130    341.4 MiB      0.0 MiB           su_loss = lasagne.objectives.categorical_crossentropy(prob_act, su_target)
   131    341.4 MiB      0.0 MiB           su_loss = su_loss.mean()
   132    341.4 MiB      0.0 MiB           l2_penalty = lasagne.regularization.regularize_network_params(self.l_out, lasagne.regularization.l2)
   133                                     # l1_penalty = lasagne.regularization.regularize_network_params(self.l_out, lasagne.regularization.l1)
   134    341.4 MiB      0.0 MiB           su_loss += 1e-3*l2_penalty
   135                                     # print 'lr_rate=', self.lr_rate
   136    341.4 MiB      0.0 MiB           su_updates = lasagne.updates.rmsprop(su_loss, params,
   137    352.6 MiB     11.3 MiB                                                self.lr_rate, self.rms_rho, self.rms_eps)
   138                                     #su_updates = lasagne.updates.nesterov_momentum(su_loss, params, self.lr_rate)
   139    360.2 MiB      7.6 MiB           self._su_train_fn = theano.function([self.states, su_target], [su_loss, prob_act], updates=su_updates)
   140    362.2 MiB      2.0 MiB           self._su_loss = theano.function([self.states, su_target], [su_loss, prob_act])
   141    362.9 MiB      0.6 MiB           self._debug = theano.function([self.states], [self.states.flatten(2)])


('-prepare for worker-', 3)
('Input layer shape: ', (None, 1, 30, 225))
('Conv1 layer shape: ', (None, 32, 28, 223))
('Pool1 layer shape: ', (None, 32, 14, 111))
('Conv2 layer shape: ', (None, 64, 12, 109))
('Pool2 layer shape: ', (None, 64, 6, 54))
('Hidden layer shape: ', (None, 128))
('Dropout layer shape: ', (None, 128))
('Output layer shape: ', (None, 16))
Filename: /gpfs/home6/terhard/DeepRM_2/pg_network.py

Line #    Mem usage    Increment   Line Contents
================================================
   247    362.9 MiB    362.9 MiB   @profile
   248                             def build_cnn_pg_network(input_height, input_width, output_length):
   249                                 
   250                                 # Input layer
   251    362.9 MiB      0.0 MiB       l_in = lasagne.layers.InputLayer(
   252    362.9 MiB      0.0 MiB           shape=(None, 1, input_height, input_width),
   253                                 )
   254                                 
   255    362.9 MiB      0.0 MiB       print("Input layer shape: ", l_in.output_shape)
   256                                 
   257                                 # First convolutional layer
   258    362.9 MiB      0.0 MiB       l_conv1 = lasagne.layers.Conv2DLayer(
   259    362.9 MiB      0.0 MiB           l_in,
   260    362.9 MiB      0.0 MiB           num_filters=32,
   261    362.9 MiB      0.0 MiB           filter_size=(3, 3),
   262    362.9 MiB      0.0 MiB           nonlinearity=lasagne.nonlinearities.rectify,
   263    362.9 MiB      0.0 MiB           W=lasagne.init.GlorotUniform()
   264                                 )
   265                                 
   266    362.9 MiB      0.0 MiB       print("Conv1 layer shape: ", l_conv1.output_shape)
   267                                 
   268                                 # Pooling layer
   269    362.9 MiB      0.0 MiB       l_pool1 = lasagne.layers.MaxPool2DLayer(l_conv1, pool_size=(2, 2))
   270                                 
   271    362.9 MiB      0.0 MiB       print("Pool1 layer shape: ",l_pool1.output_shape)
   272                                                                                             
   273                                 # Second convolutional layer
   274    362.9 MiB      0.0 MiB       l_conv2 = lasagne.layers.Conv2DLayer(
   275    362.9 MiB      0.0 MiB           l_pool1,
   276    362.9 MiB      0.0 MiB           num_filters=64,
   277    362.9 MiB      0.0 MiB           filter_size=(3, 3),
   278    362.9 MiB      0.0 MiB           nonlinearity=lasagne.nonlinearities.rectify
   279                                 )
   280                                 
   281    362.9 MiB      0.0 MiB       print("Conv2 layer shape: ", l_conv2.output_shape)
   282                                 
   283                                 # Pooling layer
   284    362.9 MiB      0.0 MiB       l_pool2 = lasagne.layers.MaxPool2DLayer(l_conv2, pool_size=(2, 2))
   285                                 
   286    362.9 MiB      0.0 MiB       print("Pool2 layer shape: ", l_pool2.output_shape) 
   287                                 
   288                                 # Fully connected layer
   289    362.9 MiB      0.0 MiB       l_hid = lasagne.layers.DenseLayer(
   290    362.9 MiB      0.0 MiB           l_pool2,
   291    362.9 MiB      0.0 MiB           num_units=128,
   292    362.9 MiB      0.0 MiB           nonlinearity=lasagne.nonlinearities.rectify,
   293    393.4 MiB     30.5 MiB           W=lasagne.init.GlorotUniform()
   294                                 )
   295                                 
   296    393.4 MiB      0.0 MiB       print("Hidden layer shape: ", l_hid.output_shape)
   297                                 
   298                                 # Dropout layer
   299    393.5 MiB      0.1 MiB       l_dropout = lasagne.layers.DropoutLayer(l_hid, p=0.5)
   300                                 
   301    393.5 MiB      0.0 MiB       print("Dropout layer shape: ", l_dropout.output_shape)
   302                                 
   303                                 # Output layer 
   304    393.5 MiB      0.0 MiB       l_out = lasagne.layers.DenseLayer(
   305    393.5 MiB      0.0 MiB           l_dropout,
   306    393.5 MiB      0.0 MiB           num_units=output_length,
   307    393.5 MiB      0.0 MiB           nonlinearity=lasagne.nonlinearities.softmax
   308                                 )
   309                                 
   310    393.5 MiB      0.0 MiB       print("Output layer shape: ", l_out.output_shape)
   311                                 
   312    393.5 MiB      0.0 MiB       return l_out


(' params=', [W, b, W, b, W, b, W, b], ' count=', 2675216)
Filename: /gpfs/home6/terhard/DeepRM_2/pg_network.py

Line #    Mem usage    Increment   Line Contents
================================================
     7    396.3 MiB    396.3 MiB   @profile
     8                             def rmsprop_updates(grads, params, stepsize, rho=0.9, epsilon=1e-9):
     9                             
    10    396.3 MiB      0.0 MiB       updates = []
    11                             
    12    396.7 MiB      0.0 MiB       for param, grad in zip(params, grads):
    13    396.7 MiB      0.1 MiB           accum = theano.shared(np.zeros(param.get_value(borrow=True).shape, dtype=param.dtype))
    14                                     # print('thanos car thanos car', accum)
    15    396.7 MiB      0.2 MiB           accum_new = rho * accum + (1 - rho) * grad ** 2
    16                                     # print('thanos bus', accum_new)
    17    396.7 MiB      0.0 MiB           updates.append((accum, accum_new))
    18    396.7 MiB      0.1 MiB           updates.append((param, param + (stepsize * grad / T.sqrt(accum_new + epsilon))))
    19                                     # print('upadata,', updates)
    20                                     # lasagne has '-' after param
    21    396.7 MiB      0.0 MiB       return updates


Filename: /gpfs/home6/terhard/DeepRM_2/pg_network.py

Line #    Mem usage    Increment   Line Contents
================================================
    60    362.9 MiB    362.9 MiB       @profile
    61                                 def __init__(self, pa, use_cnn=True):
    62                             
    63    362.9 MiB      0.0 MiB           self.input_height = pa.network_input_height
    64    362.9 MiB      0.0 MiB           self.input_width = pa.network_input_width
    65    362.9 MiB      0.0 MiB           self.output_height = pa.network_output_dim
    66                             
    67    362.9 MiB      0.0 MiB           self.num_frames = pa.num_frames
    68                                     
    69    362.9 MiB      0.0 MiB           self.update_counter = 0
    70                             
    71    362.9 MiB      0.0 MiB           self.states = T.tensor4('states')
    72    362.9 MiB      0.0 MiB           self.actions = T.ivector('actions')
    73    362.9 MiB      0.0 MiB           self.values = T.vector('values')
    74                             
    75                                     # print 'network_input_height=', pa.network_input_height
    76                                     # print 'network_input_width=', pa.network_input_width
    77                                     # print 'network_output_dim=', pa.network_output_dim
    78                             
    79                                     # print("use_cnn is now set to:", use_cnn)
    80    362.9 MiB      0.0 MiB           if use_cnn:  # choose network based on use_cnn parameter
    81    393.5 MiB     30.6 MiB               self.l_out = build_cnn_pg_network(pa.network_input_height, pa.network_input_width, pa.network_output_dim)
    82                                     else:
    83                                         self.l_out = build_pg_network(pa.network_input_height, pa.network_input_width, pa.network_output_dim)
    84                                     
    85                                     # image representation
    86                                     # self.l_out = \
    87                                     #     build_pg_network(pa.network_input_height, pa.network_input_width, pa.network_output_dim)
    88                                     
    89                                     #self.l_out = \
    90                                      #   build_pg_network(pa.network_input_height, pa.network_input_width, pa.network_output_dim)
    91                             
    92                                     # compact representation
    93                                     #self.l_out = \
    94                                      #    build_compact_pg_network(pa.network_input_height, pa.network_input_width, pa.network_output_dim)
    95                             
    96    393.5 MiB      0.0 MiB           self.lr_rate = pa.lr_rate
    97    393.5 MiB      0.0 MiB           self.rms_rho = pa.rms_rho
    98    393.5 MiB      0.0 MiB           self.rms_eps = pa.rms_eps
    99                             
   100    393.5 MiB      0.0 MiB           params = lasagne.layers.helper.get_all_params(self.l_out)
   101    393.5 MiB      0.0 MiB           print(' params=', params, ' count=', lasagne.layers.count_params(self.l_out))
   102    393.7 MiB      0.2 MiB           self._get_param = theano.function([], params)
   103                             
   104                                     # ===================================
   105                                     # training function part
   106                                     # ===================================
   107                             
   108    393.9 MiB      0.2 MiB           prob_act = lasagne.layers.get_output(self.l_out, self.states)
   109    395.6 MiB      1.8 MiB           self._get_act_prob = theano.function([self.states], prob_act, allow_input_downcast=True)
   110                             
   111                                     # --------  Policy Gradient  --------
   112                             
   113    395.6 MiB      0.0 MiB           N = self.states.shape[0]
   114    395.6 MiB      0.0 MiB           loss = T.log(prob_act[T.arange(N), self.actions]).dot(self.values) / N  # call it "loss"
   115    396.3 MiB      0.6 MiB           grads = T.grad(loss, params)
   116    396.3 MiB      0.0 MiB           updates = rmsprop_updates(
   117    396.7 MiB      0.4 MiB               grads, params, self.lr_rate, self.rms_rho, self.rms_eps)
   118                             
   119                                     # updates = adam_update(
   120                                     #     grads, params, self.lr_rate)
   121                             
   122    396.7 MiB      0.0 MiB           self._train_fn = theano.function([self.states, self.actions, self.values], loss,
   123    401.8 MiB      5.2 MiB                                            updates=updates, allow_input_downcast=True)
   124    403.9 MiB      2.1 MiB           self._get_loss = theano.function([self.states, self.actions, self.values], loss, allow_input_downcast=True)
   125    407.6 MiB      3.6 MiB           self._get_grad = theano.function([self.states, self.actions, self.values], grads, allow_input_downcast=True)
   126                             
   127                                     # --------  Supervised Learning  --------
   128                             
   129    407.6 MiB      0.0 MiB           su_target = T.ivector('su_target')
   130    407.6 MiB      0.0 MiB           su_loss = lasagne.objectives.categorical_crossentropy(prob_act, su_target)
   131    407.8 MiB      0.2 MiB           su_loss = su_loss.mean()
   132    407.8 MiB      0.0 MiB           l2_penalty = lasagne.regularization.regularize_network_params(self.l_out, lasagne.regularization.l2)
   133                                     # l1_penalty = lasagne.regularization.regularize_network_params(self.l_out, lasagne.regularization.l1)
   134    407.8 MiB      0.0 MiB           su_loss += 1e-3*l2_penalty
   135                                     # print 'lr_rate=', self.lr_rate
   136    407.8 MiB      0.1 MiB           su_updates = lasagne.updates.rmsprop(su_loss, params,
   137    418.9 MiB     11.1 MiB                                                self.lr_rate, self.rms_rho, self.rms_eps)
   138                                     #su_updates = lasagne.updates.nesterov_momentum(su_loss, params, self.lr_rate)
   139    426.4 MiB      7.5 MiB           self._su_train_fn = theano.function([self.states, su_target], [su_loss, prob_act], updates=su_updates)
   140    428.6 MiB      2.2 MiB           self._su_loss = theano.function([self.states, su_target], [su_loss, prob_act])
   141    429.0 MiB      0.4 MiB           self._debug = theano.function([self.states], [self.states.flatten(2)])


('-prepare for worker-', 4)
('Input layer shape: ', (None, 1, 30, 225))
('Conv1 layer shape: ', (None, 32, 28, 223))
('Pool1 layer shape: ', (None, 32, 14, 111))
('Conv2 layer shape: ', (None, 64, 12, 109))
('Pool2 layer shape: ', (None, 64, 6, 54))
('Hidden layer shape: ', (None, 128))
('Dropout layer shape: ', (None, 128))
('Output layer shape: ', (None, 16))
Filename: /gpfs/home6/terhard/DeepRM_2/pg_network.py

Line #    Mem usage    Increment   Line Contents
================================================
   247    429.1 MiB    429.1 MiB   @profile
   248                             def build_cnn_pg_network(input_height, input_width, output_length):
   249                                 
   250                                 # Input layer
   251    429.1 MiB      0.0 MiB       l_in = lasagne.layers.InputLayer(
   252    429.1 MiB      0.0 MiB           shape=(None, 1, input_height, input_width),
   253                                 )
   254                                 
   255    429.1 MiB      0.0 MiB       print("Input layer shape: ", l_in.output_shape)
   256                                 
   257                                 # First convolutional layer
   258    429.1 MiB      0.0 MiB       l_conv1 = lasagne.layers.Conv2DLayer(
   259    429.1 MiB      0.0 MiB           l_in,
   260    429.1 MiB      0.0 MiB           num_filters=32,
   261    429.1 MiB      0.0 MiB           filter_size=(3, 3),
   262    429.1 MiB      0.0 MiB           nonlinearity=lasagne.nonlinearities.rectify,
   263    429.1 MiB      0.0 MiB           W=lasagne.init.GlorotUniform()
   264                                 )
   265                                 
   266    429.1 MiB      0.0 MiB       print("Conv1 layer shape: ", l_conv1.output_shape)
   267                                 
   268                                 # Pooling layer
   269    429.1 MiB      0.0 MiB       l_pool1 = lasagne.layers.MaxPool2DLayer(l_conv1, pool_size=(2, 2))
   270                                 
   271    429.1 MiB      0.0 MiB       print("Pool1 layer shape: ",l_pool1.output_shape)
   272                                                                                             
   273                                 # Second convolutional layer
   274    429.1 MiB      0.0 MiB       l_conv2 = lasagne.layers.Conv2DLayer(
   275    429.1 MiB      0.0 MiB           l_pool1,
   276    429.1 MiB      0.0 MiB           num_filters=64,
   277    429.1 MiB      0.0 MiB           filter_size=(3, 3),
   278    429.1 MiB      0.0 MiB           nonlinearity=lasagne.nonlinearities.rectify
   279                                 )
   280                                 
   281    429.1 MiB      0.0 MiB       print("Conv2 layer shape: ", l_conv2.output_shape)
   282                                 
   283                                 # Pooling layer
   284    429.1 MiB      0.0 MiB       l_pool2 = lasagne.layers.MaxPool2DLayer(l_conv2, pool_size=(2, 2))
   285                                 
   286    429.1 MiB      0.0 MiB       print("Pool2 layer shape: ", l_pool2.output_shape) 
   287                                 
   288                                 # Fully connected layer
   289    429.1 MiB      0.0 MiB       l_hid = lasagne.layers.DenseLayer(
   290    429.1 MiB      0.0 MiB           l_pool2,
   291    429.1 MiB      0.0 MiB           num_units=128,
   292    429.1 MiB      0.0 MiB           nonlinearity=lasagne.nonlinearities.rectify,
   293    459.5 MiB     30.4 MiB           W=lasagne.init.GlorotUniform()
   294                                 )
   295                                 
   296    459.5 MiB      0.0 MiB       print("Hidden layer shape: ", l_hid.output_shape)
   297                                 
   298                                 # Dropout layer
   299    459.5 MiB      0.0 MiB       l_dropout = lasagne.layers.DropoutLayer(l_hid, p=0.5)
   300                                 
   301    459.5 MiB      0.0 MiB       print("Dropout layer shape: ", l_dropout.output_shape)
   302                                 
   303                                 # Output layer 
   304    459.5 MiB      0.0 MiB       l_out = lasagne.layers.DenseLayer(
   305    459.5 MiB      0.0 MiB           l_dropout,
   306    459.5 MiB      0.0 MiB           num_units=output_length,
   307    459.5 MiB      0.0 MiB           nonlinearity=lasagne.nonlinearities.softmax
   308                                 )
   309                                 
   310    459.5 MiB      0.0 MiB       print("Output layer shape: ", l_out.output_shape)
   311                                 
   312    459.5 MiB      0.0 MiB       return l_out


(' params=', [W, b, W, b, W, b, W, b], ' count=', 2675216)
Filename: /gpfs/home6/terhard/DeepRM_2/pg_network.py

Line #    Mem usage    Increment   Line Contents
================================================
     7    470.5 MiB    470.5 MiB   @profile
     8                             def rmsprop_updates(grads, params, stepsize, rho=0.9, epsilon=1e-9):
     9                             
    10    470.5 MiB      0.0 MiB       updates = []
    11                             
    12    471.0 MiB      0.0 MiB       for param, grad in zip(params, grads):
    13    471.0 MiB      0.0 MiB           accum = theano.shared(np.zeros(param.get_value(borrow=True).shape, dtype=param.dtype))
    14                                     # print('thanos car thanos car', accum)
    15    471.0 MiB      0.3 MiB           accum_new = rho * accum + (1 - rho) * grad ** 2
    16                                     # print('thanos bus', accum_new)
    17    471.0 MiB      0.0 MiB           updates.append((accum, accum_new))
    18    471.0 MiB      0.2 MiB           updates.append((param, param + (stepsize * grad / T.sqrt(accum_new + epsilon))))
    19                                     # print('upadata,', updates)
    20                                     # lasagne has '-' after param
    21    471.0 MiB      0.0 MiB       return updates


Filename: /gpfs/home6/terhard/DeepRM_2/pg_network.py

Line #    Mem usage    Increment   Line Contents
================================================
    60    429.1 MiB    429.1 MiB       @profile
    61                                 def __init__(self, pa, use_cnn=True):
    62                             
    63    429.1 MiB      0.0 MiB           self.input_height = pa.network_input_height
    64    429.1 MiB      0.0 MiB           self.input_width = pa.network_input_width
    65    429.1 MiB      0.0 MiB           self.output_height = pa.network_output_dim
    66                             
    67    429.1 MiB      0.0 MiB           self.num_frames = pa.num_frames
    68                                     
    69    429.1 MiB      0.0 MiB           self.update_counter = 0
    70                             
    71    429.1 MiB      0.0 MiB           self.states = T.tensor4('states')
    72    429.1 MiB      0.0 MiB           self.actions = T.ivector('actions')
    73    429.1 MiB      0.0 MiB           self.values = T.vector('values')
    74                             
    75                                     # print 'network_input_height=', pa.network_input_height
    76                                     # print 'network_input_width=', pa.network_input_width
    77                                     # print 'network_output_dim=', pa.network_output_dim
    78                             
    79                                     # print("use_cnn is now set to:", use_cnn)
    80    429.1 MiB      0.0 MiB           if use_cnn:  # choose network based on use_cnn parameter
    81    459.5 MiB     30.4 MiB               self.l_out = build_cnn_pg_network(pa.network_input_height, pa.network_input_width, pa.network_output_dim)
    82                                     else:
    83                                         self.l_out = build_pg_network(pa.network_input_height, pa.network_input_width, pa.network_output_dim)
    84                                     
    85                                     # image representation
    86                                     # self.l_out = \
    87                                     #     build_pg_network(pa.network_input_height, pa.network_input_width, pa.network_output_dim)
    88                                     
    89                                     #self.l_out = \
    90                                      #   build_pg_network(pa.network_input_height, pa.network_input_width, pa.network_output_dim)
    91                             
    92                                     # compact representation
    93                                     #self.l_out = \
    94                                      #    build_compact_pg_network(pa.network_input_height, pa.network_input_width, pa.network_output_dim)
    95                             
    96    459.5 MiB      0.0 MiB           self.lr_rate = pa.lr_rate
    97    459.5 MiB      0.0 MiB           self.rms_rho = pa.rms_rho
    98    459.5 MiB      0.0 MiB           self.rms_eps = pa.rms_eps
    99                             
   100    459.5 MiB      0.0 MiB           params = lasagne.layers.helper.get_all_params(self.l_out)
   101    469.3 MiB      9.8 MiB           print(' params=', params, ' count=', lasagne.layers.count_params(self.l_out))
   102    469.7 MiB      0.4 MiB           self._get_param = theano.function([], params)
   103                             
   104                                     # ===================================
   105                                     # training function part
   106                                     # ===================================
   107                             
   108    469.8 MiB      0.1 MiB           prob_act = lasagne.layers.get_output(self.l_out, self.states)
   109    470.0 MiB      0.1 MiB           self._get_act_prob = theano.function([self.states], prob_act, allow_input_downcast=True)
   110                             
   111                                     # --------  Policy Gradient  --------
   112                             
   113    470.0 MiB      0.0 MiB           N = self.states.shape[0]
   114    470.0 MiB      0.0 MiB           loss = T.log(prob_act[T.arange(N), self.actions]).dot(self.values) / N  # call it "loss"
   115    470.5 MiB      0.5 MiB           grads = T.grad(loss, params)
   116    470.5 MiB      0.0 MiB           updates = rmsprop_updates(
   117    471.0 MiB      0.5 MiB               grads, params, self.lr_rate, self.rms_rho, self.rms_eps)
   118                             
   119                                     # updates = adam_update(
   120                                     #     grads, params, self.lr_rate)
   121                             
   122    471.0 MiB      0.0 MiB           self._train_fn = theano.function([self.states, self.actions, self.values], loss,
   123    477.7 MiB      6.8 MiB                                            updates=updates, allow_input_downcast=True)
   124    480.0 MiB      2.3 MiB           self._get_loss = theano.function([self.states, self.actions, self.values], loss, allow_input_downcast=True)
   125    483.8 MiB      3.8 MiB           self._get_grad = theano.function([self.states, self.actions, self.values], grads, allow_input_downcast=True)
   126                             
   127                                     # --------  Supervised Learning  --------
   128                             
   129    483.8 MiB      0.0 MiB           su_target = T.ivector('su_target')
   130    483.8 MiB      0.0 MiB           su_loss = lasagne.objectives.categorical_crossentropy(prob_act, su_target)
   131    483.8 MiB      0.0 MiB           su_loss = su_loss.mean()
   132    483.8 MiB      0.0 MiB           l2_penalty = lasagne.regularization.regularize_network_params(self.l_out, lasagne.regularization.l2)
   133                                     # l1_penalty = lasagne.regularization.regularize_network_params(self.l_out, lasagne.regularization.l1)
   134    483.8 MiB      0.0 MiB           su_loss += 1e-3*l2_penalty
   135                                     # print 'lr_rate=', self.lr_rate
   136    483.8 MiB      0.0 MiB           su_updates = lasagne.updates.rmsprop(su_loss, params,
   137    495.4 MiB     11.6 MiB                                                self.lr_rate, self.rms_rho, self.rms_eps)
   138                                     #su_updates = lasagne.updates.nesterov_momentum(su_loss, params, self.lr_rate)
   139    502.8 MiB      7.4 MiB           self._su_train_fn = theano.function([self.states, su_target], [su_loss, prob_act], updates=su_updates)
   140    505.1 MiB      2.2 MiB           self._su_loss = theano.function([self.states, su_target], [su_loss, prob_act])
   141    505.6 MiB      0.5 MiB           self._debug = theano.function([self.states], [self.states.flatten(2)])


('-prepare for worker-', 5)
('Input layer shape: ', (None, 1, 30, 225))
('Conv1 layer shape: ', (None, 32, 28, 223))
('Pool1 layer shape: ', (None, 32, 14, 111))
('Conv2 layer shape: ', (None, 64, 12, 109))
('Pool2 layer shape: ', (None, 64, 6, 54))
('Hidden layer shape: ', (None, 128))
('Dropout layer shape: ', (None, 128))
('Output layer shape: ', (None, 16))
Filename: /gpfs/home6/terhard/DeepRM_2/pg_network.py

Line #    Mem usage    Increment   Line Contents
================================================
   247    505.6 MiB    505.6 MiB   @profile
   248                             def build_cnn_pg_network(input_height, input_width, output_length):
   249                                 
   250                                 # Input layer
   251    505.6 MiB      0.0 MiB       l_in = lasagne.layers.InputLayer(
   252    505.6 MiB      0.0 MiB           shape=(None, 1, input_height, input_width),
   253                                 )
   254                                 
   255    505.6 MiB      0.0 MiB       print("Input layer shape: ", l_in.output_shape)
   256                                 
   257                                 # First convolutional layer
   258    505.6 MiB      0.0 MiB       l_conv1 = lasagne.layers.Conv2DLayer(
   259    505.6 MiB      0.0 MiB           l_in,
   260    505.6 MiB      0.0 MiB           num_filters=32,
   261    505.6 MiB      0.0 MiB           filter_size=(3, 3),
   262    505.6 MiB      0.0 MiB           nonlinearity=lasagne.nonlinearities.rectify,
   263    505.6 MiB      0.0 MiB           W=lasagne.init.GlorotUniform()
   264                                 )
   265                                 
   266    505.6 MiB      0.0 MiB       print("Conv1 layer shape: ", l_conv1.output_shape)
   267                                 
   268                                 # Pooling layer
   269    505.6 MiB      0.0 MiB       l_pool1 = lasagne.layers.MaxPool2DLayer(l_conv1, pool_size=(2, 2))
   270                                 
   271    505.6 MiB      0.0 MiB       print("Pool1 layer shape: ",l_pool1.output_shape)
   272                                                                                             
   273                                 # Second convolutional layer
   274    505.6 MiB      0.0 MiB       l_conv2 = lasagne.layers.Conv2DLayer(
   275    505.6 MiB      0.0 MiB           l_pool1,
   276    505.6 MiB      0.0 MiB           num_filters=64,
   277    505.6 MiB      0.0 MiB           filter_size=(3, 3),
   278    505.6 MiB      0.0 MiB           nonlinearity=lasagne.nonlinearities.rectify
   279                                 )
   280                                 
   281    505.6 MiB      0.0 MiB       print("Conv2 layer shape: ", l_conv2.output_shape)
   282                                 
   283                                 # Pooling layer
   284    505.6 MiB      0.0 MiB       l_pool2 = lasagne.layers.MaxPool2DLayer(l_conv2, pool_size=(2, 2))
   285                                 
   286    505.6 MiB      0.0 MiB       print("Pool2 layer shape: ", l_pool2.output_shape) 
   287                                 
   288                                 # Fully connected layer
   289    505.6 MiB      0.0 MiB       l_hid = lasagne.layers.DenseLayer(
   290    505.6 MiB      0.0 MiB           l_pool2,
   291    505.6 MiB      0.0 MiB           num_units=128,
   292    505.6 MiB      0.0 MiB           nonlinearity=lasagne.nonlinearities.rectify,
   293    535.9 MiB     30.3 MiB           W=lasagne.init.GlorotUniform()
   294                                 )
   295                                 
   296    535.9 MiB      0.0 MiB       print("Hidden layer shape: ", l_hid.output_shape)
   297                                 
   298                                 # Dropout layer
   299    535.9 MiB      0.0 MiB       l_dropout = lasagne.layers.DropoutLayer(l_hid, p=0.5)
   300                                 
   301    535.9 MiB      0.0 MiB       print("Dropout layer shape: ", l_dropout.output_shape)
   302                                 
   303                                 # Output layer 
   304    535.9 MiB      0.0 MiB       l_out = lasagne.layers.DenseLayer(
   305    535.9 MiB      0.0 MiB           l_dropout,
   306    535.9 MiB      0.0 MiB           num_units=output_length,
   307    535.9 MiB      0.0 MiB           nonlinearity=lasagne.nonlinearities.softmax
   308                                 )
   309                                 
   310    535.9 MiB      0.0 MiB       print("Output layer shape: ", l_out.output_shape)
   311                                 
   312    535.9 MiB      0.0 MiB       return l_out


(' params=', [W, b, W, b, W, b, W, b], ' count=', 2675216)
Filename: /gpfs/home6/terhard/DeepRM_2/pg_network.py

Line #    Mem usage    Increment   Line Contents
================================================
     7    536.7 MiB    536.7 MiB   @profile
     8                             def rmsprop_updates(grads, params, stepsize, rho=0.9, epsilon=1e-9):
     9                             
    10    536.7 MiB      0.0 MiB       updates = []
    11                             
    12    537.2 MiB      0.0 MiB       for param, grad in zip(params, grads):
    13    537.2 MiB      0.0 MiB           accum = theano.shared(np.zeros(param.get_value(borrow=True).shape, dtype=param.dtype))
    14                                     # print('thanos car thanos car', accum)
    15    537.2 MiB      0.3 MiB           accum_new = rho * accum + (1 - rho) * grad ** 2
    16                                     # print('thanos bus', accum_new)
    17    537.2 MiB      0.0 MiB           updates.append((accum, accum_new))
    18    537.2 MiB      0.3 MiB           updates.append((param, param + (stepsize * grad / T.sqrt(accum_new + epsilon))))
    19                                     # print('upadata,', updates)
    20                                     # lasagne has '-' after param
    21    537.2 MiB      0.0 MiB       return updates


Filename: /gpfs/home6/terhard/DeepRM_2/pg_network.py

Line #    Mem usage    Increment   Line Contents
================================================
    60    505.6 MiB    505.6 MiB       @profile
    61                                 def __init__(self, pa, use_cnn=True):
    62                             
    63    505.6 MiB      0.0 MiB           self.input_height = pa.network_input_height
    64    505.6 MiB      0.0 MiB           self.input_width = pa.network_input_width
    65    505.6 MiB      0.0 MiB           self.output_height = pa.network_output_dim
    66                             
    67    505.6 MiB      0.0 MiB           self.num_frames = pa.num_frames
    68                                     
    69    505.6 MiB      0.0 MiB           self.update_counter = 0
    70                             
    71    505.6 MiB      0.0 MiB           self.states = T.tensor4('states')
    72    505.6 MiB      0.0 MiB           self.actions = T.ivector('actions')
    73    505.6 MiB      0.0 MiB           self.values = T.vector('values')
    74                             
    75                                     # print 'network_input_height=', pa.network_input_height
    76                                     # print 'network_input_width=', pa.network_input_width
    77                                     # print 'network_output_dim=', pa.network_output_dim
    78                             
    79                                     # print("use_cnn is now set to:", use_cnn)
    80    505.6 MiB      0.0 MiB           if use_cnn:  # choose network based on use_cnn parameter
    81    535.9 MiB     30.3 MiB               self.l_out = build_cnn_pg_network(pa.network_input_height, pa.network_input_width, pa.network_output_dim)
    82                                     else:
    83                                         self.l_out = build_pg_network(pa.network_input_height, pa.network_input_width, pa.network_output_dim)
    84                                     
    85                                     # image representation
    86                                     # self.l_out = \
    87                                     #     build_pg_network(pa.network_input_height, pa.network_input_width, pa.network_output_dim)
    88                                     
    89                                     #self.l_out = \
    90                                      #   build_pg_network(pa.network_input_height, pa.network_input_width, pa.network_output_dim)
    91                             
    92                                     # compact representation
    93                                     #self.l_out = \
    94                                      #    build_compact_pg_network(pa.network_input_height, pa.network_input_width, pa.network_output_dim)
    95                             
    96    535.9 MiB      0.0 MiB           self.lr_rate = pa.lr_rate
    97    535.9 MiB      0.0 MiB           self.rms_rho = pa.rms_rho
    98    535.9 MiB      0.0 MiB           self.rms_eps = pa.rms_eps
    99                             
   100    535.9 MiB      0.0 MiB           params = lasagne.layers.helper.get_all_params(self.l_out)
   101    535.9 MiB      0.0 MiB           print(' params=', params, ' count=', lasagne.layers.count_params(self.l_out))
   102    536.1 MiB      0.2 MiB           self._get_param = theano.function([], params)
   103                             
   104                                     # ===================================
   105                                     # training function part
   106                                     # ===================================
   107                             
   108    536.1 MiB      0.0 MiB           prob_act = lasagne.layers.get_output(self.l_out, self.states)
   109    536.2 MiB      0.1 MiB           self._get_act_prob = theano.function([self.states], prob_act, allow_input_downcast=True)
   110                             
   111                                     # --------  Policy Gradient  --------
   112                             
   113    536.2 MiB      0.0 MiB           N = self.states.shape[0]
   114    536.2 MiB      0.0 MiB           loss = T.log(prob_act[T.arange(N), self.actions]).dot(self.values) / N  # call it "loss"
   115    536.7 MiB      0.4 MiB           grads = T.grad(loss, params)
   116    536.7 MiB      0.0 MiB           updates = rmsprop_updates(
   117    537.2 MiB      0.5 MiB               grads, params, self.lr_rate, self.rms_rho, self.rms_eps)
   118                             
   119                                     # updates = adam_update(
   120                                     #     grads, params, self.lr_rate)
   121                             
   122    537.2 MiB      0.0 MiB           self._train_fn = theano.function([self.states, self.actions, self.values], loss,
   123    544.1 MiB      6.9 MiB                                            updates=updates, allow_input_downcast=True)
   124    546.2 MiB      2.1 MiB           self._get_loss = theano.function([self.states, self.actions, self.values], loss, allow_input_downcast=True)
   125    549.9 MiB      3.8 MiB           self._get_grad = theano.function([self.states, self.actions, self.values], grads, allow_input_downcast=True)
   126                             
   127                                     # --------  Supervised Learning  --------
   128                             
   129    549.9 MiB      0.0 MiB           su_target = T.ivector('su_target')
   130    549.9 MiB      0.0 MiB           su_loss = lasagne.objectives.categorical_crossentropy(prob_act, su_target)
   131    549.9 MiB      0.0 MiB           su_loss = su_loss.mean()
   132    550.0 MiB      0.1 MiB           l2_penalty = lasagne.regularization.regularize_network_params(self.l_out, lasagne.regularization.l2)
   133                                     # l1_penalty = lasagne.regularization.regularize_network_params(self.l_out, lasagne.regularization.l1)
   134    550.0 MiB      0.0 MiB           su_loss += 1e-3*l2_penalty
   135                                     # print 'lr_rate=', self.lr_rate
   136    550.0 MiB      0.0 MiB           su_updates = lasagne.updates.rmsprop(su_loss, params,
   137    561.4 MiB     11.3 MiB                                                self.lr_rate, self.rms_rho, self.rms_eps)
   138                                     #su_updates = lasagne.updates.nesterov_momentum(su_loss, params, self.lr_rate)
   139    569.0 MiB      7.7 MiB           self._su_train_fn = theano.function([self.states, su_target], [su_loss, prob_act], updates=su_updates)
   140    571.2 MiB      2.2 MiB           self._su_loss = theano.function([self.states, su_target], [su_loss, prob_act])
   141    571.6 MiB      0.4 MiB           self._debug = theano.function([self.states], [self.states.flatten(2)])


('-prepare for worker-', 6)
('Input layer shape: ', (None, 1, 30, 225))
('Conv1 layer shape: ', (None, 32, 28, 223))
('Pool1 layer shape: ', (None, 32, 14, 111))
('Conv2 layer shape: ', (None, 64, 12, 109))
('Pool2 layer shape: ', (None, 64, 6, 54))
('Hidden layer shape: ', (None, 128))
('Dropout layer shape: ', (None, 128))
('Output layer shape: ', (None, 16))
Filename: /gpfs/home6/terhard/DeepRM_2/pg_network.py

Line #    Mem usage    Increment   Line Contents
================================================
   247    571.7 MiB    571.7 MiB   @profile
   248                             def build_cnn_pg_network(input_height, input_width, output_length):
   249                                 
   250                                 # Input layer
   251    571.7 MiB      0.0 MiB       l_in = lasagne.layers.InputLayer(
   252    571.7 MiB      0.0 MiB           shape=(None, 1, input_height, input_width),
   253                                 )
   254                                 
   255    571.7 MiB      0.0 MiB       print("Input layer shape: ", l_in.output_shape)
   256                                 
   257                                 # First convolutional layer
   258    571.7 MiB      0.0 MiB       l_conv1 = lasagne.layers.Conv2DLayer(
   259    571.7 MiB      0.0 MiB           l_in,
   260    571.7 MiB      0.0 MiB           num_filters=32,
   261    571.7 MiB      0.0 MiB           filter_size=(3, 3),
   262    571.7 MiB      0.0 MiB           nonlinearity=lasagne.nonlinearities.rectify,
   263    571.7 MiB      0.0 MiB           W=lasagne.init.GlorotUniform()
   264                                 )
   265                                 
   266    571.7 MiB      0.0 MiB       print("Conv1 layer shape: ", l_conv1.output_shape)
   267                                 
   268                                 # Pooling layer
   269    571.7 MiB      0.0 MiB       l_pool1 = lasagne.layers.MaxPool2DLayer(l_conv1, pool_size=(2, 2))
   270                                 
   271    571.7 MiB      0.0 MiB       print("Pool1 layer shape: ",l_pool1.output_shape)
   272                                                                                             
   273                                 # Second convolutional layer
   274    571.7 MiB      0.0 MiB       l_conv2 = lasagne.layers.Conv2DLayer(
   275    571.7 MiB      0.0 MiB           l_pool1,
   276    571.7 MiB      0.0 MiB           num_filters=64,
   277    571.7 MiB      0.0 MiB           filter_size=(3, 3),
   278    571.7 MiB      0.0 MiB           nonlinearity=lasagne.nonlinearities.rectify
   279                                 )
   280                                 
   281    571.7 MiB      0.0 MiB       print("Conv2 layer shape: ", l_conv2.output_shape)
   282                                 
   283                                 # Pooling layer
   284    571.7 MiB      0.0 MiB       l_pool2 = lasagne.layers.MaxPool2DLayer(l_conv2, pool_size=(2, 2))
   285                                 
   286    571.7 MiB      0.0 MiB       print("Pool2 layer shape: ", l_pool2.output_shape) 
   287                                 
   288                                 # Fully connected layer
   289    571.7 MiB      0.0 MiB       l_hid = lasagne.layers.DenseLayer(
   290    571.7 MiB      0.0 MiB           l_pool2,
   291    571.7 MiB      0.0 MiB           num_units=128,
   292    571.7 MiB      0.0 MiB           nonlinearity=lasagne.nonlinearities.rectify,
   293    602.1 MiB     30.3 MiB           W=lasagne.init.GlorotUniform()
   294                                 )
   295                                 
   296    602.1 MiB      0.0 MiB       print("Hidden layer shape: ", l_hid.output_shape)
   297                                 
   298                                 # Dropout layer
   299    602.1 MiB      0.1 MiB       l_dropout = lasagne.layers.DropoutLayer(l_hid, p=0.5)
   300                                 
   301    602.1 MiB      0.0 MiB       print("Dropout layer shape: ", l_dropout.output_shape)
   302                                 
   303                                 # Output layer 
   304    602.1 MiB      0.0 MiB       l_out = lasagne.layers.DenseLayer(
   305    602.1 MiB      0.0 MiB           l_dropout,
   306    602.1 MiB      0.0 MiB           num_units=output_length,
   307    602.1 MiB      0.0 MiB           nonlinearity=lasagne.nonlinearities.softmax
   308                                 )
   309                                 
   310    602.1 MiB      0.0 MiB       print("Output layer shape: ", l_out.output_shape)
   311                                 
   312    602.1 MiB      0.0 MiB       return l_out


(' params=', [W, b, W, b, W, b, W, b], ' count=', 2675216)
Filename: /gpfs/home6/terhard/DeepRM_2/pg_network.py

Line #    Mem usage    Increment   Line Contents
================================================
     7    605.0 MiB    605.0 MiB   @profile
     8                             def rmsprop_updates(grads, params, stepsize, rho=0.9, epsilon=1e-9):
     9                             
    10    605.0 MiB      0.0 MiB       updates = []
    11                             
    12    615.1 MiB      0.0 MiB       for param, grad in zip(params, grads):
    13    615.1 MiB     10.1 MiB           accum = theano.shared(np.zeros(param.get_value(borrow=True).shape, dtype=param.dtype))
    14                                     # print('thanos car thanos car', accum)
    15    615.1 MiB      0.0 MiB           accum_new = rho * accum + (1 - rho) * grad ** 2
    16                                     # print('thanos bus', accum_new)
    17    615.1 MiB      0.0 MiB           updates.append((accum, accum_new))
    18    615.1 MiB      0.0 MiB           updates.append((param, param + (stepsize * grad / T.sqrt(accum_new + epsilon))))
    19                                     # print('upadata,', updates)
    20                                     # lasagne has '-' after param
    21    615.1 MiB      0.0 MiB       return updates


Filename: /gpfs/home6/terhard/DeepRM_2/pg_network.py

Line #    Mem usage    Increment   Line Contents
================================================
    60    571.7 MiB    571.7 MiB       @profile
    61                                 def __init__(self, pa, use_cnn=True):
    62                             
    63    571.7 MiB      0.0 MiB           self.input_height = pa.network_input_height
    64    571.7 MiB      0.0 MiB           self.input_width = pa.network_input_width
    65    571.7 MiB      0.0 MiB           self.output_height = pa.network_output_dim
    66                             
    67    571.7 MiB      0.0 MiB           self.num_frames = pa.num_frames
    68                                     
    69    571.7 MiB      0.0 MiB           self.update_counter = 0
    70                             
    71    571.7 MiB      0.0 MiB           self.states = T.tensor4('states')
    72    571.7 MiB      0.0 MiB           self.actions = T.ivector('actions')
    73    571.7 MiB      0.0 MiB           self.values = T.vector('values')
    74                             
    75                                     # print 'network_input_height=', pa.network_input_height
    76                                     # print 'network_input_width=', pa.network_input_width
    77                                     # print 'network_output_dim=', pa.network_output_dim
    78                             
    79                                     # print("use_cnn is now set to:", use_cnn)
    80    571.7 MiB      0.0 MiB           if use_cnn:  # choose network based on use_cnn parameter
    81    602.1 MiB     30.4 MiB               self.l_out = build_cnn_pg_network(pa.network_input_height, pa.network_input_width, pa.network_output_dim)
    82                                     else:
    83                                         self.l_out = build_pg_network(pa.network_input_height, pa.network_input_width, pa.network_output_dim)
    84                                     
    85                                     # image representation
    86                                     # self.l_out = \
    87                                     #     build_pg_network(pa.network_input_height, pa.network_input_width, pa.network_output_dim)
    88                                     
    89                                     #self.l_out = \
    90                                      #   build_pg_network(pa.network_input_height, pa.network_input_width, pa.network_output_dim)
    91                             
    92                                     # compact representation
    93                                     #self.l_out = \
    94                                      #    build_compact_pg_network(pa.network_input_height, pa.network_input_width, pa.network_output_dim)
    95                             
    96    602.1 MiB      0.0 MiB           self.lr_rate = pa.lr_rate
    97    602.1 MiB      0.0 MiB           self.rms_rho = pa.rms_rho
    98    602.1 MiB      0.0 MiB           self.rms_eps = pa.rms_eps
    99                             
   100    602.1 MiB      0.0 MiB           params = lasagne.layers.helper.get_all_params(self.l_out)
   101    602.1 MiB      0.0 MiB           print(' params=', params, ' count=', lasagne.layers.count_params(self.l_out))
   102    602.3 MiB      0.2 MiB           self._get_param = theano.function([], params)
   103                             
   104                                     # ===================================
   105                                     # training function part
   106                                     # ===================================
   107                             
   108    602.5 MiB      0.1 MiB           prob_act = lasagne.layers.get_output(self.l_out, self.states)
   109    604.2 MiB      1.8 MiB           self._get_act_prob = theano.function([self.states], prob_act, allow_input_downcast=True)
   110                             
   111                                     # --------  Policy Gradient  --------
   112                             
   113    604.2 MiB      0.0 MiB           N = self.states.shape[0]
   114    604.2 MiB      0.0 MiB           loss = T.log(prob_act[T.arange(N), self.actions]).dot(self.values) / N  # call it "loss"
   115    605.0 MiB      0.8 MiB           grads = T.grad(loss, params)
   116    605.0 MiB      0.0 MiB           updates = rmsprop_updates(
   117    615.1 MiB     10.2 MiB               grads, params, self.lr_rate, self.rms_rho, self.rms_eps)
   118                             
   119                                     # updates = adam_update(
   120                                     #     grads, params, self.lr_rate)
   121                             
   122    615.1 MiB      0.0 MiB           self._train_fn = theano.function([self.states, self.actions, self.values], loss,
   123    619.9 MiB      4.8 MiB                                            updates=updates, allow_input_downcast=True)
   124    621.9 MiB      2.0 MiB           self._get_loss = theano.function([self.states, self.actions, self.values], loss, allow_input_downcast=True)
   125    625.6 MiB      3.7 MiB           self._get_grad = theano.function([self.states, self.actions, self.values], grads, allow_input_downcast=True)
   126                             
   127                                     # --------  Supervised Learning  --------
   128                             
   129    625.6 MiB      0.0 MiB           su_target = T.ivector('su_target')
   130    625.6 MiB      0.0 MiB           su_loss = lasagne.objectives.categorical_crossentropy(prob_act, su_target)
   131    625.6 MiB      0.0 MiB           su_loss = su_loss.mean()
   132    625.6 MiB      0.0 MiB           l2_penalty = lasagne.regularization.regularize_network_params(self.l_out, lasagne.regularization.l2)
   133                                     # l1_penalty = lasagne.regularization.regularize_network_params(self.l_out, lasagne.regularization.l1)
   134    625.6 MiB      0.0 MiB           su_loss += 1e-3*l2_penalty
   135                                     # print 'lr_rate=', self.lr_rate
   136    625.6 MiB      0.0 MiB           su_updates = lasagne.updates.rmsprop(su_loss, params,
   137    637.2 MiB     11.6 MiB                                                self.lr_rate, self.rms_rho, self.rms_eps)
   138                                     #su_updates = lasagne.updates.nesterov_momentum(su_loss, params, self.lr_rate)
   139    644.9 MiB      7.7 MiB           self._su_train_fn = theano.function([self.states, su_target], [su_loss, prob_act], updates=su_updates)
   140    647.0 MiB      2.1 MiB           self._su_loss = theano.function([self.states, su_target], [su_loss, prob_act])
   141    647.4 MiB      0.4 MiB           self._debug = theano.function([self.states], [self.states.flatten(2)])


('-prepare for worker-', 7)
('Input layer shape: ', (None, 1, 30, 225))
('Conv1 layer shape: ', (None, 32, 28, 223))
('Pool1 layer shape: ', (None, 32, 14, 111))
('Conv2 layer shape: ', (None, 64, 12, 109))
('Pool2 layer shape: ', (None, 64, 6, 54))
('Hidden layer shape: ', (None, 128))
('Dropout layer shape: ', (None, 128))
('Output layer shape: ', (None, 16))
Filename: /gpfs/home6/terhard/DeepRM_2/pg_network.py

Line #    Mem usage    Increment   Line Contents
================================================
   247    647.6 MiB    647.6 MiB   @profile
   248                             def build_cnn_pg_network(input_height, input_width, output_length):
   249                                 
   250                                 # Input layer
   251    647.6 MiB      0.0 MiB       l_in = lasagne.layers.InputLayer(
   252    647.6 MiB      0.0 MiB           shape=(None, 1, input_height, input_width),
   253                                 )
   254                                 
   255    647.6 MiB      0.0 MiB       print("Input layer shape: ", l_in.output_shape)
   256                                 
   257                                 # First convolutional layer
   258    647.6 MiB      0.0 MiB       l_conv1 = lasagne.layers.Conv2DLayer(
   259    647.6 MiB      0.0 MiB           l_in,
   260    647.6 MiB      0.0 MiB           num_filters=32,
   261    647.6 MiB      0.0 MiB           filter_size=(3, 3),
   262    647.6 MiB      0.0 MiB           nonlinearity=lasagne.nonlinearities.rectify,
   263    647.6 MiB      0.0 MiB           W=lasagne.init.GlorotUniform()
   264                                 )
   265                                 
   266    647.6 MiB      0.0 MiB       print("Conv1 layer shape: ", l_conv1.output_shape)
   267                                 
   268                                 # Pooling layer
   269    647.6 MiB      0.0 MiB       l_pool1 = lasagne.layers.MaxPool2DLayer(l_conv1, pool_size=(2, 2))
   270                                 
   271    647.6 MiB      0.0 MiB       print("Pool1 layer shape: ",l_pool1.output_shape)
   272                                                                                             
   273                                 # Second convolutional layer
   274    647.6 MiB      0.0 MiB       l_conv2 = lasagne.layers.Conv2DLayer(
   275    647.6 MiB      0.0 MiB           l_pool1,
   276    647.6 MiB      0.0 MiB           num_filters=64,
   277    647.6 MiB      0.0 MiB           filter_size=(3, 3),
   278    647.6 MiB      0.0 MiB           nonlinearity=lasagne.nonlinearities.rectify
   279                                 )
   280                                 
   281    647.6 MiB      0.0 MiB       print("Conv2 layer shape: ", l_conv2.output_shape)
   282                                 
   283                                 # Pooling layer
   284    647.6 MiB      0.0 MiB       l_pool2 = lasagne.layers.MaxPool2DLayer(l_conv2, pool_size=(2, 2))
   285                                 
   286    647.6 MiB      0.0 MiB       print("Pool2 layer shape: ", l_pool2.output_shape) 
   287                                 
   288                                 # Fully connected layer
   289    647.6 MiB      0.0 MiB       l_hid = lasagne.layers.DenseLayer(
   290    647.6 MiB      0.0 MiB           l_pool2,
   291    647.6 MiB      0.0 MiB           num_units=128,
   292    647.6 MiB      0.0 MiB           nonlinearity=lasagne.nonlinearities.rectify,
   293    677.9 MiB     30.3 MiB           W=lasagne.init.GlorotUniform()
   294                                 )
   295                                 
   296    677.9 MiB      0.0 MiB       print("Hidden layer shape: ", l_hid.output_shape)
   297                                 
   298                                 # Dropout layer
   299    677.9 MiB      0.0 MiB       l_dropout = lasagne.layers.DropoutLayer(l_hid, p=0.5)
   300                                 
   301    677.9 MiB      0.0 MiB       print("Dropout layer shape: ", l_dropout.output_shape)
   302                                 
   303                                 # Output layer 
   304    677.9 MiB      0.0 MiB       l_out = lasagne.layers.DenseLayer(
   305    677.9 MiB      0.0 MiB           l_dropout,
   306    677.9 MiB      0.0 MiB           num_units=output_length,
   307    677.9 MiB      0.0 MiB           nonlinearity=lasagne.nonlinearities.softmax
   308                                 )
   309                                 
   310    677.9 MiB      0.0 MiB       print("Output layer shape: ", l_out.output_shape)
   311                                 
   312    677.9 MiB      0.0 MiB       return l_out


(' params=', [W, b, W, b, W, b, W, b], ' count=', 2675216)
Filename: /gpfs/home6/terhard/DeepRM_2/pg_network.py

Line #    Mem usage    Increment   Line Contents
================================================
     7    680.8 MiB    680.8 MiB   @profile
     8                             def rmsprop_updates(grads, params, stepsize, rho=0.9, epsilon=1e-9):
     9                             
    10    680.8 MiB      0.0 MiB       updates = []
    11                             
    12    691.4 MiB      0.0 MiB       for param, grad in zip(params, grads):
    13    691.3 MiB     10.0 MiB           accum = theano.shared(np.zeros(param.get_value(borrow=True).shape, dtype=param.dtype))
    14                                     # print('thanos car thanos car', accum)
    15    691.4 MiB      0.2 MiB           accum_new = rho * accum + (1 - rho) * grad ** 2
    16                                     # print('thanos bus', accum_new)
    17    691.4 MiB      0.1 MiB           updates.append((accum, accum_new))
    18    691.4 MiB      0.2 MiB           updates.append((param, param + (stepsize * grad / T.sqrt(accum_new + epsilon))))
    19                                     # print('upadata,', updates)
    20                                     # lasagne has '-' after param
    21    691.4 MiB      0.0 MiB       return updates


Filename: /gpfs/home6/terhard/DeepRM_2/pg_network.py

Line #    Mem usage    Increment   Line Contents
================================================
    60    647.6 MiB    647.6 MiB       @profile
    61                                 def __init__(self, pa, use_cnn=True):
    62                             
    63    647.6 MiB      0.0 MiB           self.input_height = pa.network_input_height
    64    647.6 MiB      0.0 MiB           self.input_width = pa.network_input_width
    65    647.6 MiB      0.0 MiB           self.output_height = pa.network_output_dim
    66                             
    67    647.6 MiB      0.0 MiB           self.num_frames = pa.num_frames
    68                                     
    69    647.6 MiB      0.0 MiB           self.update_counter = 0
    70                             
    71    647.6 MiB      0.0 MiB           self.states = T.tensor4('states')
    72    647.6 MiB      0.0 MiB           self.actions = T.ivector('actions')
    73    647.6 MiB      0.0 MiB           self.values = T.vector('values')
    74                             
    75                                     # print 'network_input_height=', pa.network_input_height
    76                                     # print 'network_input_width=', pa.network_input_width
    77                                     # print 'network_output_dim=', pa.network_output_dim
    78                             
    79                                     # print("use_cnn is now set to:", use_cnn)
    80    647.6 MiB      0.0 MiB           if use_cnn:  # choose network based on use_cnn parameter
    81    677.9 MiB     30.3 MiB               self.l_out = build_cnn_pg_network(pa.network_input_height, pa.network_input_width, pa.network_output_dim)
    82                                     else:
    83                                         self.l_out = build_pg_network(pa.network_input_height, pa.network_input_width, pa.network_output_dim)
    84                                     
    85                                     # image representation
    86                                     # self.l_out = \
    87                                     #     build_pg_network(pa.network_input_height, pa.network_input_width, pa.network_output_dim)
    88                                     
    89                                     #self.l_out = \
    90                                      #   build_pg_network(pa.network_input_height, pa.network_input_width, pa.network_output_dim)
    91                             
    92                                     # compact representation
    93                                     #self.l_out = \
    94                                      #    build_compact_pg_network(pa.network_input_height, pa.network_input_width, pa.network_output_dim)
    95                             
    96    677.9 MiB      0.0 MiB           self.lr_rate = pa.lr_rate
    97    677.9 MiB      0.0 MiB           self.rms_rho = pa.rms_rho
    98    677.9 MiB      0.0 MiB           self.rms_eps = pa.rms_eps
    99                             
   100    677.9 MiB      0.0 MiB           params = lasagne.layers.helper.get_all_params(self.l_out)
   101    677.9 MiB      0.0 MiB           print(' params=', params, ' count=', lasagne.layers.count_params(self.l_out))
   102    678.1 MiB      0.2 MiB           self._get_param = theano.function([], params)
   103                             
   104                                     # ===================================
   105                                     # training function part
   106                                     # ===================================
   107                             
   108    678.4 MiB      0.3 MiB           prob_act = lasagne.layers.get_output(self.l_out, self.states)
   109    680.2 MiB      1.8 MiB           self._get_act_prob = theano.function([self.states], prob_act, allow_input_downcast=True)
   110                             
   111                                     # --------  Policy Gradient  --------
   112                             
   113    680.2 MiB      0.0 MiB           N = self.states.shape[0]
   114    680.3 MiB      0.0 MiB           loss = T.log(prob_act[T.arange(N), self.actions]).dot(self.values) / N  # call it "loss"
   115    680.8 MiB      0.5 MiB           grads = T.grad(loss, params)
   116    680.8 MiB      0.0 MiB           updates = rmsprop_updates(
   117    691.4 MiB     10.6 MiB               grads, params, self.lr_rate, self.rms_rho, self.rms_eps)
   118                             
   119                                     # updates = adam_update(
   120                                     #     grads, params, self.lr_rate)
   121                             
   122    691.4 MiB      0.0 MiB           self._train_fn = theano.function([self.states, self.actions, self.values], loss,
   123    698.0 MiB      6.6 MiB                                            updates=updates, allow_input_downcast=True)
   124    700.2 MiB      2.2 MiB           self._get_loss = theano.function([self.states, self.actions, self.values], loss, allow_input_downcast=True)
   125    704.0 MiB      3.8 MiB           self._get_grad = theano.function([self.states, self.actions, self.values], grads, allow_input_downcast=True)
   126                             
   127                                     # --------  Supervised Learning  --------
   128                             
   129    704.0 MiB      0.0 MiB           su_target = T.ivector('su_target')
   130    704.0 MiB      0.0 MiB           su_loss = lasagne.objectives.categorical_crossentropy(prob_act, su_target)
   131    704.0 MiB      0.0 MiB           su_loss = su_loss.mean()
   132    704.1 MiB      0.1 MiB           l2_penalty = lasagne.regularization.regularize_network_params(self.l_out, lasagne.regularization.l2)
   133                                     # l1_penalty = lasagne.regularization.regularize_network_params(self.l_out, lasagne.regularization.l1)
   134    704.1 MiB      0.0 MiB           su_loss += 1e-3*l2_penalty
   135                                     # print 'lr_rate=', self.lr_rate
   136    704.1 MiB      0.0 MiB           su_updates = lasagne.updates.rmsprop(su_loss, params,
   137    715.7 MiB     11.6 MiB                                                self.lr_rate, self.rms_rho, self.rms_eps)
   138                                     #su_updates = lasagne.updates.nesterov_momentum(su_loss, params, self.lr_rate)
   139    720.7 MiB      5.1 MiB           self._su_train_fn = theano.function([self.states, su_target], [su_loss, prob_act], updates=su_updates)
   140    722.7 MiB      2.0 MiB           self._su_loss = theano.function([self.states, su_target], [su_loss, prob_act])
   141    723.3 MiB      0.6 MiB           self._debug = theano.function([self.states], [self.states.flatten(2)])


('-prepare for worker-', 8)
('Input layer shape: ', (None, 1, 30, 225))
('Conv1 layer shape: ', (None, 32, 28, 223))
('Pool1 layer shape: ', (None, 32, 14, 111))
('Conv2 layer shape: ', (None, 64, 12, 109))
('Pool2 layer shape: ', (None, 64, 6, 54))
('Hidden layer shape: ', (None, 128))
('Dropout layer shape: ', (None, 128))
('Output layer shape: ', (None, 16))
Filename: /gpfs/home6/terhard/DeepRM_2/pg_network.py

Line #    Mem usage    Increment   Line Contents
================================================
   247    723.3 MiB    723.3 MiB   @profile
   248                             def build_cnn_pg_network(input_height, input_width, output_length):
   249                                 
   250                                 # Input layer
   251    723.3 MiB      0.0 MiB       l_in = lasagne.layers.InputLayer(
   252    723.3 MiB      0.0 MiB           shape=(None, 1, input_height, input_width),
   253                                 )
   254                                 
   255    723.3 MiB      0.0 MiB       print("Input layer shape: ", l_in.output_shape)
   256                                 
   257                                 # First convolutional layer
   258    723.3 MiB      0.0 MiB       l_conv1 = lasagne.layers.Conv2DLayer(
   259    723.3 MiB      0.0 MiB           l_in,
   260    723.3 MiB      0.0 MiB           num_filters=32,
   261    723.3 MiB      0.0 MiB           filter_size=(3, 3),
   262    723.3 MiB      0.0 MiB           nonlinearity=lasagne.nonlinearities.rectify,
   263    723.4 MiB      0.0 MiB           W=lasagne.init.GlorotUniform()
   264                                 )
   265                                 
   266    723.4 MiB      0.0 MiB       print("Conv1 layer shape: ", l_conv1.output_shape)
   267                                 
   268                                 # Pooling layer
   269    723.4 MiB      0.0 MiB       l_pool1 = lasagne.layers.MaxPool2DLayer(l_conv1, pool_size=(2, 2))
   270                                 
   271    723.4 MiB      0.0 MiB       print("Pool1 layer shape: ",l_pool1.output_shape)
   272                                                                                             
   273                                 # Second convolutional layer
   274    723.4 MiB      0.0 MiB       l_conv2 = lasagne.layers.Conv2DLayer(
   275    723.4 MiB      0.0 MiB           l_pool1,
   276    723.4 MiB      0.0 MiB           num_filters=64,
   277    723.4 MiB      0.0 MiB           filter_size=(3, 3),
   278    723.4 MiB      0.0 MiB           nonlinearity=lasagne.nonlinearities.rectify
   279                                 )
   280                                 
   281    723.4 MiB      0.0 MiB       print("Conv2 layer shape: ", l_conv2.output_shape)
   282                                 
   283                                 # Pooling layer
   284    723.4 MiB      0.0 MiB       l_pool2 = lasagne.layers.MaxPool2DLayer(l_conv2, pool_size=(2, 2))
   285                                 
   286    723.4 MiB      0.0 MiB       print("Pool2 layer shape: ", l_pool2.output_shape) 
   287                                 
   288                                 # Fully connected layer
   289    723.4 MiB      0.0 MiB       l_hid = lasagne.layers.DenseLayer(
   290    723.4 MiB      0.0 MiB           l_pool2,
   291    723.4 MiB      0.0 MiB           num_units=128,
   292    723.4 MiB      0.0 MiB           nonlinearity=lasagne.nonlinearities.rectify,
   293    743.6 MiB     20.2 MiB           W=lasagne.init.GlorotUniform()
   294                                 )
   295                                 
   296    743.6 MiB      0.0 MiB       print("Hidden layer shape: ", l_hid.output_shape)
   297                                 
   298                                 # Dropout layer
   299    743.6 MiB      0.0 MiB       l_dropout = lasagne.layers.DropoutLayer(l_hid, p=0.5)
   300                                 
   301    743.6 MiB      0.0 MiB       print("Dropout layer shape: ", l_dropout.output_shape)
   302                                 
   303                                 # Output layer 
   304    743.6 MiB      0.0 MiB       l_out = lasagne.layers.DenseLayer(
   305    743.6 MiB      0.0 MiB           l_dropout,
   306    743.6 MiB      0.0 MiB           num_units=output_length,
   307    743.6 MiB      0.0 MiB           nonlinearity=lasagne.nonlinearities.softmax
   308                                 )
   309                                 
   310    743.6 MiB      0.0 MiB       print("Output layer shape: ", l_out.output_shape)
   311                                 
   312    743.6 MiB      0.0 MiB       return l_out


(' params=', [W, b, W, b, W, b, W, b], ' count=', 2675216)
Filename: /gpfs/home6/terhard/DeepRM_2/pg_network.py

Line #    Mem usage    Increment   Line Contents
================================================
     7    756.2 MiB    756.2 MiB   @profile
     8                             def rmsprop_updates(grads, params, stepsize, rho=0.9, epsilon=1e-9):
     9                             
    10    756.2 MiB      0.0 MiB       updates = []
    11                             
    12    756.7 MiB      0.0 MiB       for param, grad in zip(params, grads):
    13    756.7 MiB      0.0 MiB           accum = theano.shared(np.zeros(param.get_value(borrow=True).shape, dtype=param.dtype))
    14                                     # print('thanos car thanos car', accum)
    15    756.7 MiB      0.0 MiB           accum_new = rho * accum + (1 - rho) * grad ** 2
    16                                     # print('thanos bus', accum_new)
    17    756.7 MiB      0.0 MiB           updates.append((accum, accum_new))
    18    756.7 MiB      0.3 MiB           updates.append((param, param + (stepsize * grad / T.sqrt(accum_new + epsilon))))
    19                                     # print('upadata,', updates)
    20                                     # lasagne has '-' after param
    21    756.7 MiB      0.0 MiB       return updates


Filename: /gpfs/home6/terhard/DeepRM_2/pg_network.py

Line #    Mem usage    Increment   Line Contents
================================================
    60    723.3 MiB    723.3 MiB       @profile
    61                                 def __init__(self, pa, use_cnn=True):
    62                             
    63    723.3 MiB      0.0 MiB           self.input_height = pa.network_input_height
    64    723.3 MiB      0.0 MiB           self.input_width = pa.network_input_width
    65    723.3 MiB      0.0 MiB           self.output_height = pa.network_output_dim
    66                             
    67    723.3 MiB      0.0 MiB           self.num_frames = pa.num_frames
    68                                     
    69    723.3 MiB      0.0 MiB           self.update_counter = 0
    70                             
    71    723.3 MiB      0.0 MiB           self.states = T.tensor4('states')
    72    723.3 MiB      0.0 MiB           self.actions = T.ivector('actions')
    73    723.3 MiB      0.0 MiB           self.values = T.vector('values')
    74                             
    75                                     # print 'network_input_height=', pa.network_input_height
    76                                     # print 'network_input_width=', pa.network_input_width
    77                                     # print 'network_output_dim=', pa.network_output_dim
    78                             
    79                                     # print("use_cnn is now set to:", use_cnn)
    80    723.3 MiB      0.0 MiB           if use_cnn:  # choose network based on use_cnn parameter
    81    743.6 MiB     20.3 MiB               self.l_out = build_cnn_pg_network(pa.network_input_height, pa.network_input_width, pa.network_output_dim)
    82                                     else:
    83                                         self.l_out = build_pg_network(pa.network_input_height, pa.network_input_width, pa.network_output_dim)
    84                                     
    85                                     # image representation
    86                                     # self.l_out = \
    87                                     #     build_pg_network(pa.network_input_height, pa.network_input_width, pa.network_output_dim)
    88                                     
    89                                     #self.l_out = \
    90                                      #   build_pg_network(pa.network_input_height, pa.network_input_width, pa.network_output_dim)
    91                             
    92                                     # compact representation
    93                                     #self.l_out = \
    94                                      #    build_compact_pg_network(pa.network_input_height, pa.network_input_width, pa.network_output_dim)
    95                             
    96    743.6 MiB      0.0 MiB           self.lr_rate = pa.lr_rate
    97    743.6 MiB      0.0 MiB           self.rms_rho = pa.rms_rho
    98    743.6 MiB      0.0 MiB           self.rms_eps = pa.rms_eps
    99                             
   100    743.6 MiB      0.0 MiB           params = lasagne.layers.helper.get_all_params(self.l_out)
   101    753.2 MiB      9.6 MiB           print(' params=', params, ' count=', lasagne.layers.count_params(self.l_out))
   102    753.7 MiB      0.5 MiB           self._get_param = theano.function([], params)
   103                             
   104                                     # ===================================
   105                                     # training function part
   106                                     # ===================================
   107                             
   108    753.8 MiB      0.1 MiB           prob_act = lasagne.layers.get_output(self.l_out, self.states)
   109    755.7 MiB      1.8 MiB           self._get_act_prob = theano.function([self.states], prob_act, allow_input_downcast=True)
   110                             
   111                                     # --------  Policy Gradient  --------
   112                             
   113    755.7 MiB      0.0 MiB           N = self.states.shape[0]
   114    755.7 MiB      0.0 MiB           loss = T.log(prob_act[T.arange(N), self.actions]).dot(self.values) / N  # call it "loss"
   115    756.2 MiB      0.5 MiB           grads = T.grad(loss, params)
   116    756.2 MiB      0.0 MiB           updates = rmsprop_updates(
   117    756.7 MiB      0.5 MiB               grads, params, self.lr_rate, self.rms_rho, self.rms_eps)
   118                             
   119                                     # updates = adam_update(
   120                                     #     grads, params, self.lr_rate)
   121                             
   122    756.7 MiB      0.0 MiB           self._train_fn = theano.function([self.states, self.actions, self.values], loss,
   123    763.4 MiB      6.7 MiB                                            updates=updates, allow_input_downcast=True)
   124    765.4 MiB      2.1 MiB           self._get_loss = theano.function([self.states, self.actions, self.values], loss, allow_input_downcast=True)
   125    769.2 MiB      3.8 MiB           self._get_grad = theano.function([self.states, self.actions, self.values], grads, allow_input_downcast=True)
   126                             
   127                                     # --------  Supervised Learning  --------
   128                             
   129    769.2 MiB      0.0 MiB           su_target = T.ivector('su_target')
   130    769.2 MiB      0.0 MiB           su_loss = lasagne.objectives.categorical_crossentropy(prob_act, su_target)
   131    769.4 MiB      0.2 MiB           su_loss = su_loss.mean()
   132    769.4 MiB      0.0 MiB           l2_penalty = lasagne.regularization.regularize_network_params(self.l_out, lasagne.regularization.l2)
   133                                     # l1_penalty = lasagne.regularization.regularize_network_params(self.l_out, lasagne.regularization.l1)
   134    769.4 MiB      0.0 MiB           su_loss += 1e-3*l2_penalty
   135                                     # print 'lr_rate=', self.lr_rate
   136    769.4 MiB      0.0 MiB           su_updates = lasagne.updates.rmsprop(su_loss, params,
   137    780.9 MiB     11.5 MiB                                                self.lr_rate, self.rms_rho, self.rms_eps)
   138                                     #su_updates = lasagne.updates.nesterov_momentum(su_loss, params, self.lr_rate)
   139    788.4 MiB      7.5 MiB           self._su_train_fn = theano.function([self.states, su_target], [su_loss, prob_act], updates=su_updates)
   140    790.6 MiB      2.2 MiB           self._su_loss = theano.function([self.states, su_target], [su_loss, prob_act])
   141    791.1 MiB      0.5 MiB           self._debug = theano.function([self.states], [self.states.flatten(2)])


Filename: /gpfs/home6/terhard/DeepRM_2/pg_network.py

Line #    Mem usage    Increment   Line Contents
================================================
   161    791.1 MiB    791.1 MiB       @profile
   162                                 def get_params(self):
   163                             
   164    801.1 MiB     10.0 MiB           return self._get_param()


Filename: /gpfs/home6/terhard/DeepRM_2/pg_re.py

Line #    Mem usage    Increment   Line Contents
================================================
    24    791.1 MiB    791.1 MiB   @profile
    25                             def init_accums(pg_learner):  # in rmsprop
    26                                 #This initializes the accumulator which is a variable used for storing intermediates values during optimization updates.
    27                                 #So, here store running average of the squared gradient for each param.
    28                                 #RMSPROp is adaptive learning rate optimization algo to train NN. Good against vanishing gradient.
    29    791.1 MiB      0.0 MiB       accums = []
    30    801.1 MiB     10.0 MiB       params = pg_learner.get_params()
    31    801.1 MiB      0.0 MiB       for param in params:
    32    801.1 MiB      0.0 MiB           accum = np.zeros(param.shape, dtype=param.dtype)
    33    801.1 MiB      0.0 MiB           accums.append(accum)
    34    801.1 MiB      0.0 MiB       return accums


Preparing for reference data...
initialize the environment...
('rand valx', 0.2384460988728453)
('anomalous job', 28)
('the random val for res', 0.19624246729327466)
('the resource vector req: ', array([ 2., 11.]))
('rand valx', 0.3719692415996759)
('anomalous job', 24)
('the random val for res', 0.9138706948638771)
('the resource vector req: ', array([ 1., 10.]))
('rand val', 0.6000987108374178)
('small job', 2)
('the random val for res', 0.6410608358696614)
('the resource vector req: ', array([2., 5.]))
('rand val', 0.9343228163924074)
test2
('big job', 18)
('the random val for res', 0.4524101284476577)
('the resource vector req: ', array([ 1., 12.]))
('rand val', 0.6985668684431456)
('small job', 2)
('the random val for res', 0.7551209332561897)
('the resource vector req: ', array([1., 7.]))
('rand valx', 0.3169517000214108)
('anomalous job', 24)
('the random val for res', 0.8810190595761771)
('the resource vector req: ', array([6., 1.]))
('rand valx', 0.16746802586558296)
('anomalous job', 25)
('the random val for res', 0.7629309801466684)
('the resource vector req: ', array([7., 1.]))
('rand valx', 0.04642420775314582)
('anomalous job', 19)
('the random val for res', 0.3386230053439301)
('the resource vector req: ', array([ 1., 13.]))
('rand val', 0.7180341879486238)
('small job', 1)
('the random val for res', 0.601803513030503)
('the resource vector req: ', array([7., 2.]))
('rand val', 0.7003467445579096)
('small job', 2)
('the random val for res', 0.9459330854420219)
('the resource vector req: ', array([2., 5.]))
('rand val', 0.6222030677584274)
('small job', 2)
('the random val for res', 0.524998279334503)
('the resource vector req: ', array([8., 1.]))
('rand val', 0.6570319871415825)
('small job', 3)
('the random val for res', 0.40241667975027207)
('the resource vector req: ', array([ 1., 14.]))
('rand val', 0.7965736340971555)
test2
('big job', 14)
('the random val for res', 0.5148217788238416)
('the resource vector req: ', array([10.,  2.]))
('rand valx', 0.2895430144210672)
('anomalous job', 22)
('the random val for res', 0.6559707692417717)
('the resource vector req: ', array([2., 6.]))
('rand valx', 0.2741921001091605)
('anomalous job', 27)
('the random val for res', 0.9475670481834888)
('the resource vector req: ', array([1., 8.]))
('rand val', 0.6540636669327086)
('small job', 3)
('the random val for res', 0.03299898535447465)
('the resource vector req: ', array([14.,  2.]))
('rand valx', 0.2764304106533044)
('anomalous job', 24)
('the random val for res', 0.2966093922180567)
('the resource vector req: ', array([ 2., 13.]))
('rand valx', 0.3627420520486354)
('anomalous job', 19)
('the random val for res', 0.35010101912193625)
('the resource vector req: ', array([ 1., 12.]))
('rand val', 0.6560510683503847)
('small job', 3)
('the random val for res', 0.1234109639806964)
('the resource vector req: ', array([ 1., 13.]))
('rand val', 0.6132321626762276)
('small job', 3)
('the random val for res', 0.8358187754013422)
('the resource vector req: ', array([1., 6.]))
('rand valx', 0.23086676757048696)
('anomalous job', 21)
('the random val for res', 0.3452586336279444)
('the resource vector req: ', array([14.,  2.]))
('rand val', 0.6045434773319355)
('small job', 3)
('the random val for res', 0.7954010371845133)
('the resource vector req: ', array([7., 1.]))
('rand valx', 0.01736979379247161)
('anomalous job', 22)
('the random val for res', 0.44088363813690923)
('the resource vector req: ', array([14.,  2.]))
('rand valx', 0.312300230632807)
('anomalous job', 25)
('the random val for res', 0.36616080319238864)
('the resource vector req: ', array([ 2., 12.]))
('rand val', 0.5599063185473864)
('small job', 3)
('the random val for res', 0.9318916062415152)
('the resource vector req: ', array([7., 2.]))
(u'workload', array([0., 0.]))
Load on # 0 resource dimension is 5.968
Load on # 1 resource dimension is 10.056000000000001



=============== 0 ===============
('resleft1', array([[9., 0.],
       [9., 0.],
       [9., 0.],
       [9., 0.],
       [9., 0.],
       [9., 0.],
       [9., 0.],
       [9., 0.],
       [9., 0.],
       [9., 0.],
       [9., 0.],
       [9., 0.],
       [9., 0.],
       [9., 0.],
       [9., 0.],
       [9., 0.],
       [9., 0.],
       [9., 0.],
       [9., 0.],
       [9., 0.],
       [9., 0.],
       [9., 0.],
       [9., 0.],
       [9., 0.]]))
('action returned cloud node for long jobs', 0, 'and job info: ', 0, 24, array([ 1, 10]))
('resleft2', array([[8., 5.],
       [8., 5.]]))
('act return normal edge node for normal jobs', 6, 'and job info: ', 1, 2, array([2, 5]))
('resleft3', array([[14.,  3.],
       [14.,  3.],
       [14.,  3.],
       [14.,  3.],
       [14.,  3.],
       [14.,  3.],
       [14.,  3.],
       [14.,  3.],
       [14.,  3.],
       [14.,  3.],
       [14.,  3.],
       [14.,  3.],
       [14.,  3.],
       [14.,  3.],
       [14.,  3.],
       [14.,  3.],
       [14.,  3.],
       [14.,  3.]]))
('act return cloud node for expensive jobs', 11, 'and job info: ', 2, 18, array([ 1, 12]))
('resleft2', array([[9., 3.],
       [9., 3.]]))
('act return normal edge node for normal jobs', 6, 'and job info: ', 3, 2, array([1, 7]))
nice
(u'final reward', 0)
finished!!!!
(u'final backlog: ', 0, u'job slots: ', [None, None, None, None, None])
Filename: /gpfs/home6/terhard/DeepRM_2/slow_down_cdf.py

Line #    Mem usage    Increment   Line Contents
================================================
    40    801.1 MiB    801.1 MiB   @profile
    41                             def get_traj(test_type, pa, env, episode_max_length, pg_resume=None, use_cnn=True, render=False):
    42                                 """
    43                                 Run agent-environment loop for one whole episode (trajectory)
    44                                 Return dictionary of results
    45                                 """
    46                                 # print("pg_resume in get_traj is: ", pg_resume)
    47                                # append = False
    48    801.1 MiB      0.0 MiB       if test_type == 'PG':  # load trained parameters
    49                                   #  append = True
    50                                     pg_learner = pg_network.PGLearner(pa, use_cnn=use_cnn)
    51                             
    52                                     net_handle = open(pg_resume, 'rb')
    53                                     net_params = cPickle.load(net_handle)
    54                                     pg_learner.set_net_params(net_params)
    55                             
    56    801.1 MiB      0.0 MiB       env.reset()
    57    801.1 MiB      0.0 MiB       rews = []
    58                             
    59    801.1 MiB      0.0 MiB       ob = env.observe()
    60                             
    61    801.1 MiB      0.0 MiB       for _ in xrange(episode_max_length):
    62                             
    63    801.1 MiB      0.0 MiB           if test_type == 'PG':
    64                                         a = pg_learner.choose_action(ob)
    65                             
    66    801.1 MiB      0.0 MiB           elif test_type == 'Tetris':
    67                                       #  append = False
    68                                         a = other_agents.get_packer_action(env.machine, env.job_slot1)
    69                             
    70    801.1 MiB      0.0 MiB           elif test_type == 'SJF':
    71                                      #   append = False
    72    801.1 MiB      0.0 MiB               a = other_agents.get_sjf_action(env.machine, env.job_slot1, pa)
    73                             
    74                                     elif test_type == 'Random':
    75                                       #  append = False
    76                                         a = other_agents.get_random_action(env.job_slot1)
    77                             
    78    801.1 MiB      0.0 MiB           ob, rew, done, info = env.step(a, repeat=True, test_type=test_type)
    79                             
    80    801.1 MiB      0.0 MiB           rews.append(rew)
    81                             
    82    801.1 MiB      0.0 MiB           if done: break
    83    801.1 MiB      0.0 MiB           if render: env.render()
    84                                     # env.render()
    85                             
    86    801.1 MiB      0.0 MiB       return np.array(rews), info


---------- SJF -----------
Filename: /gpfs/home6/terhard/DeepRM_2/slow_down_cdf.py

Line #    Mem usage    Increment   Line Contents
================================================
    15    801.1 MiB    801.1 MiB   @profile
    16                             def discount(x, gamma):
    17                                 """
    18                                 Given vector x, computes a vector y such that
    19                                 y[i] = x[i] + gamma * x[i+1] + gamma^2 x[i+2] + ...
    20                                 """
    21    801.1 MiB      0.0 MiB       out = np.zeros(len(x))
    22    801.1 MiB      0.0 MiB       out[-1] = x[-1]
    23    801.1 MiB      0.0 MiB       for i in reversed(xrange(len(x)-1)):
    24    801.1 MiB      0.0 MiB           out[i] = x[i] + gamma*out[i+1]
    25    801.1 MiB      0.0 MiB       assert x.ndim >= 1
    26                                 # More efficient version:
    27                                 # scipy.signal.lfilter([1],[1,-gamma],x[::-1], axis=0)[::-1]
    28    801.1 MiB      0.0 MiB       return out


total discount reward : 	 -18.42894840332832
Filename: /gpfs/home6/terhard/DeepRM_2/slow_down_cdf.py

Line #    Mem usage    Increment   Line Contents
================================================
    15    801.1 MiB    801.1 MiB   @profile
    16                             def discount(x, gamma):
    17                                 """
    18                                 Given vector x, computes a vector y such that
    19                                 y[i] = x[i] + gamma * x[i+1] + gamma^2 x[i+2] + ...
    20                                 """
    21    801.1 MiB      0.0 MiB       out = np.zeros(len(x))
    22    801.1 MiB      0.0 MiB       out[-1] = x[-1]
    23    801.1 MiB      0.0 MiB       for i in reversed(xrange(len(x)-1)):
    24    801.1 MiB      0.0 MiB           out[i] = x[i] + gamma*out[i+1]
    25    801.1 MiB      0.0 MiB       assert x.ndim >= 1
    26                                 # More efficient version:
    27                                 # scipy.signal.lfilter([1],[1,-gamma],x[::-1], axis=0)[::-1]
    28    801.1 MiB      0.0 MiB       return out


Filename: /gpfs/home6/terhard/DeepRM_2/data_collection.py

Line #    Mem usage    Increment   Line Contents
================================================
    64    801.1 MiB    801.1 MiB           @profile
    65                                     def append_job_to_csv(self, file, header, job_info):
    66    801.1 MiB      0.0 MiB                           if not os.path.isfile(file) or os.path.getsize(file) == 0:
    67                                                             with open(file, 'a') as f:
    68                                                                     writer = csv.writer(f)
    69                                                                     writer.writerow(header)
    70                                                     else:
    71    801.1 MiB      0.0 MiB                                   with open(file, 'a') as d:
    72    801.1 MiB      0.0 MiB                                           writer = csv.writer(d)
    73    801.1 MiB      0.0 MiB                                           writer.writerow(job_info)


(4,)
(4,)
(4,)
('job slowdown: ', 1.0)
('job length array', [528])
('job total size:', array([11,  7, 13,  8]))
('job total size:', array([24,  2, 18,  2]))



=============== 1 ===============
('resleft1', array([[3., 9.],
       [3., 9.],
       [3., 9.],
       [3., 9.],
       [3., 9.],
       [3., 9.],
       [3., 9.],
       [3., 9.],
       [3., 9.],
       [3., 9.],
       [3., 9.],
       [3., 9.],
       [3., 9.],
       [3., 9.],
       [3., 9.],
       [3., 9.],
       [3., 9.],
       [3., 9.],
       [3., 9.],
       [3., 9.],
       [3., 9.],
       [3., 9.],
       [3., 9.],
       [3., 9.],
       [3., 9.]]))
('action returned cloud node for long jobs', 0, 'and job info: ', 0, 25, array([7, 1]))
('resleft3', array([[14.,  2.],
       [14.,  2.],
       [14.,  2.],
       [14.,  2.],
       [14.,  2.],
       [14.,  2.],
       [14.,  2.],
       [14.,  2.],
       [14.,  2.],
       [14.,  2.],
       [14.,  2.],
       [14.,  2.],
       [14.,  2.],
       [14.,  2.],
       [14.,  2.],
       [14.,  2.],
       [14.,  2.],
       [14.,  2.],
       [14.,  2.]]))
('act return cloud node for expensive jobs', 11, 'and job info: ', 1, 19, array([ 1, 13]))
('resleft2', array([[3., 8.]]))
('act return normal edge node for normal jobs', 6, 'and job info: ', 2, 1, array([7, 2]))
('resleft2', array([[8., 5.],
       [8., 5.]]))
('act return normal edge node for normal jobs', 6, 'and job info: ', 3, 2, array([2, 5]))
nice
(u'final reward', 0)
finished!!!!
(u'final backlog: ', 0, u'job slots: ', [None, None, None, None, None])
Filename: /gpfs/home6/terhard/DeepRM_2/slow_down_cdf.py

Line #    Mem usage    Increment   Line Contents
================================================
    40    801.1 MiB    801.1 MiB   @profile
    41                             def get_traj(test_type, pa, env, episode_max_length, pg_resume=None, use_cnn=True, render=False):
    42                                 """
    43                                 Run agent-environment loop for one whole episode (trajectory)
    44                                 Return dictionary of results
    45                                 """
    46                                 # print("pg_resume in get_traj is: ", pg_resume)
    47                                # append = False
    48    801.1 MiB      0.0 MiB       if test_type == 'PG':  # load trained parameters
    49                                   #  append = True
    50                                     pg_learner = pg_network.PGLearner(pa, use_cnn=use_cnn)
    51                             
    52                                     net_handle = open(pg_resume, 'rb')
    53                                     net_params = cPickle.load(net_handle)
    54                                     pg_learner.set_net_params(net_params)
    55                             
    56    801.1 MiB      0.0 MiB       env.reset()
    57    801.1 MiB      0.0 MiB       rews = []
    58                             
    59    801.1 MiB      0.0 MiB       ob = env.observe()
    60                             
    61    801.1 MiB      0.0 MiB       for _ in xrange(episode_max_length):
    62                             
    63    801.1 MiB      0.0 MiB           if test_type == 'PG':
    64                                         a = pg_learner.choose_action(ob)
    65                             
    66    801.1 MiB      0.0 MiB           elif test_type == 'Tetris':
    67                                       #  append = False
    68                                         a = other_agents.get_packer_action(env.machine, env.job_slot1)
    69                             
    70    801.1 MiB      0.0 MiB           elif test_type == 'SJF':
    71                                      #   append = False
    72    801.1 MiB      0.0 MiB               a = other_agents.get_sjf_action(env.machine, env.job_slot1, pa)
    73                             
    74                                     elif test_type == 'Random':
    75                                       #  append = False
    76                                         a = other_agents.get_random_action(env.job_slot1)
    77                             
    78    801.1 MiB      0.0 MiB           ob, rew, done, info = env.step(a, repeat=True, test_type=test_type)
    79                             
    80    801.1 MiB      0.0 MiB           rews.append(rew)
    81                             
    82    801.1 MiB      0.0 MiB           if done: break
    83    801.1 MiB      0.0 MiB           if render: env.render()
    84                                     # env.render()
    85                             
    86    801.1 MiB      0.0 MiB       return np.array(rews), info


---------- SJF -----------
Filename: /gpfs/home6/terhard/DeepRM_2/slow_down_cdf.py

Line #    Mem usage    Increment   Line Contents
================================================
    15    801.1 MiB    801.1 MiB   @profile
    16                             def discount(x, gamma):
    17                                 """
    18                                 Given vector x, computes a vector y such that
    19                                 y[i] = x[i] + gamma * x[i+1] + gamma^2 x[i+2] + ...
    20                                 """
    21    801.1 MiB      0.0 MiB       out = np.zeros(len(x))
    22    801.1 MiB      0.0 MiB       out[-1] = x[-1]
    23    801.1 MiB      0.0 MiB       for i in reversed(xrange(len(x)-1)):
    24    801.1 MiB      0.0 MiB           out[i] = x[i] + gamma*out[i+1]
    25    801.1 MiB      0.0 MiB       assert x.ndim >= 1
    26                                 # More efficient version:
    27                                 # scipy.signal.lfilter([1],[1,-gamma],x[::-1], axis=0)[::-1]
    28    801.1 MiB      0.0 MiB       return out


total discount reward : 	 24.88534459007315
Filename: /gpfs/home6/terhard/DeepRM_2/slow_down_cdf.py

Line #    Mem usage    Increment   Line Contents
================================================
    15    801.1 MiB    801.1 MiB   @profile
    16                             def discount(x, gamma):
    17                                 """
    18                                 Given vector x, computes a vector y such that
    19                                 y[i] = x[i] + gamma * x[i+1] + gamma^2 x[i+2] + ...
    20                                 """
    21    801.1 MiB      0.0 MiB       out = np.zeros(len(x))
    22    801.1 MiB      0.0 MiB       out[-1] = x[-1]
    23    801.1 MiB      0.0 MiB       for i in reversed(xrange(len(x)-1)):
    24    801.1 MiB      0.0 MiB           out[i] = x[i] + gamma*out[i+1]
    25    801.1 MiB      0.0 MiB       assert x.ndim >= 1
    26                                 # More efficient version:
    27                                 # scipy.signal.lfilter([1],[1,-gamma],x[::-1], axis=0)[::-1]
    28    801.1 MiB      0.0 MiB       return out


Filename: /gpfs/home6/terhard/DeepRM_2/data_collection.py

Line #    Mem usage    Increment   Line Contents
================================================
    64    801.1 MiB    801.1 MiB           @profile
    65                                     def append_job_to_csv(self, file, header, job_info):
    66    801.1 MiB      0.0 MiB                           if not os.path.isfile(file) or os.path.getsize(file) == 0:
    67                                                             with open(file, 'a') as f:
    68                                                                     writer = csv.writer(f)
    69                                                                     writer.writerow(header)
    70                                                     else:
    71    801.1 MiB      0.0 MiB                                   with open(file, 'a') as d:
    72    801.1 MiB      0.0 MiB                                           writer = csv.writer(d)
    73    801.1 MiB      0.0 MiB                                           writer.writerow(job_info)


(4,)
(4,)
(4,)
('job slowdown: ', 1.0)
('job length array', [528, 489])
('job total size:', array([ 8, 14,  9,  7]))
('job total size:', array([25, 19,  1,  2]))



=============== 2 ===============
('resleft3', array([[14.,  1.],
       [14.,  1.],
       [14.,  1.]]))
('act return cloud node for expensive jobs', 11, 'and job info: ', 0, 3, array([ 1, 14]))
('resleft2', array([[0., 8.],
       [0., 8.],
       [0., 8.],
       [0., 8.],
       [0., 8.],
       [0., 8.],
       [0., 8.],
       [0., 8.],
       [0., 8.],
       [0., 8.],
       [0., 8.],
       [0., 8.],
       [0., 8.],
       [0., 8.]]))
('act return normal edge node for normal jobs', 6, 'and job info: ', 1, 14, array([10,  2]))
('resleft1', array([[9., 2.],
       [9., 2.],
       [9., 2.],
       [9., 2.],
       [9., 2.],
       [9., 2.],
       [9., 2.],
       [9., 2.],
       [9., 2.],
       [9., 2.],
       [9., 2.],
       [9., 2.],
       [9., 2.],
       [9., 2.],
       [9., 2.],
       [9., 2.],
       [9., 2.],
       [9., 2.],
       [9., 2.],
       [9., 2.],
       [9., 2.],
       [9., 2.],
       [9., 2.],
       [9., 2.],
       [9., 2.],
       [9., 2.],
       [9., 2.]]))
('action returned cloud node for long jobs', 1, 'and job info: ', 3, 27, array([1, 8]))
('resleft2', array([[8., 4.],
       [8., 4.],
       [8., 4.],
       [8., 4.],
       [8., 4.],
       [8., 4.],
       [8., 4.],
       [8., 4.],
       [8., 4.],
       [8., 4.],
       [8., 4.],
       [8., 4.],
       [8., 4.],
       [8., 4.],
       [8., 4.],
       [8., 4.],
       [8., 4.],
       [8., 4.],
       [8., 4.],
       [8., 4.],
       [8., 4.],
       [8., 4.]]))
('act return normal edge node for normal jobs', 6, 'and job info: ', 2, 22, array([2, 6]))
nice
(u'final reward', 0)
finished!!!!
(u'final backlog: ', 0, u'job slots: ', [None, None, None, None, None])
Filename: /gpfs/home6/terhard/DeepRM_2/slow_down_cdf.py

Line #    Mem usage    Increment   Line Contents
================================================
    40    801.1 MiB    801.1 MiB   @profile
    41                             def get_traj(test_type, pa, env, episode_max_length, pg_resume=None, use_cnn=True, render=False):
    42                                 """
    43                                 Run agent-environment loop for one whole episode (trajectory)
    44                                 Return dictionary of results
    45                                 """
    46                                 # print("pg_resume in get_traj is: ", pg_resume)
    47                                # append = False
    48    801.1 MiB      0.0 MiB       if test_type == 'PG':  # load trained parameters
    49                                   #  append = True
    50                                     pg_learner = pg_network.PGLearner(pa, use_cnn=use_cnn)
    51                             
    52                                     net_handle = open(pg_resume, 'rb')
    53                                     net_params = cPickle.load(net_handle)
    54                                     pg_learner.set_net_params(net_params)
    55                             
    56    801.1 MiB      0.0 MiB       env.reset()
    57    801.1 MiB      0.0 MiB       rews = []
    58                             
    59    801.1 MiB      0.0 MiB       ob = env.observe()
    60                             
    61    801.2 MiB      0.0 MiB       for _ in xrange(episode_max_length):
    62                             
    63    801.2 MiB      0.0 MiB           if test_type == 'PG':
    64                                         a = pg_learner.choose_action(ob)
    65                             
    66    801.2 MiB      0.0 MiB           elif test_type == 'Tetris':
    67                                       #  append = False
    68                                         a = other_agents.get_packer_action(env.machine, env.job_slot1)
    69                             
    70    801.2 MiB      0.0 MiB           elif test_type == 'SJF':
    71                                      #   append = False
    72    801.2 MiB      0.0 MiB               a = other_agents.get_sjf_action(env.machine, env.job_slot1, pa)
    73                             
    74                                     elif test_type == 'Random':
    75                                       #  append = False
    76                                         a = other_agents.get_random_action(env.job_slot1)
    77                             
    78    801.2 MiB      0.0 MiB           ob, rew, done, info = env.step(a, repeat=True, test_type=test_type)
    79                             
    80    801.2 MiB      0.0 MiB           rews.append(rew)
    81                             
    82    801.2 MiB      0.0 MiB           if done: break
    83    801.2 MiB      0.0 MiB           if render: env.render()
    84                                     # env.render()
    85                             
    86    801.2 MiB      0.0 MiB       return np.array(rews), info


---------- SJF -----------
Filename: /gpfs/home6/terhard/DeepRM_2/slow_down_cdf.py

Line #    Mem usage    Increment   Line Contents
================================================
    15    801.2 MiB    801.2 MiB   @profile
    16                             def discount(x, gamma):
    17                                 """
    18                                 Given vector x, computes a vector y such that
    19                                 y[i] = x[i] + gamma * x[i+1] + gamma^2 x[i+2] + ...
    20                                 """
    21    801.2 MiB      0.0 MiB       out = np.zeros(len(x))
    22    801.2 MiB      0.0 MiB       out[-1] = x[-1]
    23    801.2 MiB      0.0 MiB       for i in reversed(xrange(len(x)-1)):
    24    801.2 MiB      0.0 MiB           out[i] = x[i] + gamma*out[i+1]
    25    801.2 MiB      0.0 MiB       assert x.ndim >= 1
    26                                 # More efficient version:
    27                                 # scipy.signal.lfilter([1],[1,-gamma],x[::-1], axis=0)[::-1]
    28    801.2 MiB      0.0 MiB       return out


total discount reward : 	 -5.356811302937467
Filename: /gpfs/home6/terhard/DeepRM_2/slow_down_cdf.py

Line #    Mem usage    Increment   Line Contents
================================================
    15    801.2 MiB    801.2 MiB   @profile
    16                             def discount(x, gamma):
    17                                 """
    18                                 Given vector x, computes a vector y such that
    19                                 y[i] = x[i] + gamma * x[i+1] + gamma^2 x[i+2] + ...
    20                                 """
    21    801.2 MiB      0.0 MiB       out = np.zeros(len(x))
    22    801.2 MiB      0.0 MiB       out[-1] = x[-1]
    23    801.2 MiB      0.0 MiB       for i in reversed(xrange(len(x)-1)):
    24    801.2 MiB      0.0 MiB           out[i] = x[i] + gamma*out[i+1]
    25    801.2 MiB      0.0 MiB       assert x.ndim >= 1
    26                                 # More efficient version:
    27                                 # scipy.signal.lfilter([1],[1,-gamma],x[::-1], axis=0)[::-1]
    28    801.2 MiB      0.0 MiB       return out


Filename: /gpfs/home6/terhard/DeepRM_2/data_collection.py

Line #    Mem usage    Increment   Line Contents
================================================
    64    801.2 MiB    801.2 MiB           @profile
    65                                     def append_job_to_csv(self, file, header, job_info):
    66    801.2 MiB      0.0 MiB                           if not os.path.isfile(file) or os.path.getsize(file) == 0:
    67                                                             with open(file, 'a') as f:
    68                                                                     writer = csv.writer(f)
    69                                                                     writer.writerow(header)
    70                                                     else:
    71    801.2 MiB      0.0 MiB                                   with open(file, 'a') as d:
    72    801.2 MiB      0.0 MiB                                           writer = csv.writer(d)
    73    801.2 MiB      0.0 MiB                                           writer.writerow(job_info)


(4,)
(4,)
(4,)
('job slowdown: ', 1.0)
('job length array', [528, 489, 632])
('job total size:', array([15, 12,  8,  9]))
('job total size:', array([ 3, 14, 22, 27]))



=============== 3 ===============
('resleft3', array([[13.,  2.],
       [13.,  2.],
       [13.,  2.],
       [13.,  2.],
       [13.,  2.],
       [13.,  2.],
       [13.,  2.],
       [13.,  2.],
       [13.,  2.],
       [13.,  2.],
       [13.,  2.],
       [13.,  2.],
       [13.,  2.],
       [13.,  2.],
       [13.,  2.],
       [13.,  2.],
       [13.,  2.],
       [13.,  2.],
       [13.,  2.],
       [13.,  2.],
       [13.,  2.],
       [13.,  2.],
       [13.,  2.],
       [13.,  2.]]))
('act return cloud node for expensive jobs', 11, 'and job info: ', 0, 24, array([ 2, 13]))
('resleft2', array([[9., 4.],
       [9., 4.],
       [9., 4.]]))
('act return normal edge node for normal jobs', 8, 'and job info: ', 3, 3, array([1, 6]))
('resleft3', array([[14.,  3.],
       [14.,  3.],
       [14.,  3.],
       [14.,  3.],
       [14.,  3.],
       [14.,  3.],
       [14.,  3.],
       [14.,  3.],
       [14.,  3.],
       [14.,  3.],
       [14.,  3.],
       [14.,  3.],
       [14.,  3.],
       [14.,  3.],
       [14.,  3.],
       [14.,  3.],
       [14.,  3.],
       [14.,  3.],
       [14.,  3.]]))
('act return cloud node for expensive jobs', 11, 'and job info: ', 1, 19, array([ 1, 12]))
('resleft3', array([[14.,  2.],
       [14.,  2.],
       [14.,  2.]]))
('act return cloud node for expensive jobs', 12, 'and job info: ', 2, 3, array([ 1, 13]))
nice
(u'final reward', 0)
finished!!!!
(u'final backlog: ', 0, u'job slots: ', [None, None, None, None, None])
Filename: /gpfs/home6/terhard/DeepRM_2/slow_down_cdf.py

Line #    Mem usage    Increment   Line Contents
================================================
    40    801.2 MiB    801.2 MiB   @profile
    41                             def get_traj(test_type, pa, env, episode_max_length, pg_resume=None, use_cnn=True, render=False):
    42                                 """
    43                                 Run agent-environment loop for one whole episode (trajectory)
    44                                 Return dictionary of results
    45                                 """
    46                                 # print("pg_resume in get_traj is: ", pg_resume)
    47                                # append = False
    48    801.2 MiB      0.0 MiB       if test_type == 'PG':  # load trained parameters
    49                                   #  append = True
    50                                     pg_learner = pg_network.PGLearner(pa, use_cnn=use_cnn)
    51                             
    52                                     net_handle = open(pg_resume, 'rb')
    53                                     net_params = cPickle.load(net_handle)
    54                                     pg_learner.set_net_params(net_params)
    55                             
    56    801.2 MiB      0.0 MiB       env.reset()
    57    801.2 MiB      0.0 MiB       rews = []
    58                             
    59    801.2 MiB      0.0 MiB       ob = env.observe()
    60                             
    61    801.2 MiB      0.0 MiB       for _ in xrange(episode_max_length):
    62                             
    63    801.2 MiB      0.0 MiB           if test_type == 'PG':
    64                                         a = pg_learner.choose_action(ob)
    65                             
    66    801.2 MiB      0.0 MiB           elif test_type == 'Tetris':
    67                                       #  append = False
    68                                         a = other_agents.get_packer_action(env.machine, env.job_slot1)
    69                             
    70    801.2 MiB      0.0 MiB           elif test_type == 'SJF':
    71                                      #   append = False
    72    801.2 MiB      0.0 MiB               a = other_agents.get_sjf_action(env.machine, env.job_slot1, pa)
    73                             
    74                                     elif test_type == 'Random':
    75                                       #  append = False
    76                                         a = other_agents.get_random_action(env.job_slot1)
    77                             
    78    801.2 MiB      0.0 MiB           ob, rew, done, info = env.step(a, repeat=True, test_type=test_type)
    79                             
    80    801.2 MiB      0.0 MiB           rews.append(rew)
    81                             
    82    801.2 MiB      0.0 MiB           if done: break
    83    801.2 MiB      0.0 MiB           if render: env.render()
    84                                     # env.render()
    85                             
    86    801.2 MiB      0.0 MiB       return np.array(rews), info


---------- SJF -----------
Filename: /gpfs/home6/terhard/DeepRM_2/slow_down_cdf.py

Line #    Mem usage    Increment   Line Contents
================================================
    15    801.2 MiB    801.2 MiB   @profile
    16                             def discount(x, gamma):
    17                                 """
    18                                 Given vector x, computes a vector y such that
    19                                 y[i] = x[i] + gamma * x[i+1] + gamma^2 x[i+2] + ...
    20                                 """
    21    801.2 MiB      0.0 MiB       out = np.zeros(len(x))
    22    801.2 MiB      0.0 MiB       out[-1] = x[-1]
    23    801.2 MiB      0.0 MiB       for i in reversed(xrange(len(x)-1)):
    24    801.2 MiB      0.0 MiB           out[i] = x[i] + gamma*out[i+1]
    25    801.2 MiB      0.0 MiB       assert x.ndim >= 1
    26                                 # More efficient version:
    27                                 # scipy.signal.lfilter([1],[1,-gamma],x[::-1], axis=0)[::-1]
    28    801.2 MiB      0.0 MiB       return out


total discount reward : 	 38.073572867653304
Filename: /gpfs/home6/terhard/DeepRM_2/slow_down_cdf.py

Line #    Mem usage    Increment   Line Contents
================================================
    15    801.2 MiB    801.2 MiB   @profile
    16                             def discount(x, gamma):
    17                                 """
    18                                 Given vector x, computes a vector y such that
    19                                 y[i] = x[i] + gamma * x[i+1] + gamma^2 x[i+2] + ...
    20                                 """
    21    801.2 MiB      0.0 MiB       out = np.zeros(len(x))
    22    801.2 MiB      0.0 MiB       out[-1] = x[-1]
    23    801.2 MiB      0.0 MiB       for i in reversed(xrange(len(x)-1)):
    24    801.2 MiB      0.0 MiB           out[i] = x[i] + gamma*out[i+1]
    25    801.2 MiB      0.0 MiB       assert x.ndim >= 1
    26                                 # More efficient version:
    27                                 # scipy.signal.lfilter([1],[1,-gamma],x[::-1], axis=0)[::-1]
    28    801.2 MiB      0.0 MiB       return out


Filename: /gpfs/home6/terhard/DeepRM_2/data_collection.py

Line #    Mem usage    Increment   Line Contents
================================================
    64    801.2 MiB    801.2 MiB           @profile
    65                                     def append_job_to_csv(self, file, header, job_info):
    66    801.2 MiB      0.0 MiB                           if not os.path.isfile(file) or os.path.getsize(file) == 0:
    67                                                             with open(file, 'a') as f:
    68                                                                     writer = csv.writer(f)
    69                                                                     writer.writerow(header)
    70                                                     else:
    71    801.2 MiB      0.0 MiB                                   with open(file, 'a') as d:
    72    801.2 MiB      0.0 MiB                                           writer = csv.writer(d)
    73    801.2 MiB      0.0 MiB                                           writer.writerow(job_info)


(4,)
(4,)
(4,)
('job slowdown: ', 1.875)
('job length array', [528, 489, 632, 670])
('job total size:', array([15, 13, 14,  7]))
('job total size:', array([24, 19,  3,  3]))



=============== 4 ===============
('resleft2', array([[3., 9.],
       [3., 9.],
       [3., 9.]]))
('act return normal edge node for normal jobs', 6, 'and job info: ', 0, 3, array([7, 1]))
('resleft3', array([[ 1., 13.],
       [ 1., 13.],
       [ 1., 13.],
       [ 1., 13.],
       [ 1., 13.],
       [ 1., 13.],
       [ 1., 13.],
       [ 1., 13.],
       [ 1., 13.],
       [ 1., 13.],
       [ 1., 13.],
       [ 1., 13.],
       [ 1., 13.],
       [ 1., 13.],
       [ 1., 13.],
       [ 1., 13.],
       [ 1., 13.],
       [ 1., 13.],
       [ 1., 13.],
       [ 1., 13.],
       [ 1., 13.],
       [ 1., 13.]]))
('act return cloud node for expensive jobs', 11, 'and job info: ', 1, 22, array([14,  2]))
('resleft2', array([[3., 8.],
       [3., 8.],
       [3., 8.]]))
('act return normal edge node for normal jobs', 7, 'and job info: ', 3, 3, array([7, 2]))
('resleft3', array([[13.,  3.],
       [13.,  3.],
       [13.,  3.],
       [13.,  3.],
       [13.,  3.],
       [13.,  3.],
       [13.,  3.],
       [13.,  3.],
       [13.,  3.],
       [13.,  3.],
       [13.,  3.],
       [13.,  3.],
       [13.,  3.],
       [13.,  3.],
       [13.,  3.],
       [13.,  3.],
       [13.,  3.],
       [13.,  3.],
       [13.,  3.],
       [13.,  3.],
       [13.,  3.],
       [13.,  3.],
       [13.,  3.],
       [13.,  3.],
       [13.,  3.]]))
('act return cloud node for expensive jobs', 11, 'and job info: ', 2, 25, array([ 2, 12]))
nice
(u'final reward', 0)
finished!!!!
(u'final backlog: ', 0, u'job slots: ', [None, None, None, None, None])
Filename: /gpfs/home6/terhard/DeepRM_2/slow_down_cdf.py

Line #    Mem usage    Increment   Line Contents
================================================
    40    801.2 MiB    801.2 MiB   @profile
    41                             def get_traj(test_type, pa, env, episode_max_length, pg_resume=None, use_cnn=True, render=False):
    42                                 """
    43                                 Run agent-environment loop for one whole episode (trajectory)
    44                                 Return dictionary of results
    45                                 """
    46                                 # print("pg_resume in get_traj is: ", pg_resume)
    47                                # append = False
    48    801.2 MiB      0.0 MiB       if test_type == 'PG':  # load trained parameters
    49                                   #  append = True
    50                                     pg_learner = pg_network.PGLearner(pa, use_cnn=use_cnn)
    51                             
    52                                     net_handle = open(pg_resume, 'rb')
    53                                     net_params = cPickle.load(net_handle)
    54                                     pg_learner.set_net_params(net_params)
    55                             
    56    801.2 MiB      0.0 MiB       env.reset()
    57    801.2 MiB      0.0 MiB       rews = []
    58                             
    59    801.2 MiB      0.0 MiB       ob = env.observe()
    60                             
    61    801.2 MiB      0.0 MiB       for _ in xrange(episode_max_length):
    62                             
    63    801.2 MiB      0.0 MiB           if test_type == 'PG':
    64                                         a = pg_learner.choose_action(ob)
    65                             
    66    801.2 MiB      0.0 MiB           elif test_type == 'Tetris':
    67                                       #  append = False
    68                                         a = other_agents.get_packer_action(env.machine, env.job_slot1)
    69                             
    70    801.2 MiB      0.0 MiB           elif test_type == 'SJF':
    71                                      #   append = False
    72    801.2 MiB      0.0 MiB               a = other_agents.get_sjf_action(env.machine, env.job_slot1, pa)
    73                             
    74                                     elif test_type == 'Random':
    75                                       #  append = False
    76                                         a = other_agents.get_random_action(env.job_slot1)
    77                             
    78    801.2 MiB      0.0 MiB           ob, rew, done, info = env.step(a, repeat=True, test_type=test_type)
    79                             
    80    801.2 MiB      0.0 MiB           rews.append(rew)
    81                             
    82    801.2 MiB      0.0 MiB           if done: break
    83    801.2 MiB      0.0 MiB           if render: env.render()
    84                                     # env.render()
    85                             
    86    801.2 MiB      0.0 MiB       return np.array(rews), info


---------- SJF -----------
Filename: /gpfs/home6/terhard/DeepRM_2/slow_down_cdf.py

Line #    Mem usage    Increment   Line Contents
================================================
    15    801.2 MiB    801.2 MiB   @profile
    16                             def discount(x, gamma):
    17                                 """
    18                                 Given vector x, computes a vector y such that
    19                                 y[i] = x[i] + gamma * x[i+1] + gamma^2 x[i+2] + ...
    20                                 """
    21    801.2 MiB      0.0 MiB       out = np.zeros(len(x))
    22    801.2 MiB      0.0 MiB       out[-1] = x[-1]
    23    801.2 MiB      0.0 MiB       for i in reversed(xrange(len(x)-1)):
    24    801.2 MiB      0.0 MiB           out[i] = x[i] + gamma*out[i+1]
    25    801.2 MiB      0.0 MiB       assert x.ndim >= 1
    26                                 # More efficient version:
    27                                 # scipy.signal.lfilter([1],[1,-gamma],x[::-1], axis=0)[::-1]
    28    801.2 MiB      0.0 MiB       return out


total discount reward : 	 38.87647261278498
Filename: /gpfs/home6/terhard/DeepRM_2/slow_down_cdf.py

Line #    Mem usage    Increment   Line Contents
================================================
    15    801.2 MiB    801.2 MiB   @profile
    16                             def discount(x, gamma):
    17                                 """
    18                                 Given vector x, computes a vector y such that
    19                                 y[i] = x[i] + gamma * x[i+1] + gamma^2 x[i+2] + ...
    20                                 """
    21    801.2 MiB      0.0 MiB       out = np.zeros(len(x))
    22    801.2 MiB      0.0 MiB       out[-1] = x[-1]
    23    801.2 MiB      0.0 MiB       for i in reversed(xrange(len(x)-1)):
    24    801.2 MiB      0.0 MiB           out[i] = x[i] + gamma*out[i+1]
    25    801.2 MiB      0.0 MiB       assert x.ndim >= 1
    26                                 # More efficient version:
    27                                 # scipy.signal.lfilter([1],[1,-gamma],x[::-1], axis=0)[::-1]
    28    801.2 MiB      0.0 MiB       return out


Filename: /gpfs/home6/terhard/DeepRM_2/data_collection.py

Line #    Mem usage    Increment   Line Contents
================================================
    64    801.2 MiB    801.2 MiB           @profile
    65                                     def append_job_to_csv(self, file, header, job_info):
    66    801.2 MiB      0.0 MiB                           if not os.path.isfile(file) or os.path.getsize(file) == 0:
    67                                                             with open(file, 'a') as f:
    68                                                                     writer = csv.writer(f)
    69                                                                     writer.writerow(header)
    70                                                     else:
    71    801.2 MiB      0.0 MiB                                   with open(file, 'a') as d:
    72    801.2 MiB      0.0 MiB                                           writer = csv.writer(d)
    73    801.2 MiB      0.0 MiB                                           writer.writerow(job_info)


(4,)
(4,)
(4,)
('job slowdown: ', 1.7)
('job length array', [528, 489, 632, 670, 753])
('job total size:', array([ 8, 16, 14,  9]))
('job total size:', array([ 3, 22, 25,  3]))
Filename: /gpfs/home6/terhard/DeepRM_2/slow_down_cdf.py

Line #    Mem usage    Increment   Line Contents
================================================
    88    801.1 MiB    801.1 MiB   @profile
    89                             def launch(pa, pg_resume=None, render=False, plot=True, repre='image', end='all_done', use_cnn=True):
    90                                 
    91                                 # print("Initial values:")
    92                                 # print("pg_resume:", pg_resume)
    93                                 # print("use_cnn:", use_cnn)
    94                                 
    95    801.1 MiB      0.0 MiB       data_collection_instances = data_collection.Data_collection()
    96    801.1 MiB      0.0 MiB       csv_header = ['Test Type', 'Average Slowdown', 'Total Slowdown','Workload','Dist Proba', 'Anomaly rate']
    97    801.1 MiB      0.0 MiB       test_file = 'test_metrics.csv'
    98                                 
    99                                 # ---- Parameters ----
   100                             
   101    801.1 MiB      0.0 MiB       test_types = ['SJF']
   102                             
   103                                 # colors:
   104    801.1 MiB      0.0 MiB       if pg_resume is not None:
   105                                     test_types = ['PG'] + test_types
   106                             
   107    801.1 MiB      0.0 MiB       env = environment.Env(pa, render, repre=repre, end=end)
   108                             
   109    801.1 MiB      0.0 MiB       all_discount_rews = {}
   110    801.1 MiB      0.0 MiB       jobs_slow_down = {}
   111    801.1 MiB      0.0 MiB       work_complete = {}
   112    801.1 MiB      0.0 MiB       work_remain = {}
   113    801.1 MiB      0.0 MiB       job_len_remain = {}
   114    801.1 MiB      0.0 MiB       num_job_remain = {}
   115    801.1 MiB      0.0 MiB       job_remain_delay = {}
   116                             
   117    801.1 MiB      0.0 MiB       deepRM_test = True
   118                                 
   119                             
   120    801.1 MiB      0.0 MiB       for test_type in test_types:
   121    801.1 MiB      0.0 MiB           all_discount_rews[test_type] = []
   122    801.1 MiB      0.0 MiB           jobs_slow_down[test_type] = []
   123    801.1 MiB      0.0 MiB           work_complete[test_type] = []
   124    801.1 MiB      0.0 MiB           work_remain[test_type] = []
   125    801.1 MiB      0.0 MiB           job_len_remain[test_type] = []
   126    801.1 MiB      0.0 MiB           num_job_remain[test_type] = []
   127    801.1 MiB      0.0 MiB           job_remain_delay[test_type] = []
   128                             
   129    801.2 MiB      0.0 MiB       for seq_idx in xrange(pa.num_ex):
   130    801.2 MiB      0.0 MiB           print('\n\n')
   131    801.2 MiB      0.0 MiB           print("=============== " + str(seq_idx) + " ===============")
   132                                     
   133    801.2 MiB      0.0 MiB           for test_type in test_types:
   134    801.2 MiB      0.0 MiB               if test_type is not 'PG':
   135    801.2 MiB      0.0 MiB                   deepRM_test = False
   136                                         
   137    801.2 MiB      0.0 MiB               rews, info = get_traj(test_type, pa, env, pa.episode_max_length, pg_resume=pg_resume, use_cnn=use_cnn, render=render)
   138                                         
   139    801.2 MiB      0.0 MiB               with open('./test_type.csv', 'a') as f:
   140    801.2 MiB      0.0 MiB                   writer = csv.writer(f)
   141    801.2 MiB      0.0 MiB                   writer.writerow([seq_idx, test_type])
   142    801.2 MiB      0.0 MiB               print "---------- " + test_type + " -----------"
   143                             
   144    801.2 MiB      0.0 MiB               print "total discount reward : \t %s" % (discount(rews, pa.discount)[0])
   145                             
   146    801.2 MiB      0.0 MiB               all_discount_rews[test_type].append(
   147    801.2 MiB      0.0 MiB                   discount(rews, pa.discount)[0]
   148                                         )
   149                             
   150                                         # ------------------------
   151                                         # ---- per job stat ----
   152                                         # ------------------------
   153                             
   154    801.2 MiB      0.0 MiB               enter_time = np.array([info.record[i].enter_time for i in xrange(len(info.record))])
   155    801.2 MiB      0.0 MiB               finish_time = np.array([info.record[i].finish_time for i in xrange(len(info.record))]) #maybe add if statement to not take into account the -1 jobs
   156    801.2 MiB      0.0 MiB               job_len = np.array([info.record[i].len for i in xrange(len(info.record))])
   157                                         
   158    801.2 MiB      0.0 MiB               job_total_size = np.array([np.sum(info.record[i].res_vec) for i in xrange(len(info.record))])
   159                             
   160    801.2 MiB      0.0 MiB               finished_idx = (finish_time >= 0)
   161    801.2 MiB      0.0 MiB               unfinished_idx = (finish_time < 0)
   162                             
   163    801.2 MiB      0.0 MiB               jobs_slow_down[test_type].append(
   164    801.2 MiB      0.0 MiB                   (finish_time[finished_idx] - enter_time[finished_idx]) / job_len[finished_idx]
   165                                         )
   166    801.2 MiB      0.0 MiB               work_complete[test_type].append(
   167    801.2 MiB      0.0 MiB                   np.sum(job_len[finished_idx] * job_total_size[finished_idx])
   168                                         )
   169    801.2 MiB      0.0 MiB               work_remain[test_type].append(
   170    801.2 MiB      0.0 MiB                   np.sum(job_len[unfinished_idx] * job_total_size[unfinished_idx])
   171                                         )
   172    801.2 MiB      0.0 MiB               job_len_remain[test_type].append(
   173    801.2 MiB      0.0 MiB                   np.sum(job_len[unfinished_idx])
   174                                         )
   175    801.2 MiB      0.0 MiB               num_job_remain[test_type].append(
   176    801.2 MiB      0.0 MiB                   len(job_len[unfinished_idx])
   177                                         )
   178    801.2 MiB      0.0 MiB               job_remain_delay[test_type].append(
   179    801.2 MiB      0.0 MiB                   np.sum(pa.episode_max_length - enter_time[unfinished_idx])
   180                                         )
   181                                         
   182    801.2 MiB      0.0 MiB               job_slowdown = (finish_time[finished_idx] - enter_time[finished_idx]) / job_len[finished_idx]
   183    801.2 MiB      0.0 MiB               mean_slowdown = np.mean(job_slowdown)
   184    801.2 MiB      0.0 MiB               total_slowdown = np.sum(job_slowdown)
   185    801.2 MiB      0.0 MiB               test_type_name = ''
   186    801.2 MiB      0.0 MiB               if test_type == 'PG':
   187                                             if use_cnn:
   188                                                 test_type_name = 'DeepRM_2'
   189                                             else:
   190                                                 test_type_name = 'DeepRM_ECO'
   191                                         else:
   192    801.2 MiB      0.0 MiB                   test_type_name = test_type
   193    801.2 MiB      0.0 MiB               run_info = [test_type_name, mean_slowdown, total_slowdown,pa.simu_len,pa.new_job_rate,pa.anomalous_job_rate]
   194    801.2 MiB      0.0 MiB               data_collection_instances.append_job_to_csv(test_file,csv_header,run_info)
   195    801.2 MiB      0.0 MiB               print(finish_time[finished_idx].shape)
   196    801.2 MiB      0.0 MiB               print(enter_time[finished_idx].shape)
   197    801.2 MiB      0.0 MiB               print(job_len[finished_idx].shape)
   198    801.2 MiB      0.0 MiB               print('job slowdown: ', np.mean(np.concatenate(jobs_slow_down[test_type])))
   199    801.2 MiB      0.0 MiB               print("job length array", work_complete[test_type])
   200    801.2 MiB      0.0 MiB               print('job total size:',job_total_size[finished_idx])
   201    801.2 MiB      0.0 MiB               print('job total size:',job_len[finished_idx])
   202    801.2 MiB      0.0 MiB           env.seq_no = (env.seq_no + 1) % env.pa.num_ex
   203                             
   204                                 # -- matplotlib colormap no overlap --
   205    801.2 MiB      0.0 MiB       if plot:
   206                                     
   207                                     num_colors = len(test_types)
   208                                     cm = plt.get_cmap('gist_rainbow')
   209                                     color_cycler = cycler(color=[cm(1. * i / num_colors) for i in range(num_colors)])
   210                             
   211                                     fig = plt.figure()
   212                                     ax = fig.add_subplot(111)
   213                                     ax.set_prop_cycle(color_cycler)
   214                             
   215                                     for test_type in test_types:
   216                                         slow_down_cdf = np.sort(np.concatenate(jobs_slow_down[test_type]))
   217                                         slow_down_yvals = np.arange(len(slow_down_cdf))/float(len(slow_down_cdf))
   218                                         ax.plot(slow_down_cdf, slow_down_yvals, linewidth=2, label=test_type)
   219                             
   220                                     plt.legend(loc=4)
   221                                     plt.xlabel("job slowdown", fontsize=20)
   222                                     plt.ylabel("CDF", fontsize=20)
   223                                     # plt.show()
   224                             
   225                                     plt.savefig(pg_resume + "_slowdown_fig" + ".pdf")
   226                                     print(plt.savefig(pg_resume + "_slowdown_fig" + ".pdf"))
   227                             
   228    801.2 MiB      0.0 MiB       return all_discount_rews, jobs_slow_down


Start training...
Filename: /gpfs/home6/terhard/DeepRM_2/pg_re.py

Line #    Mem usage    Increment   Line Contents
================================================
   239    144.8 MiB    144.8 MiB   @profile
   240                             def launch(pa, pg_resume=None, render=False, repre='image', end='all_done', use_cnn=True):
   241                                 # ----------------------------
   242    144.8 MiB      0.0 MiB       print("Preparing for workers...")
   243                                 # ----------------------------
   244    144.8 MiB      0.0 MiB       pg_resume=None #'data/pg_re_620.pkl'
   245                                 # print("pg_resume is set to:", pg_resume)
   246    144.8 MiB      0.0 MiB       data_collector = data_collection.Data_collection()
   247    144.8 MiB      0.0 MiB       data_collector.convert_parameter_to_yaml(pa)
   248                             
   249    144.8 MiB      0.0 MiB       with open('./parameters.csv', 'a') as f:
   250    144.8 MiB      0.0 MiB           writer = csv.writer(f)
   251    144.8 MiB      0.0 MiB           writer.writerow("param")
   252                                     #'data/pg_re_620.pkl'                 
   253                             
   254                             
   255                                     #the way jobs are created are in the blocks so we can visualize them in the same manner. 
   256                             
   257                                     # supervised learning mimic policy
   258                             
   259    144.8 MiB      0.0 MiB       pg_learners = []
   260    144.8 MiB      0.0 MiB       envs = []
   261                                 
   262    144.9 MiB      0.1 MiB       nw_len_seqs, nw_size_seqs = job_distribution.generate_sequence_work(pa, seed=42)
   263                             
   264    144.9 MiB      0.0 MiB       for ex in xrange(pa.num_ex):
   265                             
   266    144.9 MiB      0.0 MiB           print("-prepare for env-", ex)
   267                             
   268    144.9 MiB      0.0 MiB           env = environment.Env(pa, nw_len_seqs=nw_len_seqs, nw_size_seqs=nw_size_seqs,
   269    144.9 MiB      0.0 MiB                                 render=False, repre=repre, end=end)
   270    144.9 MiB      0.0 MiB           env.seq_no = ex
   271    144.9 MiB      0.0 MiB           envs.append(env)
   272                             
   273    791.1 MiB      0.0 MiB       for ex in xrange(pa.batch_size + 1):  # last worker for updating the parameters
   274                             
   275    723.3 MiB      0.0 MiB           print("-prepare for worker-", ex)
   276                             
   277                                     # print("use cnn type:", use_cnn, type(use_cnn))
   278    791.1 MiB     76.8 MiB           pg_learner = pg_network.PGLearner(pa, use_cnn)
   279                                     
   280    791.1 MiB      0.0 MiB           if pg_resume is not None:
   281                                         # print("pg_resume used", pg_resume)
   282                                         net_handle = open(pg_resume, 'rb')
   283                                         net_params = cPickle.load(net_handle)
   284                                         pg_learner.set_net_params(net_params)
   285                             
   286    791.1 MiB      0.0 MiB           pg_learners.append(pg_learner)
   287                             
   288    801.1 MiB     10.0 MiB       accums = init_accums(pg_learners[pa.batch_size])
   289                             
   290                                 # --------------------------------------
   291    801.1 MiB      0.0 MiB       print("Preparing for reference data...")
   292                                 # --------------------------------------
   293    801.1 MiB      0.0 MiB       testvar = "started to train"
   294    801.1 MiB      0.0 MiB       with open('./test_type.csv', 'a') as f:
   295    801.1 MiB      0.0 MiB           writer = csv.writer(f)
   296    801.1 MiB      0.0 MiB           writer.writerow([testvar, testvar])
   297    801.2 MiB      0.1 MiB       ref_discount_rews, ref_slow_down = slow_down_cdf.launch(pa, pg_resume=None, render=False, plot=False, repre=repre, end=end, use_cnn=use_cnn)
   298                                 
   299    801.2 MiB      0.0 MiB       mean_rew_lr_curve = []
   300    801.2 MiB      0.0 MiB       max_rew_lr_curve = []
   301    801.2 MiB      0.0 MiB       slow_down_lr_curve = []
   302                             
   303                                 # --------------------------------------
   304                                 
   305    801.2 MiB      0.0 MiB       print("Start training...")
   306                                 # --------------------------------------
   307                             
   308    801.2 MiB      0.0 MiB       timer_start = time.time()
   309                             
   310    801.2 MiB      0.0 MiB       for iteration in xrange(1, pa.num_epochs):
   311                             
   312                                     ps = []  # threads
   313                                     manager = Manager()  # managing return results
   314                                     manager_result = manager.list([])
   315                             
   316                                     ex_indices = range(pa.num_ex)
   317                                     np.random.shuffle(ex_indices)
   318                             
   319                                     all_eprews = []
   320                                     grads_all = []
   321                                     loss_all = []
   322                                     eprews = []
   323                                     eplens = []
   324                                     all_slowdown = []
   325                                     all_entropy = []
   326                             
   327                                     ex_counter = 0
   328                                     for ex in xrange(pa.num_ex):
   329                             
   330                                         ex_idx = ex_indices[ex]
   331                                         p = Process(target=get_traj_worker,
   332                                                     args=(pg_learners[ex_counter], envs[ex_idx], pa, manager_result, ))
   333                                         ps.append(p)
   334                             
   335                                         ex_counter += 1
   336                             
   337                                         if ex_counter >= pa.batch_size or ex == pa.num_ex - 1:
   338                             
   339                                             print(ex, "out of", pa.num_ex)
   340                             
   341                                             ex_counter = 0
   342                             
   343                                             for p in ps:
   344                                                 p.start()
   345                             
   346                                             for p in ps:
   347                                                 p.join()
   348                             
   349                                             result = []  # convert list from shared memory
   350                                             for r in manager_result:
   351                                                 result.append(r)
   352                             
   353                                             ps = []
   354                                             manager_result = manager.list([])
   355                             
   356                                             all_ob = concatenate_all_ob_across_examples([r["all_ob"] for r in result], pa)
   357                                             all_action = np.concatenate([r["all_action"] for r in result])
   358                                             all_adv = np.concatenate([r["all_adv"] for r in result])
   359                                             
   360                                             # Batch updates
   361                                             num_batches = int(np.ceil(len(all_ob) / float(pa.batch_size)))
   362                                             for batch in range(num_batches):
   363                                                 start = batch * pa.batch_size
   364                                                 end = min(start + pa.batch_size, len(all_ob))
   365                                                 
   366                                                 batch_states = all_ob[start:end]
   367                                                 batch_actions = all_action[start:end]
   368                                                 batch_values = all_adv[start:end]
   369                                                 
   370                                                 grads = pg_learners[pa.batch_size].get_grad(batch_states, batch_actions, batch_values)
   371                                                 grads_all.append(grads)
   372                             
   373                                             # Do policy gradient update step, using the first agent
   374                                             # put the new parameter in the last 'worker', then propagate the update at the end
   375                                             # grads = pg_learners[pa.batch_size].get_grad(all_ob, all_action, all_adv)
   376                             
   377                                             # grads_all.append(grads)
   378                             
   379                                             all_eprews.extend([r["all_eprews"] for r in result])
   380                             
   381                                             eprews.extend(np.concatenate([r["all_eprews"] for r in result]))  # episode total rewards
   382                                             eplens.extend(np.concatenate([r["all_eplens"] for r in result]))  # episode lengths
   383                                             all_slowdown.extend(np.concatenate([r["all_slowdown"] for r in result]))
   384                                             all_entropy.extend(np.concatenate([r["all_entropy"] for r in result]))
   385                             
   386                                     # assemble gradients
   387                                     grads = grads_all[0]
   388                                     for i in xrange(1, len(grads_all)):
   389                                         for j in xrange(len(grads)):
   390                                             grads[j] += grads_all[i][j]
   391                             
   392                                     # propagate network parameters to others
   393                                     params = pg_learners[pa.batch_size].get_params()
   394                             
   395                                     rmsprop_updates_outside(grads, params, accums, pa.lr_rate, pa.rms_rho, pa.rms_eps)
   396                             
   397                                     for i in xrange(pa.batch_size + 1):
   398                                         pg_learners[i].set_net_params(params)
   399                             
   400                                     timer_end = time.time()
   401                             
   402                                     print("Epoch: \t %i" % iteration)
   403                                     print("NumTrajs: \t %i" % len(eprews))
   404                                     print("NumTimesteps: \t %i" % np.sum(eplens))
   405                                     print("-----------------")
   406                                     # print("Loss:     \t %s" % np.mean(loss_all))
   407                                     print("MaxRew: \t %s" % np.average([np.max(rew) for rew in all_eprews]))
   408                                     print("MeanRew: \t %s +- %s" % (np.mean(eprews), np.std(eprews)))
   409                                     print("MeanSlowdown: \t %s" % np.mean(all_slowdown))
   410                                     print("MeanLen: \t %s +- %s" % (np.mean(eplens), np.std(eplens)))
   411                                     print("MeanEntropy \t %s" % (np.mean(all_entropy)))
   412                                     print("Elapsed time\t %s" % (timer_end - timer_start), "seconds")
   413                                     print("-----------------")
   414                             
   415                                     timer_start = time.time()
   416                             
   417                                     max_rew_lr_curve.append(np.average([np.max(rew) for rew in all_eprews]))
   418                                     mean_rew_lr_curve.append(np.mean(eprews))
   419                                     slow_down_lr_curve.append(np.mean(all_slowdown))
   420                                     with open('./metrics.csv', 'a') as f:
   421                                         writer = csv.writer(f)
   422                                         if os.stat('./metrics.csv').st_size == 0:
   423                                             writer.writerow(['Metric', 'Value', 'Timestamp', 'Epoch'])
   424                                         writer.writerow(['NumTrajs', float(len(eprews)), 0, iteration])
   425                                         writer.writerow(['NumTimesteps', float(np.sum(eplens)), 0, iteration])
   426                                         writer.writerow(['MaxRew', float(np.average([np.max(rew) for rew in all_eprews])), 0,iteration])
   427                                         writer.writerow(['MeanRew_lower', float(np.std(eprews)), 0, iteration])
   428                                         writer.writerow(['MeanRew_upper', float(np.mean(eprews)), 0, iteration])
   429                                         writer.writerow(['MeanSlowdown', float(np.mean(all_slowdown)), 0, iteration])
   430                                         writer.writerow(['MeanLen+', float(np.mean(eplens)), 0, iteration])
   431                                         writer.writerow(['MeanLen-', float(np.std(eplens)), 0, iteration])
   432                                         writer.writerow(['MeanEntropy', float(np.mean(all_entropy)), 0, iteration])
   433                                         
   434                                     # Write heuristic metrics to CSV
   435                                     with open('./metrics-heuristics.csv', 'a') as f:
   436                                         writer = csv.writer(f)
   437                                         if os.stat('./metrics-heuristics.csv').st_size == 0:
   438                                             writer.writerow(['Heuristic', 'Metric', 'Value', 'Epoch'])
   439                                         for k in ref_slow_down:
   440                                             writer.writerow([k, 'MeanSlowdown', np.average(np.concatenate(ref_slow_down[k])), iteration])
   441                                         for k in ref_discount_rews:
   442                                             writer.writerow([k, 'MaxRew', np.max(ref_discount_rews[k]), iteration])
   443                                             writer.writerow([k, 'MeanRew_upper', np.mean(ref_discount_rews[k]), iteration])
   444                                             
   445                                     if iteration % pa.output_freq == 0:
   446                                         param_file = open(pa.output_filename + '_' + str(iteration) + '.pkl', 'wb')
   447                                         cPickle.dump(pg_learners[pa.batch_size].get_params(), param_file, -1)
   448                                         param_file.close()
   449                             
   450                                         pa.unseen = True
   451                                         
   452                                         slow_down_cdf.launch(pa, pa.output_filename + '_' + str(iteration) + '.pkl',
   453                                                              render=False, plot=True, repre=repre, end=end, use_cnn=use_cnn)
   454                                         
   455                                         pa.unseen = False
   456                                         # test on unseen examples
   457                             
   458                                         plot_lr_curve(pa.output_filename,
   459                                                       max_rew_lr_curve, mean_rew_lr_curve, slow_down_lr_curve,
   460                                                       ref_discount_rews, ref_slow_down)


Filename: launcher.py

Line #    Mem usage    Increment   Line Contents
================================================
    44    144.7 MiB    144.7 MiB   @profile
    45                             def main():
    46                             
    47    144.7 MiB      0.0 MiB       pa = parameters.Parameters()
    48                             
    49    144.7 MiB      0.0 MiB       type_exp = 'pg_re'  # 'pg_su' 'pg_su_compact' 'v_su', 'pg_v_re', 'pg_re', q_re', 'test'
    50                             
    51    144.7 MiB      0.0 MiB       pg_resume = None
    52    144.7 MiB      0.0 MiB       v_resume = None
    53    144.7 MiB      0.0 MiB       q_resume = None
    54    144.7 MiB      0.0 MiB       log = None
    55                             
    56    144.7 MiB      0.0 MiB       render = False
    57    144.7 MiB      0.0 MiB       use_cnn = True
    58                             
    59    144.7 MiB      0.0 MiB       try:
    60    144.7 MiB      0.0 MiB           opts, args = getopt.getopt(
    61    144.7 MiB      0.0 MiB               sys.argv[1:],
    62    144.7 MiB      0.0 MiB               "hi:o:", ["exp_type=",
    63    144.7 MiB      0.0 MiB                         "num_res=",
    64    144.7 MiB      0.0 MiB                         "num_nw=",
    65    144.7 MiB      0.0 MiB                         "simu_len=",
    66    144.7 MiB      0.0 MiB                         "num_ex=",
    67    144.7 MiB      0.0 MiB                         "num_seq_per_batch=",
    68    144.7 MiB      0.0 MiB                         "eps_max_len=",
    69    144.7 MiB      0.0 MiB                         "num_epochs=",
    70    144.7 MiB      0.0 MiB                         "time_horizon=",
    71    144.7 MiB      0.0 MiB                         "res_slot=",
    72    144.7 MiB      0.0 MiB                         "max_job_len=",
    73    144.7 MiB      0.0 MiB                         "max_job_size=",
    74    144.7 MiB      0.0 MiB                         "new_job_rate=",
    75    144.7 MiB      0.0 MiB                         "dist=",
    76    144.7 MiB      0.0 MiB                         "lr_rate=",
    77    144.7 MiB      0.0 MiB                         "ba_size=",
    78    144.7 MiB      0.0 MiB                         "pg_re=",
    79    144.7 MiB      0.0 MiB                         "v_re=",
    80    144.7 MiB      0.0 MiB                         "q_re=",
    81    144.7 MiB      0.0 MiB                         "out_freq=",
    82    144.7 MiB      0.0 MiB                         "ofile=",
    83    144.7 MiB      0.0 MiB                         "log=",
    84    144.7 MiB      0.0 MiB                         "render=",
    85    144.7 MiB      0.0 MiB                         "unseen=",
    86    144.7 MiB      0.0 MiB                         "use_cnn="])
    87                             
    88                                 except getopt.GetoptError:
    89                                     script_usage()
    90                                     sys.exit(2)
    91                             
    92    144.7 MiB      0.0 MiB       for opt, arg in opts:
    93    144.7 MiB      0.0 MiB           if opt == '-h':
    94                                         script_usage()
    95                                         sys.exit()
    96    144.7 MiB      0.0 MiB           elif opt in ("-e", "--exp_type"):
    97    144.7 MiB      0.0 MiB               type_exp = arg
    98    144.7 MiB      0.0 MiB           elif opt in ("-n", "--num_res"):
    99                                         pa.num_res = int(arg)
   100    144.7 MiB      0.0 MiB           elif opt in ("-w", "--num_nw"):
   101                                         pa.num_nw = int(arg)
   102    144.7 MiB      0.0 MiB           elif opt in ("-s", "--simu_len"):
   103    144.7 MiB      0.0 MiB               pa.simu_len = int(arg)
   104    144.7 MiB      0.0 MiB           elif opt in ("-n", "--num_ex"):
   105    144.7 MiB      0.0 MiB               pa.num_ex = int(arg)
   106    144.7 MiB      0.0 MiB           elif opt in ("-sp", "--num_seq_per_batch"):
   107                                         pa.num_seq_per_batch = int(arg)
   108    144.7 MiB      0.0 MiB           elif opt in ("-el", "--eps_max_len"):
   109                                         pa.episode_max_length = int(arg)
   110    144.7 MiB      0.0 MiB           elif opt in ("-ne", "--num_epochs"):
   111    144.7 MiB      0.0 MiB               pa.num_epochs = int(arg)
   112    144.7 MiB      0.0 MiB           elif opt in ("-t", "--time_horizon"):
   113                                         pa.time_horizon = int(arg)
   114    144.7 MiB      0.0 MiB           elif opt in ("-rs", "--res_slot"):
   115                                         pa.res_slot = int(arg)
   116    144.7 MiB      0.0 MiB           elif opt in ("-ml", "--max_job_len"):
   117                                         pa.max_job_len = int(arg)
   118    144.7 MiB      0.0 MiB           elif opt in ("-ms", "--max_job_size"):
   119                                         pa.max_job_size = int(arg)
   120    144.7 MiB      0.0 MiB           elif opt in ("-nr", "--new_job_rate"):
   121                                         pa.new_job_rate = float(arg)
   122    144.7 MiB      0.0 MiB           elif opt in ("-d", "--dist"):
   123                                         pa.discount = float(arg)
   124    144.7 MiB      0.0 MiB           elif opt in ("-l", "--lr_rate"):
   125                                         pa.lr_rate = float(arg)
   126    144.7 MiB      0.0 MiB           elif opt in ("-b", "--ba_size"):
   127    144.7 MiB      0.0 MiB               pa.batch_size = int(arg)
   128    144.7 MiB      0.0 MiB           elif opt in ("-p", "--pg_re"):
   129    144.7 MiB      0.0 MiB               pg_resume = arg
   130    144.7 MiB      0.0 MiB           elif opt in ("-v", "--v_re"):
   131                                         v_resume = arg
   132    144.7 MiB      0.0 MiB           elif opt in ("-q", "--q_re"):
   133                                         q_resume = arg
   134    144.7 MiB      0.0 MiB           elif opt in ("-f", "--out_freq"):
   135                                         pa.output_freq = int(arg)
   136    144.7 MiB      0.0 MiB           elif opt in ("-o", "--ofile"):
   137    144.7 MiB      0.0 MiB               pa.output_filename = arg
   138    144.7 MiB      0.0 MiB           elif opt in ("-lg", "--log"):
   139                                         log = arg
   140    144.7 MiB      0.0 MiB           elif opt in ("-r", "--render"):
   141                                         render = (arg == 'True')
   142    144.7 MiB      0.0 MiB           elif opt in ("-u", "--unseen"):
   143                                         pa.generate_unseen = (arg == 'True')
   144    144.7 MiB      0.0 MiB           elif opt in ("--use_cnn"):
   145    144.7 MiB      0.0 MiB               use_cnn = (arg == 'True')
   146                                     else:
   147                                         script_usage()
   148                                         sys.exit()
   149                             
   150    144.7 MiB      0.0 MiB       print("\n" + "Experiment type: " + type_exp)
   151    144.7 MiB      0.0 MiB       print("CNN used: " + str(use_cnn) + "\n")
   152                                 
   153    144.7 MiB      0.0 MiB       pa.compute_dependent_parameters()
   154                             
   155    144.7 MiB      0.0 MiB       if type_exp == 'pg_su':
   156                                     pg_su.launch(pa, pg_resume, render, repre='image', end='all_done')
   157    144.7 MiB      0.0 MiB       elif type_exp == 'v_su':
   158                                     v_su.launch(pa, v_resume, render)
   159    144.7 MiB      0.0 MiB       elif type_exp == 'pg_re':
   160    801.2 MiB    656.5 MiB           pg_re.launch(pa, pg_resume, render, repre='image', end='all_done', use_cnn=use_cnn)
   161                                 elif type_exp == 'pg_v_re':
   162                                     pg_v_re.launch(pa, pg_resume, v_resume, render)
   163                                 elif type_exp == 'test':
   164                                     # quick_test.launch(pa, pg_resume, render)
   165                                     slow_down_cdf.launch(pa, pg_resume, render, True, use_cnn=use_cnn)
   166                                 # elif type_exp == 'q_re':
   167                                 #     q_re.launch(pa, q_resume, render)
   168                                 else:
   169                                     print("Error: unkown experiment type " + str(type_exp))
   170                                     exit(1)


mprof: Sampling memory every 0.1s
Traceback (most recent call last):
  File "/home/terhard/.conda/envs/py27/bin/mprof", line 8, in <module>
    sys.exit(main())
  File "/home/terhard/.conda/envs/py27/lib/python2.7/site-packages/mprof.py", line 810, in main
    actions[get_action()]()
  File "/home/terhard/.conda/envs/py27/lib/python2.7/site-packages/mprof.py", line 759, in plot_action
    fig = pl.figure(figsize=(14, 6), dpi=90)
  File "/home/terhard/.conda/envs/py27/lib/python2.7/site-packages/matplotlib/pyplot.py", line 533, in figure
    **kwargs)
  File "/home/terhard/.conda/envs/py27/lib/python2.7/site-packages/matplotlib/backend_bases.py", line 161, in new_figure_manager
    return cls.new_figure_manager_given_figure(num, fig)
  File "/home/terhard/.conda/envs/py27/lib/python2.7/site-packages/matplotlib/backend_bases.py", line 167, in new_figure_manager_given_figure
    canvas = cls.FigureCanvas(figure)
  File "/home/terhard/.conda/envs/py27/lib/python2.7/site-packages/matplotlib/backends/backend_qt5agg.py", line 24, in __init__
    super(FigureCanvasQTAgg, self).__init__(figure=figure)
  File "/home/terhard/.conda/envs/py27/lib/python2.7/site-packages/matplotlib/backends/backend_qt5.py", line 234, in __init__
    _create_qApp()
  File "/home/terhard/.conda/envs/py27/lib/python2.7/site-packages/matplotlib/backends/backend_qt5.py", line 125, in _create_qApp
    raise RuntimeError('Invalid DISPLAY variable')
RuntimeError: Invalid DISPLAY variable

JOB STATISTICS
==============
Job ID: 6459610
Cluster: snellius
User/Group: terhard/terhard
State: RUNNING
Nodes: 1
Cores per node: 18
CPU Utilized: 00:08:35
CPU Efficiency: 6.47% of 02:12:36 core-walltime
Job Wall-clock time: 00:07:22
Memory Utilized: 782.25 MB
Memory Efficiency: 0.64% of 120.00 GB
WARNING: Efficiency statistics may be misleading for RUNNING jobs.
